2025-04-19 11:41:40,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 11:41:40,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 11:41:40,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 11:41:40,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 12:15:13,134:WARNING:<ipython-input-27-4b477c73f7b0>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  clients_data["MARRIAGE"] = clients_data["MARRIAGE"].astype("category")

2025-04-19 14:39:33,808:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:33,809:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:33,900:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:33,901:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:33,988:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:33,989:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:34,072:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:34,075:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:34,181:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:34,183:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:34,272:WARNING:<ipython-input-61-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:34,273:WARNING:<ipython-input-61-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:39:35,263:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:35,264:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:35,459:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:35,460:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:35,927:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:35,928:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:36,114:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:36,115:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:36,297:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:36,298:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:36,477:WARNING:<ipython-input-62-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:39:36,478:WARNING:<ipython-input-62-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:39:44,254:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 14:46:52,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 14:46:52,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 14:46:52,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 14:46:52,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 14:56:04,342:WARNING:<ipython-input-27-96ca1f8daa86>:65: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-19 14:59:27,831:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:27,832:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:27,920:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:27,921:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:28,226:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:28,227:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:28,328:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:28,329:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:28,424:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:28,424:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:28,523:WARNING:<ipython-input-42-cdfc00873b84>:24: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:28,525:WARNING:<ipython-input-42-cdfc00873b84>:28: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 14:59:29,645:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:29,647:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:29,855:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:29,856:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:30,043:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:30,044:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:30,239:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:30,241:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:30,622:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:30,623:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:30,808:WARNING:<ipython-input-43-64a23ae80b1d>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 14:59:30,810:WARNING:<ipython-input-43-64a23ae80b1d>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 14:59:38,830:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 15:47:20,244:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,245:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:47:20,334:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,335:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:47:20,423:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,424:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:47:20,515:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,516:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:47:20,602:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,603:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:47:20,692:WARNING:<ipython-input-111-e15f0b51989a>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:47:20,693:WARNING:<ipython-input-111-e15f0b51989a>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 15:59:50,500:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:50,501:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 15:59:50,971:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:50,973:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 15:59:51,167:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:51,168:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 15:59:51,362:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:51,363:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 15:59:51,553:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:51,555:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 15:59:51,748:WARNING:<ipython-input-118-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 15:59:51,750:WARNING:<ipython-input-118-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 16:05:12,634:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 16:05:13,160:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-19 16:05:13,162:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-19 16:16:32,685:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 16:16:33,178:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-19 16:16:33,179:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-19 16:24:51,461:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 16:24:51,926:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-19 16:24:51,926:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-19 16:29:17,966:INFO:PyCaret ClassificationExperiment
2025-04-19 16:29:17,966:INFO:Logging name: baseline
2025-04-19 16:29:17,966:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 16:29:17,967:INFO:version 3.3.2
2025-04-19 16:29:17,967:INFO:Initializing setup()
2025-04-19 16:29:17,967:INFO:self.USI: 1bd7
2025-04-19 16:29:17,967:INFO:self._variable_keys: {'exp_id', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X', 'y_train', 'data', 'log_plots_param', 'idx', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'memory', 'seed', 'fold_groups_param', 'target_param', '_available_plots', 'fix_imbalance', 'y_test', 'fold_generator', 'n_jobs_param', 'logging_param', 'is_multiclass', 'gpu_param', 'USI', 'X_train', 'fold_shuffle_param'}
2025-04-19 16:29:17,967:INFO:Checking environment
2025-04-19 16:29:17,967:INFO:python_version: 3.11.4
2025-04-19 16:29:17,967:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-19 16:29:17,967:INFO:machine: AMD64
2025-04-19 16:29:17,967:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 16:29:17,979:INFO:Memory: svmem(total=16498810880, available=863391744, percent=94.8, used=15635419136, free=863391744)
2025-04-19 16:29:17,979:INFO:Physical Core: 8
2025-04-19 16:29:17,979:INFO:Logical Core: 16
2025-04-19 16:29:17,979:INFO:Checking libraries
2025-04-19 16:29:17,979:INFO:System:
2025-04-19 16:29:17,979:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-19 16:29:17,979:INFO:executable: c:\Python311\python.exe
2025-04-19 16:29:17,979:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 16:29:17,979:INFO:PyCaret required dependencies:
2025-04-19 16:29:18,107:INFO:                 pip: 23.1.2
2025-04-19 16:29:18,108:INFO:          setuptools: 65.5.0
2025-04-19 16:29:18,108:INFO:             pycaret: 3.3.2
2025-04-19 16:29:18,108:INFO:             IPython: 8.20.0
2025-04-19 16:29:18,108:INFO:          ipywidgets: 8.1.6
2025-04-19 16:29:18,108:INFO:                tqdm: 4.66.2
2025-04-19 16:29:18,108:INFO:               numpy: 1.26.2
2025-04-19 16:29:18,108:INFO:              pandas: 2.1.4
2025-04-19 16:29:18,108:INFO:              jinja2: 3.1.2
2025-04-19 16:29:18,108:INFO:               scipy: 1.11.4
2025-04-19 16:29:18,108:INFO:              joblib: 1.3.2
2025-04-19 16:29:18,108:INFO:             sklearn: 1.4.2
2025-04-19 16:29:18,108:INFO:                pyod: 2.0.4
2025-04-19 16:29:18,108:INFO:            imblearn: 0.12.0
2025-04-19 16:29:18,108:INFO:   category_encoders: 2.7.0
2025-04-19 16:29:18,108:INFO:            lightgbm: 4.6.0
2025-04-19 16:29:18,108:INFO:               numba: 0.61.2
2025-04-19 16:29:18,108:INFO:            requests: 2.31.0
2025-04-19 16:29:18,108:INFO:          matplotlib: 3.7.5
2025-04-19 16:29:18,108:INFO:          scikitplot: 0.3.7
2025-04-19 16:29:18,108:INFO:         yellowbrick: 1.5
2025-04-19 16:29:18,108:INFO:              plotly: 5.24.1
2025-04-19 16:29:18,108:INFO:    plotly-resampler: Not installed
2025-04-19 16:29:18,108:INFO:             kaleido: 0.2.1
2025-04-19 16:29:18,108:INFO:           schemdraw: 0.15
2025-04-19 16:29:18,108:INFO:         statsmodels: 0.14.4
2025-04-19 16:29:18,108:INFO:              sktime: 0.26.0
2025-04-19 16:29:18,108:INFO:               tbats: 1.1.3
2025-04-19 16:29:18,108:INFO:            pmdarima: 2.0.4
2025-04-19 16:29:18,108:INFO:              psutil: 5.9.8
2025-04-19 16:29:18,108:INFO:          markupsafe: 2.1.3
2025-04-19 16:29:18,108:INFO:             pickle5: Not installed
2025-04-19 16:29:18,108:INFO:         cloudpickle: 3.1.1
2025-04-19 16:29:18,108:INFO:         deprecation: 2.1.0
2025-04-19 16:29:18,108:INFO:              xxhash: 3.5.0
2025-04-19 16:29:18,109:INFO:           wurlitzer: Not installed
2025-04-19 16:29:18,109:INFO:PyCaret optional dependencies:
2025-04-19 16:29:18,122:INFO:                shap: Not installed
2025-04-19 16:29:18,122:INFO:           interpret: Not installed
2025-04-19 16:29:18,122:INFO:                umap: Not installed
2025-04-19 16:29:18,123:INFO:     ydata_profiling: Not installed
2025-04-19 16:29:18,123:INFO:  explainerdashboard: Not installed
2025-04-19 16:29:18,123:INFO:             autoviz: Not installed
2025-04-19 16:29:18,123:INFO:           fairlearn: Not installed
2025-04-19 16:29:18,123:INFO:          deepchecks: Not installed
2025-04-19 16:29:18,123:INFO:             xgboost: Not installed
2025-04-19 16:29:18,123:INFO:            catboost: Not installed
2025-04-19 16:29:18,123:INFO:              kmodes: Not installed
2025-04-19 16:29:18,123:INFO:             mlxtend: 0.23.4
2025-04-19 16:29:18,123:INFO:       statsforecast: Not installed
2025-04-19 16:29:18,123:INFO:        tune_sklearn: Not installed
2025-04-19 16:29:18,123:INFO:                 ray: Not installed
2025-04-19 16:29:18,123:INFO:            hyperopt: Not installed
2025-04-19 16:29:18,123:INFO:              optuna: Not installed
2025-04-19 16:29:18,123:INFO:               skopt: Not installed
2025-04-19 16:29:18,123:INFO:              mlflow: Not installed
2025-04-19 16:29:18,123:INFO:              gradio: Not installed
2025-04-19 16:29:18,123:INFO:             fastapi: Not installed
2025-04-19 16:29:18,123:INFO:             uvicorn: Not installed
2025-04-19 16:29:18,123:INFO:              m2cgen: Not installed
2025-04-19 16:29:18,123:INFO:           evidently: Not installed
2025-04-19 16:29:18,123:INFO:               fugue: Not installed
2025-04-19 16:29:18,123:INFO:           streamlit: Not installed
2025-04-19 16:29:18,123:INFO:             prophet: Not installed
2025-04-19 16:29:18,123:INFO:None
2025-04-19 16:29:18,123:INFO:Set up data.
2025-04-19 16:29:18,138:INFO:Set up folding strategy.
2025-04-19 16:29:18,138:INFO:Set up train/test split.
2025-04-19 16:29:18,159:INFO:Set up index.
2025-04-19 16:29:18,160:INFO:Assigning column types.
2025-04-19 16:29:18,172:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 16:29:18,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,282:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 16:29:18,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 16:29:18,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,428:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 16:29:18,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:18,557:INFO:Preparing preprocessing pipeline...
2025-04-19 16:29:18,559:INFO:Set up simple imputation.
2025-04-19 16:29:18,565:INFO:Set up encoding of ordinal features.
2025-04-19 16:29:18,574:INFO:Set up encoding of categorical features.
2025-04-19 16:29:18,722:INFO:Finished creating preprocessing pipeline.
2025-04-19 16:29:18,750:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 1.0    0
2.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-19 16:29:18,750:INFO:Creating final display dataframe.
2025-04-19 16:29:19,113:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        1bd7
2025-04-19 16:29:19,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:19,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:19,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:19,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 16:29:19,280:INFO:setup() successfully completed in 1.35s...............
2025-04-19 16:31:44,277:INFO:Initializing compare_models()
2025-04-19 16:31:44,278:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-19 16:31:44,278:INFO:Checking exceptions
2025-04-19 16:31:44,289:INFO:Preparing display monitor
2025-04-19 16:31:44,312:INFO:Initializing Logistic Regression
2025-04-19 16:31:44,312:INFO:Total runtime is 0.0 minutes
2025-04-19 16:31:44,317:INFO:SubProcess create_model() called ==================================
2025-04-19 16:31:44,318:INFO:Initializing create_model()
2025-04-19 16:31:44,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:31:44,318:INFO:Checking exceptions
2025-04-19 16:31:44,318:INFO:Importing libraries
2025-04-19 16:31:44,318:INFO:Copying training dataset
2025-04-19 16:31:44,343:INFO:Defining folds
2025-04-19 16:31:44,343:INFO:Declaring metric variables
2025-04-19 16:31:44,351:INFO:Importing untrained model
2025-04-19 16:31:44,354:INFO:Logistic Regression Imported successfully
2025-04-19 16:31:44,361:INFO:Starting cross validation
2025-04-19 16:31:44,362:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:31:52,985:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 16:31:53,048:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 16:31:53,061:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 16:31:53,130:INFO:Calculating mean and std
2025-04-19 16:31:53,132:INFO:Creating metrics dataframe
2025-04-19 16:31:53,135:INFO:Uploading results into container
2025-04-19 16:31:53,135:INFO:Uploading model into container now
2025-04-19 16:31:53,137:INFO:_master_model_container: 1
2025-04-19 16:31:53,137:INFO:_display_container: 2
2025-04-19 16:31:53,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 16:31:53,138:INFO:create_model() successfully completed......................................
2025-04-19 16:31:53,735:INFO:SubProcess create_model() end ==================================
2025-04-19 16:31:53,735:INFO:Creating metrics dataframe
2025-04-19 16:31:53,743:INFO:Initializing K Neighbors Classifier
2025-04-19 16:31:53,743:INFO:Total runtime is 0.1571771542231242 minutes
2025-04-19 16:31:53,748:INFO:SubProcess create_model() called ==================================
2025-04-19 16:31:53,748:INFO:Initializing create_model()
2025-04-19 16:31:53,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:31:53,748:INFO:Checking exceptions
2025-04-19 16:31:53,748:INFO:Importing libraries
2025-04-19 16:31:53,748:INFO:Copying training dataset
2025-04-19 16:31:53,773:INFO:Defining folds
2025-04-19 16:31:53,773:INFO:Declaring metric variables
2025-04-19 16:31:53,777:INFO:Importing untrained model
2025-04-19 16:31:53,785:INFO:K Neighbors Classifier Imported successfully
2025-04-19 16:31:53,792:INFO:Starting cross validation
2025-04-19 16:31:53,794:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:31:58,812:INFO:Calculating mean and std
2025-04-19 16:31:58,814:INFO:Creating metrics dataframe
2025-04-19 16:31:58,816:INFO:Uploading results into container
2025-04-19 16:31:58,817:INFO:Uploading model into container now
2025-04-19 16:31:58,818:INFO:_master_model_container: 2
2025-04-19 16:31:58,818:INFO:_display_container: 2
2025-04-19 16:31:58,818:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 16:31:58,818:INFO:create_model() successfully completed......................................
2025-04-19 16:31:59,181:INFO:SubProcess create_model() end ==================================
2025-04-19 16:31:59,182:INFO:Creating metrics dataframe
2025-04-19 16:31:59,187:INFO:Initializing Naive Bayes
2025-04-19 16:31:59,187:INFO:Total runtime is 0.24790740013122559 minutes
2025-04-19 16:31:59,190:INFO:SubProcess create_model() called ==================================
2025-04-19 16:31:59,190:INFO:Initializing create_model()
2025-04-19 16:31:59,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:31:59,190:INFO:Checking exceptions
2025-04-19 16:31:59,190:INFO:Importing libraries
2025-04-19 16:31:59,190:INFO:Copying training dataset
2025-04-19 16:31:59,212:INFO:Defining folds
2025-04-19 16:31:59,212:INFO:Declaring metric variables
2025-04-19 16:31:59,216:INFO:Importing untrained model
2025-04-19 16:31:59,221:INFO:Naive Bayes Imported successfully
2025-04-19 16:31:59,231:INFO:Starting cross validation
2025-04-19 16:31:59,233:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:03,272:INFO:Calculating mean and std
2025-04-19 16:32:03,273:INFO:Creating metrics dataframe
2025-04-19 16:32:03,275:INFO:Uploading results into container
2025-04-19 16:32:03,276:INFO:Uploading model into container now
2025-04-19 16:32:03,278:INFO:_master_model_container: 3
2025-04-19 16:32:03,278:INFO:_display_container: 2
2025-04-19 16:32:03,279:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 16:32:03,279:INFO:create_model() successfully completed......................................
2025-04-19 16:32:03,650:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:03,650:INFO:Creating metrics dataframe
2025-04-19 16:32:03,659:INFO:Initializing Decision Tree Classifier
2025-04-19 16:32:03,659:INFO:Total runtime is 0.3224445303281148 minutes
2025-04-19 16:32:03,663:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:03,664:INFO:Initializing create_model()
2025-04-19 16:32:03,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:03,664:INFO:Checking exceptions
2025-04-19 16:32:03,664:INFO:Importing libraries
2025-04-19 16:32:03,664:INFO:Copying training dataset
2025-04-19 16:32:03,690:INFO:Defining folds
2025-04-19 16:32:03,690:INFO:Declaring metric variables
2025-04-19 16:32:03,694:INFO:Importing untrained model
2025-04-19 16:32:03,698:INFO:Decision Tree Classifier Imported successfully
2025-04-19 16:32:03,707:INFO:Starting cross validation
2025-04-19 16:32:03,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:07,394:INFO:Calculating mean and std
2025-04-19 16:32:07,395:INFO:Creating metrics dataframe
2025-04-19 16:32:07,398:INFO:Uploading results into container
2025-04-19 16:32:07,398:INFO:Uploading model into container now
2025-04-19 16:32:07,398:INFO:_master_model_container: 4
2025-04-19 16:32:07,399:INFO:_display_container: 2
2025-04-19 16:32:07,399:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-19 16:32:07,399:INFO:create_model() successfully completed......................................
2025-04-19 16:32:07,712:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:07,713:INFO:Creating metrics dataframe
2025-04-19 16:32:07,719:INFO:Initializing SVM - Linear Kernel
2025-04-19 16:32:07,719:INFO:Total runtime is 0.39010616540908816 minutes
2025-04-19 16:32:07,722:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:07,723:INFO:Initializing create_model()
2025-04-19 16:32:07,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:07,723:INFO:Checking exceptions
2025-04-19 16:32:07,723:INFO:Importing libraries
2025-04-19 16:32:07,723:INFO:Copying training dataset
2025-04-19 16:32:07,744:INFO:Defining folds
2025-04-19 16:32:07,744:INFO:Declaring metric variables
2025-04-19 16:32:07,748:INFO:Importing untrained model
2025-04-19 16:32:07,752:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 16:32:07,758:INFO:Starting cross validation
2025-04-19 16:32:07,760:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:08,469:INFO:Calculating mean and std
2025-04-19 16:32:08,470:INFO:Creating metrics dataframe
2025-04-19 16:32:08,472:INFO:Uploading results into container
2025-04-19 16:32:08,472:INFO:Uploading model into container now
2025-04-19 16:32:08,473:INFO:_master_model_container: 5
2025-04-19 16:32:08,473:INFO:_display_container: 2
2025-04-19 16:32:08,473:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 16:32:08,474:INFO:create_model() successfully completed......................................
2025-04-19 16:32:08,785:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:08,785:INFO:Creating metrics dataframe
2025-04-19 16:32:08,793:INFO:Initializing Ridge Classifier
2025-04-19 16:32:08,793:INFO:Total runtime is 0.40801016489664715 minutes
2025-04-19 16:32:08,796:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:08,797:INFO:Initializing create_model()
2025-04-19 16:32:08,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:08,797:INFO:Checking exceptions
2025-04-19 16:32:08,797:INFO:Importing libraries
2025-04-19 16:32:08,797:INFO:Copying training dataset
2025-04-19 16:32:08,821:INFO:Defining folds
2025-04-19 16:32:08,821:INFO:Declaring metric variables
2025-04-19 16:32:08,824:INFO:Importing untrained model
2025-04-19 16:32:08,827:INFO:Ridge Classifier Imported successfully
2025-04-19 16:32:08,835:INFO:Starting cross validation
2025-04-19 16:32:08,838:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:09,303:INFO:Calculating mean and std
2025-04-19 16:32:09,305:INFO:Creating metrics dataframe
2025-04-19 16:32:09,307:INFO:Uploading results into container
2025-04-19 16:32:09,308:INFO:Uploading model into container now
2025-04-19 16:32:09,309:INFO:_master_model_container: 6
2025-04-19 16:32:09,309:INFO:_display_container: 2
2025-04-19 16:32:09,310:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 16:32:09,310:INFO:create_model() successfully completed......................................
2025-04-19 16:32:09,624:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:09,624:INFO:Creating metrics dataframe
2025-04-19 16:32:09,632:INFO:Initializing Random Forest Classifier
2025-04-19 16:32:09,632:INFO:Total runtime is 0.42199734846750897 minutes
2025-04-19 16:32:09,635:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:09,637:INFO:Initializing create_model()
2025-04-19 16:32:09,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:09,637:INFO:Checking exceptions
2025-04-19 16:32:09,638:INFO:Importing libraries
2025-04-19 16:32:09,638:INFO:Copying training dataset
2025-04-19 16:32:09,659:INFO:Defining folds
2025-04-19 16:32:09,659:INFO:Declaring metric variables
2025-04-19 16:32:09,663:INFO:Importing untrained model
2025-04-19 16:32:09,666:INFO:Random Forest Classifier Imported successfully
2025-04-19 16:32:09,674:INFO:Starting cross validation
2025-04-19 16:32:09,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:13,175:INFO:Calculating mean and std
2025-04-19 16:32:13,176:INFO:Creating metrics dataframe
2025-04-19 16:32:13,179:INFO:Uploading results into container
2025-04-19 16:32:13,180:INFO:Uploading model into container now
2025-04-19 16:32:13,180:INFO:_master_model_container: 7
2025-04-19 16:32:13,180:INFO:_display_container: 2
2025-04-19 16:32:13,181:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-19 16:32:13,181:INFO:create_model() successfully completed......................................
2025-04-19 16:32:13,595:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:13,596:INFO:Creating metrics dataframe
2025-04-19 16:32:13,605:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 16:32:13,605:INFO:Total runtime is 0.48821397622426355 minutes
2025-04-19 16:32:13,609:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:13,610:INFO:Initializing create_model()
2025-04-19 16:32:13,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:13,610:INFO:Checking exceptions
2025-04-19 16:32:13,610:INFO:Importing libraries
2025-04-19 16:32:13,610:INFO:Copying training dataset
2025-04-19 16:32:13,636:INFO:Defining folds
2025-04-19 16:32:13,636:INFO:Declaring metric variables
2025-04-19 16:32:13,640:INFO:Importing untrained model
2025-04-19 16:32:13,644:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 16:32:13,651:INFO:Starting cross validation
2025-04-19 16:32:13,654:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:13,923:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 16:32:13,923:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 16:32:13,925:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 16:32:14,031:INFO:Calculating mean and std
2025-04-19 16:32:14,032:INFO:Creating metrics dataframe
2025-04-19 16:32:14,034:INFO:Uploading results into container
2025-04-19 16:32:14,035:INFO:Uploading model into container now
2025-04-19 16:32:14,036:INFO:_master_model_container: 8
2025-04-19 16:32:14,036:INFO:_display_container: 2
2025-04-19 16:32:14,036:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 16:32:14,036:INFO:create_model() successfully completed......................................
2025-04-19 16:32:14,414:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:14,414:INFO:Creating metrics dataframe
2025-04-19 16:32:14,422:INFO:Initializing Ada Boost Classifier
2025-04-19 16:32:14,422:INFO:Total runtime is 0.5018245259920756 minutes
2025-04-19 16:32:14,425:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:14,425:INFO:Initializing create_model()
2025-04-19 16:32:14,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:14,425:INFO:Checking exceptions
2025-04-19 16:32:14,425:INFO:Importing libraries
2025-04-19 16:32:14,426:INFO:Copying training dataset
2025-04-19 16:32:14,449:INFO:Defining folds
2025-04-19 16:32:14,449:INFO:Declaring metric variables
2025-04-19 16:32:14,452:INFO:Importing untrained model
2025-04-19 16:32:14,455:INFO:Ada Boost Classifier Imported successfully
2025-04-19 16:32:14,461:INFO:Starting cross validation
2025-04-19 16:32:14,463:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:14,685:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 16:32:14,685:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 16:32:14,703:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 16:32:16,896:INFO:Calculating mean and std
2025-04-19 16:32:16,898:INFO:Creating metrics dataframe
2025-04-19 16:32:16,899:INFO:Uploading results into container
2025-04-19 16:32:16,900:INFO:Uploading model into container now
2025-04-19 16:32:16,900:INFO:_master_model_container: 9
2025-04-19 16:32:16,901:INFO:_display_container: 2
2025-04-19 16:32:16,901:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-19 16:32:16,901:INFO:create_model() successfully completed......................................
2025-04-19 16:32:17,209:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:17,209:INFO:Creating metrics dataframe
2025-04-19 16:32:17,217:INFO:Initializing Gradient Boosting Classifier
2025-04-19 16:32:17,217:INFO:Total runtime is 0.548405933380127 minutes
2025-04-19 16:32:17,221:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:17,221:INFO:Initializing create_model()
2025-04-19 16:32:17,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:17,222:INFO:Checking exceptions
2025-04-19 16:32:17,222:INFO:Importing libraries
2025-04-19 16:32:17,222:INFO:Copying training dataset
2025-04-19 16:32:17,239:INFO:Defining folds
2025-04-19 16:32:17,239:INFO:Declaring metric variables
2025-04-19 16:32:17,241:INFO:Importing untrained model
2025-04-19 16:32:17,244:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 16:32:17,250:INFO:Starting cross validation
2025-04-19 16:32:17,252:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:23,981:INFO:Calculating mean and std
2025-04-19 16:32:23,983:INFO:Creating metrics dataframe
2025-04-19 16:32:23,985:INFO:Uploading results into container
2025-04-19 16:32:23,985:INFO:Uploading model into container now
2025-04-19 16:32:23,986:INFO:_master_model_container: 10
2025-04-19 16:32:23,986:INFO:_display_container: 2
2025-04-19 16:32:23,986:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 16:32:23,986:INFO:create_model() successfully completed......................................
2025-04-19 16:32:24,274:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:24,274:INFO:Creating metrics dataframe
2025-04-19 16:32:24,282:INFO:Initializing Linear Discriminant Analysis
2025-04-19 16:32:24,282:INFO:Total runtime is 0.6661708156267803 minutes
2025-04-19 16:32:24,287:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:24,287:INFO:Initializing create_model()
2025-04-19 16:32:24,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:24,287:INFO:Checking exceptions
2025-04-19 16:32:24,287:INFO:Importing libraries
2025-04-19 16:32:24,287:INFO:Copying training dataset
2025-04-19 16:32:24,303:INFO:Defining folds
2025-04-19 16:32:24,303:INFO:Declaring metric variables
2025-04-19 16:32:24,305:INFO:Importing untrained model
2025-04-19 16:32:24,308:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 16:32:24,315:INFO:Starting cross validation
2025-04-19 16:32:24,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:24,607:INFO:Calculating mean and std
2025-04-19 16:32:24,609:INFO:Creating metrics dataframe
2025-04-19 16:32:24,610:INFO:Uploading results into container
2025-04-19 16:32:24,610:INFO:Uploading model into container now
2025-04-19 16:32:24,611:INFO:_master_model_container: 11
2025-04-19 16:32:24,611:INFO:_display_container: 2
2025-04-19 16:32:24,611:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 16:32:24,611:INFO:create_model() successfully completed......................................
2025-04-19 16:32:24,904:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:24,904:INFO:Creating metrics dataframe
2025-04-19 16:32:24,909:INFO:Initializing Extra Trees Classifier
2025-04-19 16:32:24,910:INFO:Total runtime is 0.6766340255737305 minutes
2025-04-19 16:32:24,912:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:24,912:INFO:Initializing create_model()
2025-04-19 16:32:24,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:24,913:INFO:Checking exceptions
2025-04-19 16:32:24,913:INFO:Importing libraries
2025-04-19 16:32:24,913:INFO:Copying training dataset
2025-04-19 16:32:24,930:INFO:Defining folds
2025-04-19 16:32:24,930:INFO:Declaring metric variables
2025-04-19 16:32:24,933:INFO:Importing untrained model
2025-04-19 16:32:24,935:INFO:Extra Trees Classifier Imported successfully
2025-04-19 16:32:24,940:INFO:Starting cross validation
2025-04-19 16:32:24,942:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:26,510:INFO:Calculating mean and std
2025-04-19 16:32:26,511:INFO:Creating metrics dataframe
2025-04-19 16:32:26,513:INFO:Uploading results into container
2025-04-19 16:32:26,514:INFO:Uploading model into container now
2025-04-19 16:32:26,514:INFO:_master_model_container: 12
2025-04-19 16:32:26,514:INFO:_display_container: 2
2025-04-19 16:32:26,515:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-19 16:32:26,515:INFO:create_model() successfully completed......................................
2025-04-19 16:32:26,872:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:26,872:INFO:Creating metrics dataframe
2025-04-19 16:32:26,880:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 16:32:26,880:INFO:Total runtime is 0.7094664454460144 minutes
2025-04-19 16:32:26,883:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:26,883:INFO:Initializing create_model()
2025-04-19 16:32:26,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:26,883:INFO:Checking exceptions
2025-04-19 16:32:26,883:INFO:Importing libraries
2025-04-19 16:32:26,883:INFO:Copying training dataset
2025-04-19 16:32:26,899:INFO:Defining folds
2025-04-19 16:32:26,899:INFO:Declaring metric variables
2025-04-19 16:32:26,903:INFO:Importing untrained model
2025-04-19 16:32:26,908:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 16:32:26,913:INFO:Starting cross validation
2025-04-19 16:32:26,914:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:27,906:INFO:Calculating mean and std
2025-04-19 16:32:27,908:INFO:Creating metrics dataframe
2025-04-19 16:32:27,910:INFO:Uploading results into container
2025-04-19 16:32:27,910:INFO:Uploading model into container now
2025-04-19 16:32:27,911:INFO:_master_model_container: 13
2025-04-19 16:32:27,911:INFO:_display_container: 2
2025-04-19 16:32:27,912:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 16:32:27,912:INFO:create_model() successfully completed......................................
2025-04-19 16:32:28,365:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:28,365:INFO:Creating metrics dataframe
2025-04-19 16:32:28,374:INFO:Initializing Dummy Classifier
2025-04-19 16:32:28,374:INFO:Total runtime is 0.734358012676239 minutes
2025-04-19 16:32:28,377:INFO:SubProcess create_model() called ==================================
2025-04-19 16:32:28,377:INFO:Initializing create_model()
2025-04-19 16:32:28,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDCD606350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:28,377:INFO:Checking exceptions
2025-04-19 16:32:28,377:INFO:Importing libraries
2025-04-19 16:32:28,377:INFO:Copying training dataset
2025-04-19 16:32:28,401:INFO:Defining folds
2025-04-19 16:32:28,401:INFO:Declaring metric variables
2025-04-19 16:32:28,405:INFO:Importing untrained model
2025-04-19 16:32:28,408:INFO:Dummy Classifier Imported successfully
2025-04-19 16:32:28,416:INFO:Starting cross validation
2025-04-19 16:32:28,417:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 16:32:28,638:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 16:32:28,645:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 16:32:28,655:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 16:32:28,655:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 16:32:28,670:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 16:32:28,680:INFO:Calculating mean and std
2025-04-19 16:32:28,682:INFO:Creating metrics dataframe
2025-04-19 16:32:28,683:INFO:Uploading results into container
2025-04-19 16:32:28,684:INFO:Uploading model into container now
2025-04-19 16:32:28,684:INFO:_master_model_container: 14
2025-04-19 16:32:28,684:INFO:_display_container: 2
2025-04-19 16:32:28,684:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 16:32:28,684:INFO:create_model() successfully completed......................................
2025-04-19 16:32:29,004:INFO:SubProcess create_model() end ==================================
2025-04-19 16:32:29,004:INFO:Creating metrics dataframe
2025-04-19 16:32:29,018:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-19 16:32:29,025:INFO:Initializing create_model()
2025-04-19 16:32:29,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC010F790>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 16:32:29,025:INFO:Checking exceptions
2025-04-19 16:32:29,026:INFO:Importing libraries
2025-04-19 16:32:29,026:INFO:Copying training dataset
2025-04-19 16:32:29,045:INFO:Defining folds
2025-04-19 16:32:29,046:INFO:Declaring metric variables
2025-04-19 16:32:29,046:INFO:Importing untrained model
2025-04-19 16:32:29,046:INFO:Declaring custom model
2025-04-19 16:32:29,046:INFO:Naive Bayes Imported successfully
2025-04-19 16:32:29,047:INFO:Cross validation set to False
2025-04-19 16:32:29,047:INFO:Fitting Model
2025-04-19 16:32:29,155:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 16:32:29,155:INFO:create_model() successfully completed......................................
2025-04-19 16:32:29,490:INFO:_master_model_container: 14
2025-04-19 16:32:29,490:INFO:_display_container: 2
2025-04-19 16:32:29,490:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 16:32:29,490:INFO:compare_models() successfully completed......................................
2025-04-19 17:24:28,880:INFO:PyCaret ClassificationExperiment
2025-04-19 17:24:28,880:INFO:Logging name: clf-default-name
2025-04-19 17:24:28,880:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 17:24:28,880:INFO:version 3.3.2
2025-04-19 17:24:28,880:INFO:Initializing setup()
2025-04-19 17:24:28,880:INFO:self.USI: 6681
2025-04-19 17:24:28,880:INFO:self._variable_keys: {'exp_id', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X', 'y_train', 'data', 'log_plots_param', 'idx', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'memory', 'seed', 'fold_groups_param', 'target_param', '_available_plots', 'fix_imbalance', 'y_test', 'fold_generator', 'n_jobs_param', 'logging_param', 'is_multiclass', 'gpu_param', 'USI', 'X_train', 'fold_shuffle_param'}
2025-04-19 17:24:28,880:INFO:Checking environment
2025-04-19 17:24:28,880:INFO:python_version: 3.11.4
2025-04-19 17:24:28,880:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-19 17:24:28,880:INFO:machine: AMD64
2025-04-19 17:24:28,880:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 17:24:28,891:INFO:Memory: svmem(total=16498810880, available=3232440320, percent=80.4, used=13266370560, free=3232440320)
2025-04-19 17:24:28,891:INFO:Physical Core: 8
2025-04-19 17:24:28,891:INFO:Logical Core: 16
2025-04-19 17:24:28,891:INFO:Checking libraries
2025-04-19 17:24:28,891:INFO:System:
2025-04-19 17:24:28,891:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-19 17:24:28,891:INFO:executable: c:\Python311\python.exe
2025-04-19 17:24:28,891:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 17:24:28,891:INFO:PyCaret required dependencies:
2025-04-19 17:24:28,891:INFO:                 pip: 23.1.2
2025-04-19 17:24:28,892:INFO:          setuptools: 65.5.0
2025-04-19 17:24:28,892:INFO:             pycaret: 3.3.2
2025-04-19 17:24:28,892:INFO:             IPython: 8.20.0
2025-04-19 17:24:28,892:INFO:          ipywidgets: 8.1.6
2025-04-19 17:24:28,892:INFO:                tqdm: 4.66.2
2025-04-19 17:24:28,892:INFO:               numpy: 1.26.2
2025-04-19 17:24:28,892:INFO:              pandas: 2.1.4
2025-04-19 17:24:28,892:INFO:              jinja2: 3.1.2
2025-04-19 17:24:28,892:INFO:               scipy: 1.11.4
2025-04-19 17:24:28,892:INFO:              joblib: 1.3.2
2025-04-19 17:24:28,892:INFO:             sklearn: 1.4.2
2025-04-19 17:24:28,892:INFO:                pyod: 2.0.4
2025-04-19 17:24:28,892:INFO:            imblearn: 0.12.0
2025-04-19 17:24:28,892:INFO:   category_encoders: 2.7.0
2025-04-19 17:24:28,892:INFO:            lightgbm: 4.6.0
2025-04-19 17:24:28,892:INFO:               numba: 0.61.2
2025-04-19 17:24:28,892:INFO:            requests: 2.31.0
2025-04-19 17:24:28,892:INFO:          matplotlib: 3.7.5
2025-04-19 17:24:28,892:INFO:          scikitplot: 0.3.7
2025-04-19 17:24:28,892:INFO:         yellowbrick: 1.5
2025-04-19 17:24:28,893:INFO:              plotly: 5.24.1
2025-04-19 17:24:28,893:INFO:    plotly-resampler: Not installed
2025-04-19 17:24:28,893:INFO:             kaleido: 0.2.1
2025-04-19 17:24:28,893:INFO:           schemdraw: 0.15
2025-04-19 17:24:28,893:INFO:         statsmodels: 0.14.4
2025-04-19 17:24:28,893:INFO:              sktime: 0.26.0
2025-04-19 17:24:28,893:INFO:               tbats: 1.1.3
2025-04-19 17:24:28,893:INFO:            pmdarima: 2.0.4
2025-04-19 17:24:28,893:INFO:              psutil: 5.9.8
2025-04-19 17:24:28,893:INFO:          markupsafe: 2.1.3
2025-04-19 17:24:28,893:INFO:             pickle5: Not installed
2025-04-19 17:24:28,893:INFO:         cloudpickle: 3.1.1
2025-04-19 17:24:28,893:INFO:         deprecation: 2.1.0
2025-04-19 17:24:28,893:INFO:              xxhash: 3.5.0
2025-04-19 17:24:28,893:INFO:           wurlitzer: Not installed
2025-04-19 17:24:28,893:INFO:PyCaret optional dependencies:
2025-04-19 17:24:28,893:INFO:                shap: Not installed
2025-04-19 17:24:28,893:INFO:           interpret: Not installed
2025-04-19 17:24:28,893:INFO:                umap: Not installed
2025-04-19 17:24:28,893:INFO:     ydata_profiling: Not installed
2025-04-19 17:24:28,893:INFO:  explainerdashboard: Not installed
2025-04-19 17:24:28,893:INFO:             autoviz: Not installed
2025-04-19 17:24:28,893:INFO:           fairlearn: Not installed
2025-04-19 17:24:28,893:INFO:          deepchecks: Not installed
2025-04-19 17:24:28,893:INFO:             xgboost: Not installed
2025-04-19 17:24:28,893:INFO:            catboost: Not installed
2025-04-19 17:24:28,893:INFO:              kmodes: Not installed
2025-04-19 17:24:28,893:INFO:             mlxtend: 0.23.4
2025-04-19 17:24:28,894:INFO:       statsforecast: Not installed
2025-04-19 17:24:28,894:INFO:        tune_sklearn: Not installed
2025-04-19 17:24:28,894:INFO:                 ray: Not installed
2025-04-19 17:24:28,894:INFO:            hyperopt: Not installed
2025-04-19 17:24:28,894:INFO:              optuna: Not installed
2025-04-19 17:24:28,894:INFO:               skopt: Not installed
2025-04-19 17:24:28,894:INFO:              mlflow: Not installed
2025-04-19 17:24:28,894:INFO:              gradio: Not installed
2025-04-19 17:24:28,894:INFO:             fastapi: Not installed
2025-04-19 17:24:28,894:INFO:             uvicorn: Not installed
2025-04-19 17:24:28,894:INFO:              m2cgen: Not installed
2025-04-19 17:24:28,894:INFO:           evidently: Not installed
2025-04-19 17:24:28,894:INFO:               fugue: Not installed
2025-04-19 17:24:28,894:INFO:           streamlit: Not installed
2025-04-19 17:24:28,894:INFO:             prophet: Not installed
2025-04-19 17:24:28,894:INFO:None
2025-04-19 17:24:28,894:INFO:Set up data.
2025-04-19 17:24:28,902:INFO:Set up folding strategy.
2025-04-19 17:24:28,902:INFO:Set up train/test split.
2025-04-19 17:24:28,915:INFO:Set up index.
2025-04-19 17:24:28,916:INFO:Assigning column types.
2025-04-19 17:24:28,923:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 17:24:28,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 17:24:28,960:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 17:24:28,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:28,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 17:24:29,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 17:24:29,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,040:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 17:24:29,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 17:24:29,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,134:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 17:24:29,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,156:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 17:24:29,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:29,275:INFO:Preparing preprocessing pipeline...
2025-04-19 17:24:29,277:INFO:Set up simple imputation.
2025-04-19 17:24:29,277:INFO:Set up imbalanced handling.
2025-04-19 17:24:29,277:INFO:Set up feature normalization.
2025-04-19 17:24:32,108:INFO:Finished creating preprocessing pipeline.
2025-04-19 17:24:32,113:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status', 'Momentum',
                                             'momentum_stability_flag',
                                             'risk_index_1_log',
                                             'low_repayment_months_log',
                                             'momentum_recent_mean_inte...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-19 17:24:32,113:INFO:Creating final display dataframe.
2025-04-19 17:24:34,900:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 13)
4        Transformed data shape                 (40445, 13)
5   Transformed train set shape                 (31696, 13)
6    Transformed test set shape                  (8749, 13)
7              Numeric features                          12
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name            clf-default-name
22                          USI                        6681
2025-04-19 17:24:34,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:34,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:35,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:35,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 17:24:35,025:INFO:setup() successfully completed in 6.16s...............
2025-04-19 17:24:35,025:INFO:Initializing compare_models()
2025-04-19 17:24:35,025:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-19 17:24:35,025:INFO:Checking exceptions
2025-04-19 17:24:35,031:INFO:Preparing display monitor
2025-04-19 17:24:35,048:INFO:Initializing Logistic Regression
2025-04-19 17:24:35,048:INFO:Total runtime is 0.0 minutes
2025-04-19 17:24:35,050:INFO:SubProcess create_model() called ==================================
2025-04-19 17:24:35,051:INFO:Initializing create_model()
2025-04-19 17:24:35,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:24:35,051:INFO:Checking exceptions
2025-04-19 17:24:35,051:INFO:Importing libraries
2025-04-19 17:24:35,051:INFO:Copying training dataset
2025-04-19 17:24:35,061:INFO:Defining folds
2025-04-19 17:24:35,062:INFO:Declaring metric variables
2025-04-19 17:24:35,064:INFO:Importing untrained model
2025-04-19 17:24:35,067:INFO:Logistic Regression Imported successfully
2025-04-19 17:24:35,072:INFO:Starting cross validation
2025-04-19 17:24:35,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:24:42,291:INFO:Calculating mean and std
2025-04-19 17:24:42,292:INFO:Creating metrics dataframe
2025-04-19 17:24:42,295:INFO:Uploading results into container
2025-04-19 17:24:42,295:INFO:Uploading model into container now
2025-04-19 17:24:42,296:INFO:_master_model_container: 1
2025-04-19 17:24:42,296:INFO:_display_container: 2
2025-04-19 17:24:42,296:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 17:24:42,296:INFO:create_model() successfully completed......................................
2025-04-19 17:24:42,698:INFO:SubProcess create_model() end ==================================
2025-04-19 17:24:42,698:INFO:Creating metrics dataframe
2025-04-19 17:24:42,702:INFO:Initializing K Neighbors Classifier
2025-04-19 17:24:42,702:INFO:Total runtime is 0.12758065462112428 minutes
2025-04-19 17:24:42,706:INFO:SubProcess create_model() called ==================================
2025-04-19 17:24:42,706:INFO:Initializing create_model()
2025-04-19 17:24:42,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:24:42,706:INFO:Checking exceptions
2025-04-19 17:24:42,706:INFO:Importing libraries
2025-04-19 17:24:42,706:INFO:Copying training dataset
2025-04-19 17:24:42,718:INFO:Defining folds
2025-04-19 17:24:42,718:INFO:Declaring metric variables
2025-04-19 17:24:42,721:INFO:Importing untrained model
2025-04-19 17:24:42,723:INFO:K Neighbors Classifier Imported successfully
2025-04-19 17:24:42,729:INFO:Starting cross validation
2025-04-19 17:24:42,730:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:24:49,993:INFO:Calculating mean and std
2025-04-19 17:24:49,994:INFO:Creating metrics dataframe
2025-04-19 17:24:49,996:INFO:Uploading results into container
2025-04-19 17:24:49,996:INFO:Uploading model into container now
2025-04-19 17:24:49,996:INFO:_master_model_container: 2
2025-04-19 17:24:49,996:INFO:_display_container: 2
2025-04-19 17:24:49,997:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 17:24:49,997:INFO:create_model() successfully completed......................................
2025-04-19 17:24:50,281:INFO:SubProcess create_model() end ==================================
2025-04-19 17:24:50,281:INFO:Creating metrics dataframe
2025-04-19 17:24:50,286:INFO:Initializing Naive Bayes
2025-04-19 17:24:50,286:INFO:Total runtime is 0.2539675235748291 minutes
2025-04-19 17:24:50,288:INFO:SubProcess create_model() called ==================================
2025-04-19 17:24:50,288:INFO:Initializing create_model()
2025-04-19 17:24:50,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:24:50,288:INFO:Checking exceptions
2025-04-19 17:24:50,289:INFO:Importing libraries
2025-04-19 17:24:50,289:INFO:Copying training dataset
2025-04-19 17:24:50,299:INFO:Defining folds
2025-04-19 17:24:50,299:INFO:Declaring metric variables
2025-04-19 17:24:50,303:INFO:Importing untrained model
2025-04-19 17:24:50,305:INFO:Naive Bayes Imported successfully
2025-04-19 17:24:50,310:INFO:Starting cross validation
2025-04-19 17:24:50,312:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:24:55,767:INFO:Calculating mean and std
2025-04-19 17:24:55,768:INFO:Creating metrics dataframe
2025-04-19 17:24:55,770:INFO:Uploading results into container
2025-04-19 17:24:55,771:INFO:Uploading model into container now
2025-04-19 17:24:55,772:INFO:_master_model_container: 3
2025-04-19 17:24:55,772:INFO:_display_container: 2
2025-04-19 17:24:55,772:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 17:24:55,772:INFO:create_model() successfully completed......................................
2025-04-19 17:24:56,059:INFO:SubProcess create_model() end ==================================
2025-04-19 17:24:56,059:INFO:Creating metrics dataframe
2025-04-19 17:24:56,065:INFO:Initializing Decision Tree Classifier
2025-04-19 17:24:56,065:INFO:Total runtime is 0.3502948085467021 minutes
2025-04-19 17:24:56,068:INFO:SubProcess create_model() called ==================================
2025-04-19 17:24:56,068:INFO:Initializing create_model()
2025-04-19 17:24:56,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:24:56,068:INFO:Checking exceptions
2025-04-19 17:24:56,068:INFO:Importing libraries
2025-04-19 17:24:56,068:INFO:Copying training dataset
2025-04-19 17:24:56,081:INFO:Defining folds
2025-04-19 17:24:56,081:INFO:Declaring metric variables
2025-04-19 17:24:56,084:INFO:Importing untrained model
2025-04-19 17:24:56,087:INFO:Decision Tree Classifier Imported successfully
2025-04-19 17:24:56,091:INFO:Starting cross validation
2025-04-19 17:24:56,092:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:00,727:INFO:Calculating mean and std
2025-04-19 17:25:00,728:INFO:Creating metrics dataframe
2025-04-19 17:25:00,730:INFO:Uploading results into container
2025-04-19 17:25:00,731:INFO:Uploading model into container now
2025-04-19 17:25:00,731:INFO:_master_model_container: 4
2025-04-19 17:25:00,731:INFO:_display_container: 2
2025-04-19 17:25:00,732:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-19 17:25:00,732:INFO:create_model() successfully completed......................................
2025-04-19 17:25:01,001:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:01,001:INFO:Creating metrics dataframe
2025-04-19 17:25:01,007:INFO:Initializing SVM - Linear Kernel
2025-04-19 17:25:01,007:INFO:Total runtime is 0.4326521436373393 minutes
2025-04-19 17:25:01,010:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:01,010:INFO:Initializing create_model()
2025-04-19 17:25:01,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:01,011:INFO:Checking exceptions
2025-04-19 17:25:01,011:INFO:Importing libraries
2025-04-19 17:25:01,011:INFO:Copying training dataset
2025-04-19 17:25:01,021:INFO:Defining folds
2025-04-19 17:25:01,021:INFO:Declaring metric variables
2025-04-19 17:25:01,024:INFO:Importing untrained model
2025-04-19 17:25:01,028:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 17:25:01,033:INFO:Starting cross validation
2025-04-19 17:25:01,034:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:03,720:INFO:Calculating mean and std
2025-04-19 17:25:03,722:INFO:Creating metrics dataframe
2025-04-19 17:25:03,723:INFO:Uploading results into container
2025-04-19 17:25:03,724:INFO:Uploading model into container now
2025-04-19 17:25:03,724:INFO:_master_model_container: 5
2025-04-19 17:25:03,724:INFO:_display_container: 2
2025-04-19 17:25:03,725:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 17:25:03,725:INFO:create_model() successfully completed......................................
2025-04-19 17:25:03,997:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:03,997:INFO:Creating metrics dataframe
2025-04-19 17:25:04,003:INFO:Initializing Ridge Classifier
2025-04-19 17:25:04,003:INFO:Total runtime is 0.4825886925061544 minutes
2025-04-19 17:25:04,006:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:04,006:INFO:Initializing create_model()
2025-04-19 17:25:04,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:04,006:INFO:Checking exceptions
2025-04-19 17:25:04,006:INFO:Importing libraries
2025-04-19 17:25:04,006:INFO:Copying training dataset
2025-04-19 17:25:04,016:INFO:Defining folds
2025-04-19 17:25:04,016:INFO:Declaring metric variables
2025-04-19 17:25:04,019:INFO:Importing untrained model
2025-04-19 17:25:04,022:INFO:Ridge Classifier Imported successfully
2025-04-19 17:25:04,026:INFO:Starting cross validation
2025-04-19 17:25:04,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:06,734:INFO:Calculating mean and std
2025-04-19 17:25:06,736:INFO:Creating metrics dataframe
2025-04-19 17:25:06,737:INFO:Uploading results into container
2025-04-19 17:25:06,738:INFO:Uploading model into container now
2025-04-19 17:25:06,738:INFO:_master_model_container: 6
2025-04-19 17:25:06,738:INFO:_display_container: 2
2025-04-19 17:25:06,739:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 17:25:06,739:INFO:create_model() successfully completed......................................
2025-04-19 17:25:07,016:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:07,016:INFO:Creating metrics dataframe
2025-04-19 17:25:07,022:INFO:Initializing Random Forest Classifier
2025-04-19 17:25:07,022:INFO:Total runtime is 0.5329081336657207 minutes
2025-04-19 17:25:07,024:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:07,025:INFO:Initializing create_model()
2025-04-19 17:25:07,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:07,025:INFO:Checking exceptions
2025-04-19 17:25:07,025:INFO:Importing libraries
2025-04-19 17:25:07,025:INFO:Copying training dataset
2025-04-19 17:25:07,035:INFO:Defining folds
2025-04-19 17:25:07,035:INFO:Declaring metric variables
2025-04-19 17:25:07,038:INFO:Importing untrained model
2025-04-19 17:25:07,042:INFO:Random Forest Classifier Imported successfully
2025-04-19 17:25:07,047:INFO:Starting cross validation
2025-04-19 17:25:07,048:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:10,310:INFO:Calculating mean and std
2025-04-19 17:25:10,311:INFO:Creating metrics dataframe
2025-04-19 17:25:10,313:INFO:Uploading results into container
2025-04-19 17:25:10,313:INFO:Uploading model into container now
2025-04-19 17:25:10,314:INFO:_master_model_container: 7
2025-04-19 17:25:10,314:INFO:_display_container: 2
2025-04-19 17:25:10,314:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-19 17:25:10,314:INFO:create_model() successfully completed......................................
2025-04-19 17:25:10,620:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:10,620:INFO:Creating metrics dataframe
2025-04-19 17:25:10,626:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 17:25:10,626:INFO:Total runtime is 0.5929661512374879 minutes
2025-04-19 17:25:10,629:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:10,629:INFO:Initializing create_model()
2025-04-19 17:25:10,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:10,629:INFO:Checking exceptions
2025-04-19 17:25:10,630:INFO:Importing libraries
2025-04-19 17:25:10,630:INFO:Copying training dataset
2025-04-19 17:25:10,641:INFO:Defining folds
2025-04-19 17:25:10,641:INFO:Declaring metric variables
2025-04-19 17:25:10,644:INFO:Importing untrained model
2025-04-19 17:25:10,647:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 17:25:10,652:INFO:Starting cross validation
2025-04-19 17:25:10,653:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:13,719:INFO:Calculating mean and std
2025-04-19 17:25:13,720:INFO:Creating metrics dataframe
2025-04-19 17:25:13,722:INFO:Uploading results into container
2025-04-19 17:25:13,722:INFO:Uploading model into container now
2025-04-19 17:25:13,722:INFO:_master_model_container: 8
2025-04-19 17:25:13,723:INFO:_display_container: 2
2025-04-19 17:25:13,723:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 17:25:13,723:INFO:create_model() successfully completed......................................
2025-04-19 17:25:13,995:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:13,995:INFO:Creating metrics dataframe
2025-04-19 17:25:14,002:INFO:Initializing Ada Boost Classifier
2025-04-19 17:25:14,002:INFO:Total runtime is 0.6492377241452536 minutes
2025-04-19 17:25:14,004:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:14,004:INFO:Initializing create_model()
2025-04-19 17:25:14,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:14,005:INFO:Checking exceptions
2025-04-19 17:25:14,005:INFO:Importing libraries
2025-04-19 17:25:14,005:INFO:Copying training dataset
2025-04-19 17:25:14,015:INFO:Defining folds
2025-04-19 17:25:14,015:INFO:Declaring metric variables
2025-04-19 17:25:14,018:INFO:Importing untrained model
2025-04-19 17:25:14,020:INFO:Ada Boost Classifier Imported successfully
2025-04-19 17:25:14,026:INFO:Starting cross validation
2025-04-19 17:25:14,027:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:16,515:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 17:25:16,535:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 17:25:16,568:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 17:25:16,638:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 17:25:16,726:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 17:25:17,294:INFO:Calculating mean and std
2025-04-19 17:25:17,295:INFO:Creating metrics dataframe
2025-04-19 17:25:17,297:INFO:Uploading results into container
2025-04-19 17:25:17,297:INFO:Uploading model into container now
2025-04-19 17:25:17,297:INFO:_master_model_container: 9
2025-04-19 17:25:17,297:INFO:_display_container: 2
2025-04-19 17:25:17,297:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-19 17:25:17,299:INFO:create_model() successfully completed......................................
2025-04-19 17:25:17,569:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:17,569:INFO:Creating metrics dataframe
2025-04-19 17:25:17,575:INFO:Initializing Gradient Boosting Classifier
2025-04-19 17:25:17,575:INFO:Total runtime is 0.7087905287742616 minutes
2025-04-19 17:25:17,578:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:17,578:INFO:Initializing create_model()
2025-04-19 17:25:17,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:17,578:INFO:Checking exceptions
2025-04-19 17:25:17,578:INFO:Importing libraries
2025-04-19 17:25:17,578:INFO:Copying training dataset
2025-04-19 17:25:17,589:INFO:Defining folds
2025-04-19 17:25:17,589:INFO:Declaring metric variables
2025-04-19 17:25:17,592:INFO:Importing untrained model
2025-04-19 17:25:17,594:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 17:25:17,600:INFO:Starting cross validation
2025-04-19 17:25:17,601:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:21,525:INFO:Calculating mean and std
2025-04-19 17:25:21,526:INFO:Creating metrics dataframe
2025-04-19 17:25:21,527:INFO:Uploading results into container
2025-04-19 17:25:21,528:INFO:Uploading model into container now
2025-04-19 17:25:21,528:INFO:_master_model_container: 10
2025-04-19 17:25:21,528:INFO:_display_container: 2
2025-04-19 17:25:21,528:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 17:25:21,529:INFO:create_model() successfully completed......................................
2025-04-19 17:25:21,791:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:21,791:INFO:Creating metrics dataframe
2025-04-19 17:25:21,798:INFO:Initializing Linear Discriminant Analysis
2025-04-19 17:25:21,798:INFO:Total runtime is 0.7791672428448997 minutes
2025-04-19 17:25:21,800:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:21,800:INFO:Initializing create_model()
2025-04-19 17:25:21,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:21,800:INFO:Checking exceptions
2025-04-19 17:25:21,800:INFO:Importing libraries
2025-04-19 17:25:21,800:INFO:Copying training dataset
2025-04-19 17:25:21,811:INFO:Defining folds
2025-04-19 17:25:21,811:INFO:Declaring metric variables
2025-04-19 17:25:21,813:INFO:Importing untrained model
2025-04-19 17:25:21,816:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 17:25:21,820:INFO:Starting cross validation
2025-04-19 17:25:21,822:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:24,473:INFO:Calculating mean and std
2025-04-19 17:25:24,474:INFO:Creating metrics dataframe
2025-04-19 17:25:24,475:INFO:Uploading results into container
2025-04-19 17:25:24,476:INFO:Uploading model into container now
2025-04-19 17:25:24,476:INFO:_master_model_container: 11
2025-04-19 17:25:24,476:INFO:_display_container: 2
2025-04-19 17:25:24,477:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 17:25:24,477:INFO:create_model() successfully completed......................................
2025-04-19 17:25:24,740:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:24,740:INFO:Creating metrics dataframe
2025-04-19 17:25:24,747:INFO:Initializing Extra Trees Classifier
2025-04-19 17:25:24,747:INFO:Total runtime is 0.8283185799916587 minutes
2025-04-19 17:25:24,749:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:24,749:INFO:Initializing create_model()
2025-04-19 17:25:24,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:24,750:INFO:Checking exceptions
2025-04-19 17:25:24,750:INFO:Importing libraries
2025-04-19 17:25:24,750:INFO:Copying training dataset
2025-04-19 17:25:24,760:INFO:Defining folds
2025-04-19 17:25:24,760:INFO:Declaring metric variables
2025-04-19 17:25:24,763:INFO:Importing untrained model
2025-04-19 17:25:24,767:INFO:Extra Trees Classifier Imported successfully
2025-04-19 17:25:24,772:INFO:Starting cross validation
2025-04-19 17:25:24,773:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:27,816:INFO:Calculating mean and std
2025-04-19 17:25:27,818:INFO:Creating metrics dataframe
2025-04-19 17:25:27,819:INFO:Uploading results into container
2025-04-19 17:25:27,820:INFO:Uploading model into container now
2025-04-19 17:25:27,820:INFO:_master_model_container: 12
2025-04-19 17:25:27,820:INFO:_display_container: 2
2025-04-19 17:25:27,821:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-19 17:25:27,821:INFO:create_model() successfully completed......................................
2025-04-19 17:25:28,089:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:28,089:INFO:Creating metrics dataframe
2025-04-19 17:25:28,097:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 17:25:28,097:INFO:Total runtime is 0.8841530044873557 minutes
2025-04-19 17:25:28,099:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:28,100:INFO:Initializing create_model()
2025-04-19 17:25:28,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:28,100:INFO:Checking exceptions
2025-04-19 17:25:28,100:INFO:Importing libraries
2025-04-19 17:25:28,100:INFO:Copying training dataset
2025-04-19 17:25:28,109:INFO:Defining folds
2025-04-19 17:25:28,109:INFO:Declaring metric variables
2025-04-19 17:25:28,113:INFO:Importing untrained model
2025-04-19 17:25:28,115:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 17:25:28,120:INFO:Starting cross validation
2025-04-19 17:25:28,121:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:31,322:INFO:Calculating mean and std
2025-04-19 17:25:31,323:INFO:Creating metrics dataframe
2025-04-19 17:25:31,326:INFO:Uploading results into container
2025-04-19 17:25:31,327:INFO:Uploading model into container now
2025-04-19 17:25:31,327:INFO:_master_model_container: 13
2025-04-19 17:25:31,327:INFO:_display_container: 2
2025-04-19 17:25:31,328:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 17:25:31,328:INFO:create_model() successfully completed......................................
2025-04-19 17:25:31,609:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:31,609:INFO:Creating metrics dataframe
2025-04-19 17:25:31,616:INFO:Initializing Dummy Classifier
2025-04-19 17:25:31,616:INFO:Total runtime is 0.9428080995877585 minutes
2025-04-19 17:25:31,619:INFO:SubProcess create_model() called ==================================
2025-04-19 17:25:31,619:INFO:Initializing create_model()
2025-04-19 17:25:31,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD0ADD250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:31,619:INFO:Checking exceptions
2025-04-19 17:25:31,619:INFO:Importing libraries
2025-04-19 17:25:31,619:INFO:Copying training dataset
2025-04-19 17:25:31,630:INFO:Defining folds
2025-04-19 17:25:31,630:INFO:Declaring metric variables
2025-04-19 17:25:31,633:INFO:Importing untrained model
2025-04-19 17:25:31,636:INFO:Dummy Classifier Imported successfully
2025-04-19 17:25:31,641:INFO:Starting cross validation
2025-04-19 17:25:31,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 17:25:33,998:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 17:25:34,104:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 17:25:34,124:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 17:25:34,150:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 17:25:34,161:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 17:25:34,171:INFO:Calculating mean and std
2025-04-19 17:25:34,172:INFO:Creating metrics dataframe
2025-04-19 17:25:34,174:INFO:Uploading results into container
2025-04-19 17:25:34,174:INFO:Uploading model into container now
2025-04-19 17:25:34,174:INFO:_master_model_container: 14
2025-04-19 17:25:34,174:INFO:_display_container: 2
2025-04-19 17:25:34,175:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 17:25:34,175:INFO:create_model() successfully completed......................................
2025-04-19 17:25:34,433:INFO:SubProcess create_model() end ==================================
2025-04-19 17:25:34,433:INFO:Creating metrics dataframe
2025-04-19 17:25:34,441:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-19 17:25:34,448:INFO:Initializing create_model()
2025-04-19 17:25:34,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:25:34,448:INFO:Checking exceptions
2025-04-19 17:25:34,450:INFO:Importing libraries
2025-04-19 17:25:34,450:INFO:Copying training dataset
2025-04-19 17:25:34,459:INFO:Defining folds
2025-04-19 17:25:34,459:INFO:Declaring metric variables
2025-04-19 17:25:34,459:INFO:Importing untrained model
2025-04-19 17:25:34,459:INFO:Declaring custom model
2025-04-19 17:25:34,459:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 17:25:34,460:INFO:Cross validation set to False
2025-04-19 17:25:34,460:INFO:Fitting Model
2025-04-19 17:25:38,284:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 17:25:38,284:INFO:create_model() successfully completed......................................
2025-04-19 17:25:38,576:INFO:_master_model_container: 14
2025-04-19 17:25:38,576:INFO:_display_container: 2
2025-04-19 17:25:38,578:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 17:25:38,578:INFO:compare_models() successfully completed......................................
2025-04-19 17:33:00,978:INFO:Initializing create_model()
2025-04-19 17:33:00,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDCE648190>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 17:33:00,979:INFO:Checking exceptions
2025-04-19 17:33:00,991:INFO:Importing libraries
2025-04-19 17:33:00,992:INFO:Copying training dataset
2025-04-19 17:33:01,005:INFO:Defining folds
2025-04-19 17:33:01,005:INFO:Declaring metric variables
2025-04-19 17:33:01,008:INFO:Importing untrained model
2025-04-19 17:33:01,011:INFO:Ada Boost Classifier Imported successfully
2025-04-19 17:33:01,019:INFO:Starting cross validation
2025-04-19 17:33:01,021:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:33:07,597:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:07,598:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:07,683:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:07,684:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:07,770:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:07,771:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:07,859:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:07,859:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:07,947:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:07,948:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:08,032:WARNING:<ipython-input-229-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:08,033:WARNING:<ipython-input-229-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-19 19:33:46,741:WARNING:<ipython-input-233-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-19 19:33:59,735:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:59,736:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:33:59,922:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:33:59,924:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:34:00,127:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:34:00,130:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:34:00,323:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:34:00,324:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:34:00,506:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:34:00,508:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:34:00,689:WARNING:<ipython-input-234-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-19 19:34:00,691:WARNING:<ipython-input-234-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-19 19:34:05,631:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-19 19:34:06,080:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-19 19:34:06,081:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-19 19:37:08,069:INFO:PyCaret ClassificationExperiment
2025-04-19 19:37:08,069:INFO:Logging name: baseline
2025-04-19 19:37:08,069:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 19:37:08,069:INFO:version 3.3.2
2025-04-19 19:37:08,069:INFO:Initializing setup()
2025-04-19 19:37:08,069:INFO:self.USI: 188c
2025-04-19 19:37:08,069:INFO:self._variable_keys: {'exp_id', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X', 'y_train', 'data', 'log_plots_param', 'idx', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'memory', 'seed', 'fold_groups_param', 'target_param', '_available_plots', 'fix_imbalance', 'y_test', 'fold_generator', 'n_jobs_param', 'logging_param', 'is_multiclass', 'gpu_param', 'USI', 'X_train', 'fold_shuffle_param'}
2025-04-19 19:37:08,069:INFO:Checking environment
2025-04-19 19:37:08,069:INFO:python_version: 3.11.4
2025-04-19 19:37:08,069:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-19 19:37:08,069:INFO:machine: AMD64
2025-04-19 19:37:08,069:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:37:08,078:INFO:Memory: svmem(total=16498810880, available=2077941760, percent=87.4, used=14420869120, free=2077941760)
2025-04-19 19:37:08,078:INFO:Physical Core: 8
2025-04-19 19:37:08,078:INFO:Logical Core: 16
2025-04-19 19:37:08,079:INFO:Checking libraries
2025-04-19 19:37:08,079:INFO:System:
2025-04-19 19:37:08,079:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-19 19:37:08,079:INFO:executable: c:\Python311\python.exe
2025-04-19 19:37:08,079:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:37:08,079:INFO:PyCaret required dependencies:
2025-04-19 19:37:08,079:INFO:                 pip: 23.1.2
2025-04-19 19:37:08,079:INFO:          setuptools: 65.5.0
2025-04-19 19:37:08,079:INFO:             pycaret: 3.3.2
2025-04-19 19:37:08,079:INFO:             IPython: 8.20.0
2025-04-19 19:37:08,079:INFO:          ipywidgets: 8.1.6
2025-04-19 19:37:08,079:INFO:                tqdm: 4.66.2
2025-04-19 19:37:08,079:INFO:               numpy: 1.26.2
2025-04-19 19:37:08,079:INFO:              pandas: 2.1.4
2025-04-19 19:37:08,079:INFO:              jinja2: 3.1.2
2025-04-19 19:37:08,079:INFO:               scipy: 1.11.4
2025-04-19 19:37:08,079:INFO:              joblib: 1.3.2
2025-04-19 19:37:08,079:INFO:             sklearn: 1.4.2
2025-04-19 19:37:08,079:INFO:                pyod: 2.0.4
2025-04-19 19:37:08,079:INFO:            imblearn: 0.12.0
2025-04-19 19:37:08,079:INFO:   category_encoders: 2.7.0
2025-04-19 19:37:08,079:INFO:            lightgbm: 4.6.0
2025-04-19 19:37:08,079:INFO:               numba: 0.61.2
2025-04-19 19:37:08,079:INFO:            requests: 2.31.0
2025-04-19 19:37:08,079:INFO:          matplotlib: 3.7.5
2025-04-19 19:37:08,079:INFO:          scikitplot: 0.3.7
2025-04-19 19:37:08,079:INFO:         yellowbrick: 1.5
2025-04-19 19:37:08,079:INFO:              plotly: 5.24.1
2025-04-19 19:37:08,079:INFO:    plotly-resampler: Not installed
2025-04-19 19:37:08,079:INFO:             kaleido: 0.2.1
2025-04-19 19:37:08,080:INFO:           schemdraw: 0.15
2025-04-19 19:37:08,080:INFO:         statsmodels: 0.14.4
2025-04-19 19:37:08,080:INFO:              sktime: 0.26.0
2025-04-19 19:37:08,080:INFO:               tbats: 1.1.3
2025-04-19 19:37:08,080:INFO:            pmdarima: 2.0.4
2025-04-19 19:37:08,080:INFO:              psutil: 5.9.8
2025-04-19 19:37:08,080:INFO:          markupsafe: 2.1.3
2025-04-19 19:37:08,080:INFO:             pickle5: Not installed
2025-04-19 19:37:08,080:INFO:         cloudpickle: 3.1.1
2025-04-19 19:37:08,080:INFO:         deprecation: 2.1.0
2025-04-19 19:37:08,080:INFO:              xxhash: 3.5.0
2025-04-19 19:37:08,080:INFO:           wurlitzer: Not installed
2025-04-19 19:37:08,080:INFO:PyCaret optional dependencies:
2025-04-19 19:37:08,080:INFO:                shap: Not installed
2025-04-19 19:37:08,080:INFO:           interpret: Not installed
2025-04-19 19:37:08,080:INFO:                umap: Not installed
2025-04-19 19:37:08,080:INFO:     ydata_profiling: Not installed
2025-04-19 19:37:08,080:INFO:  explainerdashboard: Not installed
2025-04-19 19:37:08,080:INFO:             autoviz: Not installed
2025-04-19 19:37:08,080:INFO:           fairlearn: Not installed
2025-04-19 19:37:08,080:INFO:          deepchecks: Not installed
2025-04-19 19:37:08,080:INFO:             xgboost: Not installed
2025-04-19 19:37:08,080:INFO:            catboost: Not installed
2025-04-19 19:37:08,080:INFO:              kmodes: Not installed
2025-04-19 19:37:08,080:INFO:             mlxtend: 0.23.4
2025-04-19 19:37:08,080:INFO:       statsforecast: Not installed
2025-04-19 19:37:08,080:INFO:        tune_sklearn: Not installed
2025-04-19 19:37:08,080:INFO:                 ray: Not installed
2025-04-19 19:37:08,080:INFO:            hyperopt: Not installed
2025-04-19 19:37:08,080:INFO:              optuna: Not installed
2025-04-19 19:37:08,080:INFO:               skopt: Not installed
2025-04-19 19:37:08,080:INFO:              mlflow: Not installed
2025-04-19 19:37:08,080:INFO:              gradio: Not installed
2025-04-19 19:37:08,080:INFO:             fastapi: Not installed
2025-04-19 19:37:08,080:INFO:             uvicorn: Not installed
2025-04-19 19:37:08,080:INFO:              m2cgen: Not installed
2025-04-19 19:37:08,080:INFO:           evidently: Not installed
2025-04-19 19:37:08,080:INFO:               fugue: Not installed
2025-04-19 19:37:08,080:INFO:           streamlit: Not installed
2025-04-19 19:37:08,081:INFO:             prophet: Not installed
2025-04-19 19:37:08,081:INFO:None
2025-04-19 19:37:08,081:INFO:Set up data.
2025-04-19 19:37:08,092:INFO:Set up folding strategy.
2025-04-19 19:37:08,092:INFO:Set up train/test split.
2025-04-19 19:37:08,108:INFO:Set up index.
2025-04-19 19:37:08,109:INFO:Assigning column types.
2025-04-19 19:37:08,121:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:37:08,159:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,160:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:37:08,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,344:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:37:08,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,368:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 19:37:08,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,494:INFO:Preparing preprocessing pipeline...
2025-04-19 19:37:08,497:INFO:Set up simple imputation.
2025-04-19 19:37:08,504:INFO:Set up encoding of ordinal features.
2025-04-19 19:37:08,512:INFO:Set up encoding of categorical features.
2025-04-19 19:37:08,627:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:37:08,653:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-19 19:37:08,653:INFO:Creating final display dataframe.
2025-04-19 19:37:08,919:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        188c
2025-04-19 19:37:08,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:08,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:09,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:09,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:37:09,051:INFO:setup() successfully completed in 1.01s...............
2025-04-19 19:37:22,137:INFO:Initializing compare_models()
2025-04-19 19:37:22,137:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-19 19:37:22,137:INFO:Checking exceptions
2025-04-19 19:37:22,151:INFO:Preparing display monitor
2025-04-19 19:37:22,168:INFO:Initializing Logistic Regression
2025-04-19 19:37:22,168:INFO:Total runtime is 0.0 minutes
2025-04-19 19:37:22,171:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:22,171:INFO:Initializing create_model()
2025-04-19 19:37:22,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:22,171:INFO:Checking exceptions
2025-04-19 19:37:22,171:INFO:Importing libraries
2025-04-19 19:37:22,171:INFO:Copying training dataset
2025-04-19 19:37:22,188:INFO:Defining folds
2025-04-19 19:37:22,188:INFO:Declaring metric variables
2025-04-19 19:37:22,192:INFO:Importing untrained model
2025-04-19 19:37:22,195:INFO:Logistic Regression Imported successfully
2025-04-19 19:37:22,200:INFO:Starting cross validation
2025-04-19 19:37:22,202:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:30,064:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 19:37:30,117:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 19:37:30,193:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 19:37:30,207:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 19:37:30,234:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-19 19:37:30,305:INFO:Calculating mean and std
2025-04-19 19:37:30,308:INFO:Creating metrics dataframe
2025-04-19 19:37:30,310:INFO:Uploading results into container
2025-04-19 19:37:30,313:INFO:Uploading model into container now
2025-04-19 19:37:30,314:INFO:_master_model_container: 1
2025-04-19 19:37:30,314:INFO:_display_container: 2
2025-04-19 19:37:30,315:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 19:37:30,315:INFO:create_model() successfully completed......................................
2025-04-19 19:37:30,897:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:30,897:INFO:Creating metrics dataframe
2025-04-19 19:37:30,902:INFO:Initializing K Neighbors Classifier
2025-04-19 19:37:30,902:INFO:Total runtime is 0.14556576013565065 minutes
2025-04-19 19:37:30,905:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:30,905:INFO:Initializing create_model()
2025-04-19 19:37:30,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:30,905:INFO:Checking exceptions
2025-04-19 19:37:30,905:INFO:Importing libraries
2025-04-19 19:37:30,905:INFO:Copying training dataset
2025-04-19 19:37:30,923:INFO:Defining folds
2025-04-19 19:37:30,923:INFO:Declaring metric variables
2025-04-19 19:37:30,926:INFO:Importing untrained model
2025-04-19 19:37:30,930:INFO:K Neighbors Classifier Imported successfully
2025-04-19 19:37:30,938:INFO:Starting cross validation
2025-04-19 19:37:30,939:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:35,197:INFO:Calculating mean and std
2025-04-19 19:37:35,200:INFO:Creating metrics dataframe
2025-04-19 19:37:35,203:INFO:Uploading results into container
2025-04-19 19:37:35,203:INFO:Uploading model into container now
2025-04-19 19:37:35,204:INFO:_master_model_container: 2
2025-04-19 19:37:35,204:INFO:_display_container: 2
2025-04-19 19:37:35,204:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 19:37:35,205:INFO:create_model() successfully completed......................................
2025-04-19 19:37:35,553:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:35,553:INFO:Creating metrics dataframe
2025-04-19 19:37:35,559:INFO:Initializing Naive Bayes
2025-04-19 19:37:35,559:INFO:Total runtime is 0.22319108247756958 minutes
2025-04-19 19:37:35,561:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:35,561:INFO:Initializing create_model()
2025-04-19 19:37:35,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:35,563:INFO:Checking exceptions
2025-04-19 19:37:35,563:INFO:Importing libraries
2025-04-19 19:37:35,563:INFO:Copying training dataset
2025-04-19 19:37:35,579:INFO:Defining folds
2025-04-19 19:37:35,579:INFO:Declaring metric variables
2025-04-19 19:37:35,582:INFO:Importing untrained model
2025-04-19 19:37:35,585:INFO:Naive Bayes Imported successfully
2025-04-19 19:37:35,596:INFO:Starting cross validation
2025-04-19 19:37:35,598:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:38,150:INFO:Calculating mean and std
2025-04-19 19:37:38,151:INFO:Creating metrics dataframe
2025-04-19 19:37:38,153:INFO:Uploading results into container
2025-04-19 19:37:38,154:INFO:Uploading model into container now
2025-04-19 19:37:38,155:INFO:_master_model_container: 3
2025-04-19 19:37:38,155:INFO:_display_container: 2
2025-04-19 19:37:38,155:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 19:37:38,155:INFO:create_model() successfully completed......................................
2025-04-19 19:37:38,508:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:38,508:INFO:Creating metrics dataframe
2025-04-19 19:37:38,514:INFO:Initializing Decision Tree Classifier
2025-04-19 19:37:38,514:INFO:Total runtime is 0.27243798176447553 minutes
2025-04-19 19:37:38,516:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:38,517:INFO:Initializing create_model()
2025-04-19 19:37:38,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:38,517:INFO:Checking exceptions
2025-04-19 19:37:38,517:INFO:Importing libraries
2025-04-19 19:37:38,517:INFO:Copying training dataset
2025-04-19 19:37:38,533:INFO:Defining folds
2025-04-19 19:37:38,533:INFO:Declaring metric variables
2025-04-19 19:37:38,536:INFO:Importing untrained model
2025-04-19 19:37:38,540:INFO:Decision Tree Classifier Imported successfully
2025-04-19 19:37:38,544:INFO:Starting cross validation
2025-04-19 19:37:38,545:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:41,155:INFO:Calculating mean and std
2025-04-19 19:37:41,156:INFO:Creating metrics dataframe
2025-04-19 19:37:41,158:INFO:Uploading results into container
2025-04-19 19:37:41,158:INFO:Uploading model into container now
2025-04-19 19:37:41,160:INFO:_master_model_container: 4
2025-04-19 19:37:41,160:INFO:_display_container: 2
2025-04-19 19:37:41,160:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-19 19:37:41,160:INFO:create_model() successfully completed......................................
2025-04-19 19:37:41,500:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:41,501:INFO:Creating metrics dataframe
2025-04-19 19:37:41,506:INFO:Initializing SVM - Linear Kernel
2025-04-19 19:37:41,506:INFO:Total runtime is 0.3222976167996725 minutes
2025-04-19 19:37:41,509:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:41,509:INFO:Initializing create_model()
2025-04-19 19:37:41,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:41,509:INFO:Checking exceptions
2025-04-19 19:37:41,509:INFO:Importing libraries
2025-04-19 19:37:41,509:INFO:Copying training dataset
2025-04-19 19:37:41,525:INFO:Defining folds
2025-04-19 19:37:41,525:INFO:Declaring metric variables
2025-04-19 19:37:41,527:INFO:Importing untrained model
2025-04-19 19:37:41,530:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 19:37:41,535:INFO:Starting cross validation
2025-04-19 19:37:41,537:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:42,350:INFO:Calculating mean and std
2025-04-19 19:37:42,351:INFO:Creating metrics dataframe
2025-04-19 19:37:42,352:INFO:Uploading results into container
2025-04-19 19:37:42,353:INFO:Uploading model into container now
2025-04-19 19:37:42,353:INFO:_master_model_container: 5
2025-04-19 19:37:42,354:INFO:_display_container: 2
2025-04-19 19:37:42,354:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 19:37:42,355:INFO:create_model() successfully completed......................................
2025-04-19 19:37:42,721:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:42,721:INFO:Creating metrics dataframe
2025-04-19 19:37:42,727:INFO:Initializing Ridge Classifier
2025-04-19 19:37:42,727:INFO:Total runtime is 0.3426435669263205 minutes
2025-04-19 19:37:42,731:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:42,732:INFO:Initializing create_model()
2025-04-19 19:37:42,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:42,732:INFO:Checking exceptions
2025-04-19 19:37:42,732:INFO:Importing libraries
2025-04-19 19:37:42,732:INFO:Copying training dataset
2025-04-19 19:37:42,757:INFO:Defining folds
2025-04-19 19:37:42,758:INFO:Declaring metric variables
2025-04-19 19:37:42,762:INFO:Importing untrained model
2025-04-19 19:37:42,766:INFO:Ridge Classifier Imported successfully
2025-04-19 19:37:42,772:INFO:Starting cross validation
2025-04-19 19:37:42,775:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:43,082:INFO:Calculating mean and std
2025-04-19 19:37:43,083:INFO:Creating metrics dataframe
2025-04-19 19:37:43,084:INFO:Uploading results into container
2025-04-19 19:37:43,085:INFO:Uploading model into container now
2025-04-19 19:37:43,085:INFO:_master_model_container: 6
2025-04-19 19:37:43,085:INFO:_display_container: 2
2025-04-19 19:37:43,086:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 19:37:43,086:INFO:create_model() successfully completed......................................
2025-04-19 19:37:43,443:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:43,443:INFO:Creating metrics dataframe
2025-04-19 19:37:43,451:INFO:Initializing Random Forest Classifier
2025-04-19 19:37:43,451:INFO:Total runtime is 0.35471840302149465 minutes
2025-04-19 19:37:43,453:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:43,453:INFO:Initializing create_model()
2025-04-19 19:37:43,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:43,454:INFO:Checking exceptions
2025-04-19 19:37:43,454:INFO:Importing libraries
2025-04-19 19:37:43,454:INFO:Copying training dataset
2025-04-19 19:37:43,472:INFO:Defining folds
2025-04-19 19:37:43,472:INFO:Declaring metric variables
2025-04-19 19:37:43,475:INFO:Importing untrained model
2025-04-19 19:37:43,478:INFO:Random Forest Classifier Imported successfully
2025-04-19 19:37:43,485:INFO:Starting cross validation
2025-04-19 19:37:43,486:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:46,435:INFO:Calculating mean and std
2025-04-19 19:37:46,436:INFO:Creating metrics dataframe
2025-04-19 19:37:46,438:INFO:Uploading results into container
2025-04-19 19:37:46,439:INFO:Uploading model into container now
2025-04-19 19:37:46,439:INFO:_master_model_container: 7
2025-04-19 19:37:46,439:INFO:_display_container: 2
2025-04-19 19:37:46,439:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-19 19:37:46,440:INFO:create_model() successfully completed......................................
2025-04-19 19:37:46,912:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:46,913:INFO:Creating metrics dataframe
2025-04-19 19:37:46,920:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 19:37:46,921:INFO:Total runtime is 0.41255331834157316 minutes
2025-04-19 19:37:46,926:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:46,926:INFO:Initializing create_model()
2025-04-19 19:37:46,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:46,926:INFO:Checking exceptions
2025-04-19 19:37:46,927:INFO:Importing libraries
2025-04-19 19:37:46,927:INFO:Copying training dataset
2025-04-19 19:37:46,951:INFO:Defining folds
2025-04-19 19:37:46,951:INFO:Declaring metric variables
2025-04-19 19:37:46,955:INFO:Importing untrained model
2025-04-19 19:37:46,960:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 19:37:46,967:INFO:Starting cross validation
2025-04-19 19:37:46,968:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:47,207:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:37:47,233:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:37:47,233:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:37:47,243:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:37:47,273:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:37:47,355:INFO:Calculating mean and std
2025-04-19 19:37:47,357:INFO:Creating metrics dataframe
2025-04-19 19:37:47,359:INFO:Uploading results into container
2025-04-19 19:37:47,360:INFO:Uploading model into container now
2025-04-19 19:37:47,360:INFO:_master_model_container: 8
2025-04-19 19:37:47,360:INFO:_display_container: 2
2025-04-19 19:37:47,361:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 19:37:47,361:INFO:create_model() successfully completed......................................
2025-04-19 19:37:47,834:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:47,834:INFO:Creating metrics dataframe
2025-04-19 19:37:47,841:INFO:Initializing Ada Boost Classifier
2025-04-19 19:37:47,841:INFO:Total runtime is 0.4278910954793295 minutes
2025-04-19 19:37:47,844:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:47,845:INFO:Initializing create_model()
2025-04-19 19:37:47,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:47,845:INFO:Checking exceptions
2025-04-19 19:37:47,845:INFO:Importing libraries
2025-04-19 19:37:47,845:INFO:Copying training dataset
2025-04-19 19:37:47,864:INFO:Defining folds
2025-04-19 19:37:47,864:INFO:Declaring metric variables
2025-04-19 19:37:47,869:INFO:Importing untrained model
2025-04-19 19:37:47,873:INFO:Ada Boost Classifier Imported successfully
2025-04-19 19:37:47,880:INFO:Starting cross validation
2025-04-19 19:37:47,882:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:48,074:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:37:48,085:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:37:48,095:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:37:48,098:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:37:48,114:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:37:49,999:INFO:Calculating mean and std
2025-04-19 19:37:50,000:INFO:Creating metrics dataframe
2025-04-19 19:37:50,001:INFO:Uploading results into container
2025-04-19 19:37:50,002:INFO:Uploading model into container now
2025-04-19 19:37:50,002:INFO:_master_model_container: 9
2025-04-19 19:37:50,002:INFO:_display_container: 2
2025-04-19 19:37:50,003:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-19 19:37:50,003:INFO:create_model() successfully completed......................................
2025-04-19 19:37:50,355:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:50,356:INFO:Creating metrics dataframe
2025-04-19 19:37:50,363:INFO:Initializing Gradient Boosting Classifier
2025-04-19 19:37:50,364:INFO:Total runtime is 0.46994006236394253 minutes
2025-04-19 19:37:50,367:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:50,367:INFO:Initializing create_model()
2025-04-19 19:37:50,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:50,367:INFO:Checking exceptions
2025-04-19 19:37:50,367:INFO:Importing libraries
2025-04-19 19:37:50,367:INFO:Copying training dataset
2025-04-19 19:37:50,384:INFO:Defining folds
2025-04-19 19:37:50,384:INFO:Declaring metric variables
2025-04-19 19:37:50,387:INFO:Importing untrained model
2025-04-19 19:37:50,391:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 19:37:50,400:INFO:Starting cross validation
2025-04-19 19:37:50,401:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:56,523:INFO:Calculating mean and std
2025-04-19 19:37:56,525:INFO:Creating metrics dataframe
2025-04-19 19:37:56,527:INFO:Uploading results into container
2025-04-19 19:37:56,528:INFO:Uploading model into container now
2025-04-19 19:37:56,528:INFO:_master_model_container: 10
2025-04-19 19:37:56,528:INFO:_display_container: 2
2025-04-19 19:37:56,529:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 19:37:56,529:INFO:create_model() successfully completed......................................
2025-04-19 19:37:56,869:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:56,870:INFO:Creating metrics dataframe
2025-04-19 19:37:56,876:INFO:Initializing Linear Discriminant Analysis
2025-04-19 19:37:56,876:INFO:Total runtime is 0.5784663637479147 minutes
2025-04-19 19:37:56,879:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:56,879:INFO:Initializing create_model()
2025-04-19 19:37:56,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:56,880:INFO:Checking exceptions
2025-04-19 19:37:56,880:INFO:Importing libraries
2025-04-19 19:37:56,880:INFO:Copying training dataset
2025-04-19 19:37:56,896:INFO:Defining folds
2025-04-19 19:37:56,896:INFO:Declaring metric variables
2025-04-19 19:37:56,900:INFO:Importing untrained model
2025-04-19 19:37:56,903:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 19:37:56,908:INFO:Starting cross validation
2025-04-19 19:37:56,910:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:57,203:INFO:Calculating mean and std
2025-04-19 19:37:57,204:INFO:Creating metrics dataframe
2025-04-19 19:37:57,205:INFO:Uploading results into container
2025-04-19 19:37:57,206:INFO:Uploading model into container now
2025-04-19 19:37:57,206:INFO:_master_model_container: 11
2025-04-19 19:37:57,206:INFO:_display_container: 2
2025-04-19 19:37:57,206:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 19:37:57,207:INFO:create_model() successfully completed......................................
2025-04-19 19:37:57,589:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:57,589:INFO:Creating metrics dataframe
2025-04-19 19:37:57,599:INFO:Initializing Extra Trees Classifier
2025-04-19 19:37:57,599:INFO:Total runtime is 0.59052152633667 minutes
2025-04-19 19:37:57,602:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:57,602:INFO:Initializing create_model()
2025-04-19 19:37:57,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:57,602:INFO:Checking exceptions
2025-04-19 19:37:57,602:INFO:Importing libraries
2025-04-19 19:37:57,602:INFO:Copying training dataset
2025-04-19 19:37:57,621:INFO:Defining folds
2025-04-19 19:37:57,621:INFO:Declaring metric variables
2025-04-19 19:37:57,624:INFO:Importing untrained model
2025-04-19 19:37:57,626:INFO:Extra Trees Classifier Imported successfully
2025-04-19 19:37:57,632:INFO:Starting cross validation
2025-04-19 19:37:57,633:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:37:58,985:INFO:Calculating mean and std
2025-04-19 19:37:58,986:INFO:Creating metrics dataframe
2025-04-19 19:37:58,987:INFO:Uploading results into container
2025-04-19 19:37:58,988:INFO:Uploading model into container now
2025-04-19 19:37:58,988:INFO:_master_model_container: 12
2025-04-19 19:37:58,988:INFO:_display_container: 2
2025-04-19 19:37:58,988:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-19 19:37:58,989:INFO:create_model() successfully completed......................................
2025-04-19 19:37:59,305:INFO:SubProcess create_model() end ==================================
2025-04-19 19:37:59,305:INFO:Creating metrics dataframe
2025-04-19 19:37:59,314:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:37:59,314:INFO:Total runtime is 0.6191087643305462 minutes
2025-04-19 19:37:59,317:INFO:SubProcess create_model() called ==================================
2025-04-19 19:37:59,318:INFO:Initializing create_model()
2025-04-19 19:37:59,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:37:59,318:INFO:Checking exceptions
2025-04-19 19:37:59,318:INFO:Importing libraries
2025-04-19 19:37:59,318:INFO:Copying training dataset
2025-04-19 19:37:59,335:INFO:Defining folds
2025-04-19 19:37:59,335:INFO:Declaring metric variables
2025-04-19 19:37:59,338:INFO:Importing untrained model
2025-04-19 19:37:59,341:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:37:59,346:INFO:Starting cross validation
2025-04-19 19:37:59,348:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:38:00,238:INFO:Calculating mean and std
2025-04-19 19:38:00,239:INFO:Creating metrics dataframe
2025-04-19 19:38:00,242:INFO:Uploading results into container
2025-04-19 19:38:00,242:INFO:Uploading model into container now
2025-04-19 19:38:00,243:INFO:_master_model_container: 13
2025-04-19 19:38:00,243:INFO:_display_container: 2
2025-04-19 19:38:00,244:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 19:38:00,244:INFO:create_model() successfully completed......................................
2025-04-19 19:38:00,576:INFO:SubProcess create_model() end ==================================
2025-04-19 19:38:00,576:INFO:Creating metrics dataframe
2025-04-19 19:38:00,585:INFO:Initializing Dummy Classifier
2025-04-19 19:38:00,585:INFO:Total runtime is 0.6402763485908509 minutes
2025-04-19 19:38:00,587:INFO:SubProcess create_model() called ==================================
2025-04-19 19:38:00,587:INFO:Initializing create_model()
2025-04-19 19:38:00,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD9056B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:38:00,588:INFO:Checking exceptions
2025-04-19 19:38:00,588:INFO:Importing libraries
2025-04-19 19:38:00,588:INFO:Copying training dataset
2025-04-19 19:38:00,603:INFO:Defining folds
2025-04-19 19:38:00,603:INFO:Declaring metric variables
2025-04-19 19:38:00,606:INFO:Importing untrained model
2025-04-19 19:38:00,609:INFO:Dummy Classifier Imported successfully
2025-04-19 19:38:00,616:INFO:Starting cross validation
2025-04-19 19:38:00,617:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:38:00,785:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:38:00,787:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:38:00,810:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:38:00,811:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:38:00,812:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:38:00,824:INFO:Calculating mean and std
2025-04-19 19:38:00,825:INFO:Creating metrics dataframe
2025-04-19 19:38:00,826:INFO:Uploading results into container
2025-04-19 19:38:00,828:INFO:Uploading model into container now
2025-04-19 19:38:00,828:INFO:_master_model_container: 14
2025-04-19 19:38:00,828:INFO:_display_container: 2
2025-04-19 19:38:00,828:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 19:38:00,828:INFO:create_model() successfully completed......................................
2025-04-19 19:38:01,195:INFO:SubProcess create_model() end ==================================
2025-04-19 19:38:01,195:INFO:Creating metrics dataframe
2025-04-19 19:38:01,204:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-19 19:38:01,211:INFO:Initializing create_model()
2025-04-19 19:38:01,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDD90A79D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:38:01,211:INFO:Checking exceptions
2025-04-19 19:38:01,212:INFO:Importing libraries
2025-04-19 19:38:01,212:INFO:Copying training dataset
2025-04-19 19:38:01,230:INFO:Defining folds
2025-04-19 19:38:01,230:INFO:Declaring metric variables
2025-04-19 19:38:01,230:INFO:Importing untrained model
2025-04-19 19:38:01,230:INFO:Declaring custom model
2025-04-19 19:38:01,232:INFO:Naive Bayes Imported successfully
2025-04-19 19:38:01,233:INFO:Cross validation set to False
2025-04-19 19:38:01,233:INFO:Fitting Model
2025-04-19 19:38:01,326:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 19:38:01,326:INFO:create_model() successfully completed......................................
2025-04-19 19:38:01,670:INFO:_master_model_container: 14
2025-04-19 19:38:01,671:INFO:_display_container: 2
2025-04-19 19:38:01,671:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 19:38:01,671:INFO:compare_models() successfully completed......................................
2025-04-19 19:57:41,027:INFO:PyCaret ClassificationExperiment
2025-04-19 19:57:41,027:INFO:Logging name: clf-default-name
2025-04-19 19:57:41,027:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 19:57:41,027:INFO:version 3.3.2
2025-04-19 19:57:41,027:INFO:Initializing setup()
2025-04-19 19:57:41,027:INFO:self.USI: 2058
2025-04-19 19:57:41,027:INFO:self._variable_keys: {'exp_id', '_ml_usecase', 'pipeline', 'X_test', 'y', 'X', 'y_train', 'data', 'log_plots_param', 'idx', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'memory', 'seed', 'fold_groups_param', 'target_param', '_available_plots', 'fix_imbalance', 'y_test', 'fold_generator', 'n_jobs_param', 'logging_param', 'is_multiclass', 'gpu_param', 'USI', 'X_train', 'fold_shuffle_param'}
2025-04-19 19:57:41,027:INFO:Checking environment
2025-04-19 19:57:41,027:INFO:python_version: 3.11.4
2025-04-19 19:57:41,027:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-19 19:57:41,027:INFO:machine: AMD64
2025-04-19 19:57:41,027:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:57:41,037:INFO:Memory: svmem(total=16498810880, available=3384303616, percent=79.5, used=13114507264, free=3384303616)
2025-04-19 19:57:41,037:INFO:Physical Core: 8
2025-04-19 19:57:41,037:INFO:Logical Core: 16
2025-04-19 19:57:41,037:INFO:Checking libraries
2025-04-19 19:57:41,037:INFO:System:
2025-04-19 19:57:41,037:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-19 19:57:41,037:INFO:executable: c:\Python311\python.exe
2025-04-19 19:57:41,037:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:57:41,037:INFO:PyCaret required dependencies:
2025-04-19 19:57:41,037:INFO:                 pip: 23.1.2
2025-04-19 19:57:41,037:INFO:          setuptools: 65.5.0
2025-04-19 19:57:41,037:INFO:             pycaret: 3.3.2
2025-04-19 19:57:41,037:INFO:             IPython: 8.20.0
2025-04-19 19:57:41,037:INFO:          ipywidgets: 8.1.6
2025-04-19 19:57:41,037:INFO:                tqdm: 4.66.2
2025-04-19 19:57:41,037:INFO:               numpy: 1.26.2
2025-04-19 19:57:41,037:INFO:              pandas: 2.1.4
2025-04-19 19:57:41,037:INFO:              jinja2: 3.1.2
2025-04-19 19:57:41,037:INFO:               scipy: 1.11.4
2025-04-19 19:57:41,038:INFO:              joblib: 1.3.2
2025-04-19 19:57:41,038:INFO:             sklearn: 1.4.2
2025-04-19 19:57:41,038:INFO:                pyod: 2.0.4
2025-04-19 19:57:41,038:INFO:            imblearn: 0.12.0
2025-04-19 19:57:41,038:INFO:   category_encoders: 2.7.0
2025-04-19 19:57:41,038:INFO:            lightgbm: 4.6.0
2025-04-19 19:57:41,038:INFO:               numba: 0.61.2
2025-04-19 19:57:41,038:INFO:            requests: 2.31.0
2025-04-19 19:57:41,038:INFO:          matplotlib: 3.7.5
2025-04-19 19:57:41,038:INFO:          scikitplot: 0.3.7
2025-04-19 19:57:41,038:INFO:         yellowbrick: 1.5
2025-04-19 19:57:41,038:INFO:              plotly: 5.24.1
2025-04-19 19:57:41,038:INFO:    plotly-resampler: Not installed
2025-04-19 19:57:41,038:INFO:             kaleido: 0.2.1
2025-04-19 19:57:41,038:INFO:           schemdraw: 0.15
2025-04-19 19:57:41,038:INFO:         statsmodels: 0.14.4
2025-04-19 19:57:41,038:INFO:              sktime: 0.26.0
2025-04-19 19:57:41,038:INFO:               tbats: 1.1.3
2025-04-19 19:57:41,038:INFO:            pmdarima: 2.0.4
2025-04-19 19:57:41,038:INFO:              psutil: 5.9.8
2025-04-19 19:57:41,038:INFO:          markupsafe: 2.1.3
2025-04-19 19:57:41,038:INFO:             pickle5: Not installed
2025-04-19 19:57:41,038:INFO:         cloudpickle: 3.1.1
2025-04-19 19:57:41,038:INFO:         deprecation: 2.1.0
2025-04-19 19:57:41,038:INFO:              xxhash: 3.5.0
2025-04-19 19:57:41,038:INFO:           wurlitzer: Not installed
2025-04-19 19:57:41,038:INFO:PyCaret optional dependencies:
2025-04-19 19:57:41,038:INFO:                shap: Not installed
2025-04-19 19:57:41,038:INFO:           interpret: Not installed
2025-04-19 19:57:41,038:INFO:                umap: Not installed
2025-04-19 19:57:41,038:INFO:     ydata_profiling: Not installed
2025-04-19 19:57:41,038:INFO:  explainerdashboard: Not installed
2025-04-19 19:57:41,038:INFO:             autoviz: Not installed
2025-04-19 19:57:41,038:INFO:           fairlearn: Not installed
2025-04-19 19:57:41,038:INFO:          deepchecks: Not installed
2025-04-19 19:57:41,039:INFO:             xgboost: Not installed
2025-04-19 19:57:41,039:INFO:            catboost: Not installed
2025-04-19 19:57:41,039:INFO:              kmodes: Not installed
2025-04-19 19:57:41,039:INFO:             mlxtend: 0.23.4
2025-04-19 19:57:41,039:INFO:       statsforecast: Not installed
2025-04-19 19:57:41,039:INFO:        tune_sklearn: Not installed
2025-04-19 19:57:41,039:INFO:                 ray: Not installed
2025-04-19 19:57:41,039:INFO:            hyperopt: Not installed
2025-04-19 19:57:41,039:INFO:              optuna: Not installed
2025-04-19 19:57:41,039:INFO:               skopt: Not installed
2025-04-19 19:57:41,039:INFO:              mlflow: Not installed
2025-04-19 19:57:41,039:INFO:              gradio: Not installed
2025-04-19 19:57:41,039:INFO:             fastapi: Not installed
2025-04-19 19:57:41,039:INFO:             uvicorn: Not installed
2025-04-19 19:57:41,039:INFO:              m2cgen: Not installed
2025-04-19 19:57:41,039:INFO:           evidently: Not installed
2025-04-19 19:57:41,039:INFO:               fugue: Not installed
2025-04-19 19:57:41,039:INFO:           streamlit: Not installed
2025-04-19 19:57:41,039:INFO:             prophet: Not installed
2025-04-19 19:57:41,039:INFO:None
2025-04-19 19:57:41,039:INFO:Set up data.
2025-04-19 19:57:41,048:INFO:Set up folding strategy.
2025-04-19 19:57:41,048:INFO:Set up train/test split.
2025-04-19 19:57:41,061:INFO:Set up index.
2025-04-19 19:57:41,061:INFO:Assigning column types.
2025-04-19 19:57:41,069:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:57:41,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,187:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:57:41,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,280:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:57:41,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,304:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 19:57:41,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:41,425:INFO:Preparing preprocessing pipeline...
2025-04-19 19:57:41,427:INFO:Set up simple imputation.
2025-04-19 19:57:41,427:INFO:Set up imbalanced handling.
2025-04-19 19:57:41,427:INFO:Set up feature normalization.
2025-04-19 19:57:44,332:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:57:44,337:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status', 'Momentum',
                                             'momentum_stability_flag',
                                             'risk_index_1_log',
                                             'low_repayment_months_log',
                                             'momentum_recent_mean_inte...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-19 19:57:44,337:INFO:Creating final display dataframe.
2025-04-19 19:57:47,535:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 14)
4        Transformed data shape                 (40441, 14)
5   Transformed train set shape                 (31692, 14)
6    Transformed test set shape                  (8749, 14)
7              Numeric features                          13
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name            clf-default-name
22                          USI                        2058
2025-04-19 19:57:47,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:47,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:47,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:47,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:57:47,658:INFO:setup() successfully completed in 6.65s...............
2025-04-19 19:57:47,659:INFO:Initializing compare_models()
2025-04-19 19:57:47,659:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-19 19:57:47,659:INFO:Checking exceptions
2025-04-19 19:57:47,666:INFO:Preparing display monitor
2025-04-19 19:57:47,683:INFO:Initializing Logistic Regression
2025-04-19 19:57:47,683:INFO:Total runtime is 0.0 minutes
2025-04-19 19:57:47,686:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:47,687:INFO:Initializing create_model()
2025-04-19 19:57:47,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:57:47,687:INFO:Checking exceptions
2025-04-19 19:57:47,687:INFO:Importing libraries
2025-04-19 19:57:47,687:INFO:Copying training dataset
2025-04-19 19:57:47,700:INFO:Defining folds
2025-04-19 19:57:47,700:INFO:Declaring metric variables
2025-04-19 19:57:47,703:INFO:Importing untrained model
2025-04-19 19:57:47,707:INFO:Logistic Regression Imported successfully
2025-04-19 19:57:47,712:INFO:Starting cross validation
2025-04-19 19:57:47,713:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:56,668:INFO:Calculating mean and std
2025-04-19 19:57:56,669:INFO:Creating metrics dataframe
2025-04-19 19:57:56,672:INFO:Uploading results into container
2025-04-19 19:57:56,673:INFO:Uploading model into container now
2025-04-19 19:57:56,673:INFO:_master_model_container: 1
2025-04-19 19:57:56,673:INFO:_display_container: 2
2025-04-19 19:57:56,674:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 19:57:56,674:INFO:create_model() successfully completed......................................
2025-04-19 19:57:57,106:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:57,106:INFO:Creating metrics dataframe
2025-04-19 19:57:57,110:INFO:Initializing K Neighbors Classifier
2025-04-19 19:57:57,110:INFO:Total runtime is 0.1571135958035787 minutes
2025-04-19 19:57:57,113:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:57,113:INFO:Initializing create_model()
2025-04-19 19:57:57,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:57:57,113:INFO:Checking exceptions
2025-04-19 19:57:57,114:INFO:Importing libraries
2025-04-19 19:57:57,114:INFO:Copying training dataset
2025-04-19 19:57:57,128:INFO:Defining folds
2025-04-19 19:57:57,128:INFO:Declaring metric variables
2025-04-19 19:57:57,132:INFO:Importing untrained model
2025-04-19 19:57:57,134:INFO:K Neighbors Classifier Imported successfully
2025-04-19 19:57:57,139:INFO:Starting cross validation
2025-04-19 19:57:57,141:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:04,585:INFO:Calculating mean and std
2025-04-19 19:58:04,586:INFO:Creating metrics dataframe
2025-04-19 19:58:04,589:INFO:Uploading results into container
2025-04-19 19:58:04,589:INFO:Uploading model into container now
2025-04-19 19:58:04,590:INFO:_master_model_container: 2
2025-04-19 19:58:04,590:INFO:_display_container: 2
2025-04-19 19:58:04,590:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 19:58:04,590:INFO:create_model() successfully completed......................................
2025-04-19 19:58:04,924:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:04,924:INFO:Creating metrics dataframe
2025-04-19 19:58:04,930:INFO:Initializing Naive Bayes
2025-04-19 19:58:04,930:INFO:Total runtime is 0.2874434232711792 minutes
2025-04-19 19:58:04,933:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:04,933:INFO:Initializing create_model()
2025-04-19 19:58:04,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:04,933:INFO:Checking exceptions
2025-04-19 19:58:04,933:INFO:Importing libraries
2025-04-19 19:58:04,933:INFO:Copying training dataset
2025-04-19 19:58:04,945:INFO:Defining folds
2025-04-19 19:58:04,945:INFO:Declaring metric variables
2025-04-19 19:58:04,948:INFO:Importing untrained model
2025-04-19 19:58:04,951:INFO:Naive Bayes Imported successfully
2025-04-19 19:58:04,957:INFO:Starting cross validation
2025-04-19 19:58:04,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:10,333:INFO:Calculating mean and std
2025-04-19 19:58:10,334:INFO:Creating metrics dataframe
2025-04-19 19:58:10,336:INFO:Uploading results into container
2025-04-19 19:58:10,336:INFO:Uploading model into container now
2025-04-19 19:58:10,338:INFO:_master_model_container: 3
2025-04-19 19:58:10,338:INFO:_display_container: 2
2025-04-19 19:58:10,338:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 19:58:10,338:INFO:create_model() successfully completed......................................
2025-04-19 19:58:10,682:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:10,682:INFO:Creating metrics dataframe
2025-04-19 19:58:10,688:INFO:Initializing Decision Tree Classifier
2025-04-19 19:58:10,688:INFO:Total runtime is 0.38340376615524296 minutes
2025-04-19 19:58:10,691:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:10,692:INFO:Initializing create_model()
2025-04-19 19:58:10,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:10,692:INFO:Checking exceptions
2025-04-19 19:58:10,692:INFO:Importing libraries
2025-04-19 19:58:10,692:INFO:Copying training dataset
2025-04-19 19:58:10,703:INFO:Defining folds
2025-04-19 19:58:10,703:INFO:Declaring metric variables
2025-04-19 19:58:10,707:INFO:Importing untrained model
2025-04-19 19:58:10,709:INFO:Decision Tree Classifier Imported successfully
2025-04-19 19:58:10,714:INFO:Starting cross validation
2025-04-19 19:58:10,715:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:15,467:INFO:Calculating mean and std
2025-04-19 19:58:15,469:INFO:Creating metrics dataframe
2025-04-19 19:58:15,470:INFO:Uploading results into container
2025-04-19 19:58:15,471:INFO:Uploading model into container now
2025-04-19 19:58:15,471:INFO:_master_model_container: 4
2025-04-19 19:58:15,472:INFO:_display_container: 2
2025-04-19 19:58:15,472:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-19 19:58:15,472:INFO:create_model() successfully completed......................................
2025-04-19 19:58:15,825:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:15,825:INFO:Creating metrics dataframe
2025-04-19 19:58:15,830:INFO:Initializing SVM - Linear Kernel
2025-04-19 19:58:15,830:INFO:Total runtime is 0.46911736726760866 minutes
2025-04-19 19:58:15,833:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:15,833:INFO:Initializing create_model()
2025-04-19 19:58:15,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:15,833:INFO:Checking exceptions
2025-04-19 19:58:15,833:INFO:Importing libraries
2025-04-19 19:58:15,833:INFO:Copying training dataset
2025-04-19 19:58:15,844:INFO:Defining folds
2025-04-19 19:58:15,844:INFO:Declaring metric variables
2025-04-19 19:58:15,847:INFO:Importing untrained model
2025-04-19 19:58:15,850:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 19:58:15,855:INFO:Starting cross validation
2025-04-19 19:58:15,858:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:18,858:INFO:Calculating mean and std
2025-04-19 19:58:18,859:INFO:Creating metrics dataframe
2025-04-19 19:58:18,861:INFO:Uploading results into container
2025-04-19 19:58:18,861:INFO:Uploading model into container now
2025-04-19 19:58:18,862:INFO:_master_model_container: 5
2025-04-19 19:58:18,862:INFO:_display_container: 2
2025-04-19 19:58:18,862:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 19:58:18,862:INFO:create_model() successfully completed......................................
2025-04-19 19:58:19,174:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:19,174:INFO:Creating metrics dataframe
2025-04-19 19:58:19,180:INFO:Initializing Ridge Classifier
2025-04-19 19:58:19,180:INFO:Total runtime is 0.5249406099319458 minutes
2025-04-19 19:58:19,183:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:19,183:INFO:Initializing create_model()
2025-04-19 19:58:19,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:19,183:INFO:Checking exceptions
2025-04-19 19:58:19,183:INFO:Importing libraries
2025-04-19 19:58:19,183:INFO:Copying training dataset
2025-04-19 19:58:19,194:INFO:Defining folds
2025-04-19 19:58:19,194:INFO:Declaring metric variables
2025-04-19 19:58:19,198:INFO:Importing untrained model
2025-04-19 19:58:19,200:INFO:Ridge Classifier Imported successfully
2025-04-19 19:58:19,204:INFO:Starting cross validation
2025-04-19 19:58:19,205:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:21,992:INFO:Calculating mean and std
2025-04-19 19:58:21,992:INFO:Creating metrics dataframe
2025-04-19 19:58:21,994:INFO:Uploading results into container
2025-04-19 19:58:21,994:INFO:Uploading model into container now
2025-04-19 19:58:21,995:INFO:_master_model_container: 6
2025-04-19 19:58:21,995:INFO:_display_container: 2
2025-04-19 19:58:21,995:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 19:58:21,995:INFO:create_model() successfully completed......................................
2025-04-19 19:58:22,296:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:22,297:INFO:Creating metrics dataframe
2025-04-19 19:58:22,302:INFO:Initializing Random Forest Classifier
2025-04-19 19:58:22,302:INFO:Total runtime is 0.5769723137219747 minutes
2025-04-19 19:58:22,305:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:22,305:INFO:Initializing create_model()
2025-04-19 19:58:22,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:22,305:INFO:Checking exceptions
2025-04-19 19:58:22,305:INFO:Importing libraries
2025-04-19 19:58:22,306:INFO:Copying training dataset
2025-04-19 19:58:22,317:INFO:Defining folds
2025-04-19 19:58:22,317:INFO:Declaring metric variables
2025-04-19 19:58:22,319:INFO:Importing untrained model
2025-04-19 19:58:22,322:INFO:Random Forest Classifier Imported successfully
2025-04-19 19:58:22,327:INFO:Starting cross validation
2025-04-19 19:58:22,328:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:25,907:INFO:Calculating mean and std
2025-04-19 19:58:25,908:INFO:Creating metrics dataframe
2025-04-19 19:58:25,910:INFO:Uploading results into container
2025-04-19 19:58:25,910:INFO:Uploading model into container now
2025-04-19 19:58:25,910:INFO:_master_model_container: 7
2025-04-19 19:58:25,910:INFO:_display_container: 2
2025-04-19 19:58:25,912:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-19 19:58:25,912:INFO:create_model() successfully completed......................................
2025-04-19 19:58:26,212:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:26,212:INFO:Creating metrics dataframe
2025-04-19 19:58:26,218:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 19:58:26,218:INFO:Total runtime is 0.6422371665636698 minutes
2025-04-19 19:58:26,220:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:26,221:INFO:Initializing create_model()
2025-04-19 19:58:26,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:26,221:INFO:Checking exceptions
2025-04-19 19:58:26,221:INFO:Importing libraries
2025-04-19 19:58:26,221:INFO:Copying training dataset
2025-04-19 19:58:26,232:INFO:Defining folds
2025-04-19 19:58:26,232:INFO:Declaring metric variables
2025-04-19 19:58:26,234:INFO:Importing untrained model
2025-04-19 19:58:26,238:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 19:58:26,242:INFO:Starting cross validation
2025-04-19 19:58:26,244:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:29,056:INFO:Calculating mean and std
2025-04-19 19:58:29,058:INFO:Creating metrics dataframe
2025-04-19 19:58:29,059:INFO:Uploading results into container
2025-04-19 19:58:29,059:INFO:Uploading model into container now
2025-04-19 19:58:29,060:INFO:_master_model_container: 8
2025-04-19 19:58:29,060:INFO:_display_container: 2
2025-04-19 19:58:29,060:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 19:58:29,060:INFO:create_model() successfully completed......................................
2025-04-19 19:58:29,373:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:29,373:INFO:Creating metrics dataframe
2025-04-19 19:58:29,380:INFO:Initializing Ada Boost Classifier
2025-04-19 19:58:29,380:INFO:Total runtime is 0.6949356953303019 minutes
2025-04-19 19:58:29,383:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:29,383:INFO:Initializing create_model()
2025-04-19 19:58:29,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:29,383:INFO:Checking exceptions
2025-04-19 19:58:29,383:INFO:Importing libraries
2025-04-19 19:58:29,383:INFO:Copying training dataset
2025-04-19 19:58:29,393:INFO:Defining folds
2025-04-19 19:58:29,393:INFO:Declaring metric variables
2025-04-19 19:58:29,396:INFO:Importing untrained model
2025-04-19 19:58:29,399:INFO:Ada Boost Classifier Imported successfully
2025-04-19 19:58:29,403:INFO:Starting cross validation
2025-04-19 19:58:29,405:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:31,976:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:58:31,998:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:58:32,114:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:58:32,226:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:58:32,432:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 19:58:32,968:INFO:Calculating mean and std
2025-04-19 19:58:32,969:INFO:Creating metrics dataframe
2025-04-19 19:58:32,971:INFO:Uploading results into container
2025-04-19 19:58:32,972:INFO:Uploading model into container now
2025-04-19 19:58:32,972:INFO:_master_model_container: 9
2025-04-19 19:58:32,972:INFO:_display_container: 2
2025-04-19 19:58:32,972:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-19 19:58:32,972:INFO:create_model() successfully completed......................................
2025-04-19 19:58:33,269:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:33,269:INFO:Creating metrics dataframe
2025-04-19 19:58:33,276:INFO:Initializing Gradient Boosting Classifier
2025-04-19 19:58:33,276:INFO:Total runtime is 0.7598756909370422 minutes
2025-04-19 19:58:33,278:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:33,278:INFO:Initializing create_model()
2025-04-19 19:58:33,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:33,278:INFO:Checking exceptions
2025-04-19 19:58:33,278:INFO:Importing libraries
2025-04-19 19:58:33,278:INFO:Copying training dataset
2025-04-19 19:58:33,290:INFO:Defining folds
2025-04-19 19:58:33,290:INFO:Declaring metric variables
2025-04-19 19:58:33,292:INFO:Importing untrained model
2025-04-19 19:58:33,295:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 19:58:33,300:INFO:Starting cross validation
2025-04-19 19:58:33,301:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:37,476:INFO:Calculating mean and std
2025-04-19 19:58:37,476:INFO:Creating metrics dataframe
2025-04-19 19:58:37,478:INFO:Uploading results into container
2025-04-19 19:58:37,478:INFO:Uploading model into container now
2025-04-19 19:58:37,478:INFO:_master_model_container: 10
2025-04-19 19:58:37,478:INFO:_display_container: 2
2025-04-19 19:58:37,479:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 19:58:37,479:INFO:create_model() successfully completed......................................
2025-04-19 19:58:37,794:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:37,794:INFO:Creating metrics dataframe
2025-04-19 19:58:37,801:INFO:Initializing Linear Discriminant Analysis
2025-04-19 19:58:37,801:INFO:Total runtime is 0.8352911392847697 minutes
2025-04-19 19:58:37,803:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:37,803:INFO:Initializing create_model()
2025-04-19 19:58:37,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:37,803:INFO:Checking exceptions
2025-04-19 19:58:37,803:INFO:Importing libraries
2025-04-19 19:58:37,803:INFO:Copying training dataset
2025-04-19 19:58:37,815:INFO:Defining folds
2025-04-19 19:58:37,815:INFO:Declaring metric variables
2025-04-19 19:58:37,819:INFO:Importing untrained model
2025-04-19 19:58:37,821:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 19:58:37,826:INFO:Starting cross validation
2025-04-19 19:58:37,828:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:40,994:INFO:Calculating mean and std
2025-04-19 19:58:40,996:INFO:Creating metrics dataframe
2025-04-19 19:58:40,997:INFO:Uploading results into container
2025-04-19 19:58:40,998:INFO:Uploading model into container now
2025-04-19 19:58:40,998:INFO:_master_model_container: 11
2025-04-19 19:58:40,998:INFO:_display_container: 2
2025-04-19 19:58:40,999:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 19:58:40,999:INFO:create_model() successfully completed......................................
2025-04-19 19:58:41,302:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:41,302:INFO:Creating metrics dataframe
2025-04-19 19:58:41,310:INFO:Initializing Extra Trees Classifier
2025-04-19 19:58:41,310:INFO:Total runtime is 0.893768048286438 minutes
2025-04-19 19:58:41,313:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:41,313:INFO:Initializing create_model()
2025-04-19 19:58:41,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:41,313:INFO:Checking exceptions
2025-04-19 19:58:41,313:INFO:Importing libraries
2025-04-19 19:58:41,313:INFO:Copying training dataset
2025-04-19 19:58:41,323:INFO:Defining folds
2025-04-19 19:58:41,324:INFO:Declaring metric variables
2025-04-19 19:58:41,326:INFO:Importing untrained model
2025-04-19 19:58:41,330:INFO:Extra Trees Classifier Imported successfully
2025-04-19 19:58:41,334:INFO:Starting cross validation
2025-04-19 19:58:41,335:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:45,140:INFO:Calculating mean and std
2025-04-19 19:58:45,141:INFO:Creating metrics dataframe
2025-04-19 19:58:45,143:INFO:Uploading results into container
2025-04-19 19:58:45,143:INFO:Uploading model into container now
2025-04-19 19:58:45,143:INFO:_master_model_container: 12
2025-04-19 19:58:45,143:INFO:_display_container: 2
2025-04-19 19:58:45,144:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-19 19:58:45,144:INFO:create_model() successfully completed......................................
2025-04-19 19:58:45,443:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:45,443:INFO:Creating metrics dataframe
2025-04-19 19:58:45,449:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:58:45,449:INFO:Total runtime is 0.9627597649892171 minutes
2025-04-19 19:58:45,452:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:45,452:INFO:Initializing create_model()
2025-04-19 19:58:45,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:45,452:INFO:Checking exceptions
2025-04-19 19:58:45,452:INFO:Importing libraries
2025-04-19 19:58:45,452:INFO:Copying training dataset
2025-04-19 19:58:45,463:INFO:Defining folds
2025-04-19 19:58:45,463:INFO:Declaring metric variables
2025-04-19 19:58:45,466:INFO:Importing untrained model
2025-04-19 19:58:45,469:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:58:45,473:INFO:Starting cross validation
2025-04-19 19:58:45,475:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:48,890:INFO:Calculating mean and std
2025-04-19 19:58:48,892:INFO:Creating metrics dataframe
2025-04-19 19:58:48,894:INFO:Uploading results into container
2025-04-19 19:58:48,895:INFO:Uploading model into container now
2025-04-19 19:58:48,896:INFO:_master_model_container: 13
2025-04-19 19:58:48,896:INFO:_display_container: 2
2025-04-19 19:58:48,896:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 19:58:48,897:INFO:create_model() successfully completed......................................
2025-04-19 19:58:49,217:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:49,217:INFO:Creating metrics dataframe
2025-04-19 19:58:49,224:INFO:Initializing Dummy Classifier
2025-04-19 19:58:49,224:INFO:Total runtime is 1.0256756742795308 minutes
2025-04-19 19:58:49,227:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:49,227:INFO:Initializing create_model()
2025-04-19 19:58:49,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDC3657110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:49,227:INFO:Checking exceptions
2025-04-19 19:58:49,227:INFO:Importing libraries
2025-04-19 19:58:49,227:INFO:Copying training dataset
2025-04-19 19:58:49,238:INFO:Defining folds
2025-04-19 19:58:49,238:INFO:Declaring metric variables
2025-04-19 19:58:49,241:INFO:Importing untrained model
2025-04-19 19:58:49,243:INFO:Dummy Classifier Imported successfully
2025-04-19 19:58:49,248:INFO:Starting cross validation
2025-04-19 19:58:49,249:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:51,681:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:58:51,772:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:58:51,855:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:58:52,121:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:58:52,220:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-19 19:58:52,228:INFO:Calculating mean and std
2025-04-19 19:58:52,229:INFO:Creating metrics dataframe
2025-04-19 19:58:52,231:INFO:Uploading results into container
2025-04-19 19:58:52,231:INFO:Uploading model into container now
2025-04-19 19:58:52,231:INFO:_master_model_container: 14
2025-04-19 19:58:52,232:INFO:_display_container: 2
2025-04-19 19:58:52,232:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 19:58:52,232:INFO:create_model() successfully completed......................................
2025-04-19 19:58:52,539:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:52,539:INFO:Creating metrics dataframe
2025-04-19 19:58:52,548:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-19 19:58:52,553:INFO:Initializing create_model()
2025-04-19 19:58:52,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 19:58:52,553:INFO:Checking exceptions
2025-04-19 19:58:52,555:INFO:Importing libraries
2025-04-19 19:58:52,555:INFO:Copying training dataset
2025-04-19 19:58:52,567:INFO:Defining folds
2025-04-19 19:58:52,567:INFO:Declaring metric variables
2025-04-19 19:58:52,567:INFO:Importing untrained model
2025-04-19 19:58:52,567:INFO:Declaring custom model
2025-04-19 19:58:52,567:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 19:58:52,568:INFO:Cross validation set to False
2025-04-19 19:58:52,568:INFO:Fitting Model
2025-04-19 19:58:56,589:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 19:58:56,589:INFO:create_model() successfully completed......................................
2025-04-19 19:58:56,900:INFO:_master_model_container: 14
2025-04-19 19:58:56,900:INFO:_display_container: 2
2025-04-19 19:58:56,900:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 19:58:56,900:INFO:compare_models() successfully completed......................................
2025-04-19 20:00:15,708:INFO:Initializing create_model()
2025-04-19 20:00:15,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 20:00:15,709:INFO:Checking exceptions
2025-04-19 20:00:15,721:INFO:Importing libraries
2025-04-19 20:00:15,721:INFO:Copying training dataset
2025-04-19 20:00:15,736:INFO:Defining folds
2025-04-19 20:00:15,736:INFO:Declaring metric variables
2025-04-19 20:00:15,739:INFO:Importing untrained model
2025-04-19 20:00:15,742:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 20:00:15,751:INFO:Starting cross validation
2025-04-19 20:00:15,753:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:00:20,034:INFO:Calculating mean and std
2025-04-19 20:00:20,035:INFO:Creating metrics dataframe
2025-04-19 20:00:20,040:INFO:Finalizing model
2025-04-19 20:00:24,585:INFO:Uploading results into container
2025-04-19 20:00:24,585:INFO:Uploading model into container now
2025-04-19 20:00:24,593:INFO:_master_model_container: 15
2025-04-19 20:00:24,593:INFO:_display_container: 3
2025-04-19 20:00:24,593:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 20:00:24,593:INFO:create_model() successfully completed......................................
2025-04-19 20:00:24,916:INFO:Initializing predict_model()
2025-04-19 20:00:24,917:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDCA688B80>)
2025-04-19 20:00:24,917:INFO:Checking exceptions
2025-04-19 20:00:24,917:INFO:Preloading libraries
2025-04-19 20:02:40,762:INFO:Initializing create_model()
2025-04-19 20:02:40,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.005, 'loss': 'log_loss', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.3, 'min_samples_leaf': 2, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 180, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.35, 'tol': 0.0001, 'validation_fraction': 0.1, 'warm_start': False})
2025-04-19 20:02:40,763:INFO:Checking exceptions
2025-04-19 20:02:40,775:INFO:Importing libraries
2025-04-19 20:02:40,775:INFO:Copying training dataset
2025-04-19 20:02:40,789:INFO:Defining folds
2025-04-19 20:02:40,789:INFO:Declaring metric variables
2025-04-19 20:02:40,793:INFO:Importing untrained model
2025-04-19 20:02:40,797:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 20:02:40,803:INFO:Starting cross validation
2025-04-19 20:02:40,805:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:02:45,465:INFO:Calculating mean and std
2025-04-19 20:02:45,466:INFO:Creating metrics dataframe
2025-04-19 20:02:45,471:INFO:Finalizing model
2025-04-19 20:02:50,104:INFO:Uploading results into container
2025-04-19 20:02:50,105:INFO:Uploading model into container now
2025-04-19 20:02:50,112:INFO:_master_model_container: 16
2025-04-19 20:02:50,112:INFO:_display_container: 5
2025-04-19 20:02:50,112:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 20:02:50,112:INFO:create_model() successfully completed......................................
2025-04-19 20:02:50,446:INFO:Initializing predict_model()
2025-04-19 20:02:50,447:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDCA688FE0>)
2025-04-19 20:02:50,447:INFO:Checking exceptions
2025-04-19 20:02:50,447:INFO:Preloading libraries
2025-04-19 20:05:30,638:INFO:Initializing plot_model()
2025-04-19 20:05:30,638:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:30,638:INFO:Checking exceptions
2025-04-19 20:05:30,648:INFO:Preloading libraries
2025-04-19 20:05:30,659:INFO:Copying training dataset
2025-04-19 20:05:30,659:INFO:Plot type: auc
2025-04-19 20:05:30,737:INFO:Fitting Model
2025-04-19 20:05:30,750:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:05:30,750:INFO:Scoring test/hold-out set
2025-04-19 20:05:30,972:INFO:Visual Rendered Successfully
2025-04-19 20:05:31,305:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:31,306:INFO:Initializing plot_model()
2025-04-19 20:05:31,306:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:31,306:INFO:Checking exceptions
2025-04-19 20:05:31,317:INFO:Preloading libraries
2025-04-19 20:05:31,330:INFO:Copying training dataset
2025-04-19 20:05:31,330:INFO:Plot type: confusion_matrix
2025-04-19 20:05:31,413:INFO:Fitting Model
2025-04-19 20:05:31,413:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:05:31,413:INFO:Scoring test/hold-out set
2025-04-19 20:05:31,563:INFO:Visual Rendered Successfully
2025-04-19 20:05:31,866:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:31,867:INFO:Initializing plot_model()
2025-04-19 20:05:31,867:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:31,867:INFO:Checking exceptions
2025-04-19 20:05:31,874:INFO:Preloading libraries
2025-04-19 20:05:31,884:INFO:Copying training dataset
2025-04-19 20:05:31,884:INFO:Plot type: pr
2025-04-19 20:05:31,964:INFO:Fitting Model
2025-04-19 20:05:31,965:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:05:31,966:INFO:Scoring test/hold-out set
2025-04-19 20:05:32,161:INFO:Visual Rendered Successfully
2025-04-19 20:05:32,465:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:32,465:INFO:Initializing plot_model()
2025-04-19 20:05:32,467:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:32,467:INFO:Checking exceptions
2025-04-19 20:05:32,473:INFO:Preloading libraries
2025-04-19 20:05:32,482:INFO:Copying training dataset
2025-04-19 20:05:32,482:INFO:Plot type: class_report
2025-04-19 20:05:32,561:INFO:Fitting Model
2025-04-19 20:05:32,562:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:05:32,562:INFO:Scoring test/hold-out set
2025-04-19 20:05:32,786:INFO:Visual Rendered Successfully
2025-04-19 20:05:33,116:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:33,117:INFO:Initializing plot_model()
2025-04-19 20:05:33,117:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:33,117:INFO:Checking exceptions
2025-04-19 20:05:33,125:INFO:Preloading libraries
2025-04-19 20:05:33,133:INFO:Copying training dataset
2025-04-19 20:05:33,133:INFO:Plot type: lift
2025-04-19 20:05:33,133:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:05:33,358:INFO:Visual Rendered Successfully
2025-04-19 20:05:33,664:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:33,665:INFO:Initializing plot_model()
2025-04-19 20:05:33,665:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:33,665:INFO:Checking exceptions
2025-04-19 20:05:33,672:INFO:Preloading libraries
2025-04-19 20:05:33,681:INFO:Copying training dataset
2025-04-19 20:05:33,681:INFO:Plot type: gain
2025-04-19 20:05:33,682:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:05:33,887:INFO:Visual Rendered Successfully
2025-04-19 20:05:34,219:INFO:plot_model() successfully completed......................................
2025-04-19 20:05:34,219:INFO:Initializing plot_model()
2025-04-19 20:05:34,219:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=10,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=2,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=42, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:05:34,219:INFO:Checking exceptions
2025-04-19 20:05:34,227:INFO:Preloading libraries
2025-04-19 20:05:34,237:INFO:Copying training dataset
2025-04-19 20:05:34,237:INFO:Plot type: feature
2025-04-19 20:05:34,237:WARNING:No coef_ found. Trying feature_importances_
2025-04-19 20:05:34,381:INFO:Visual Rendered Successfully
2025-04-19 20:05:34,691:INFO:plot_model() successfully completed......................................
2025-04-19 20:08:50,907:INFO:Initializing create_model()
2025-04-19 20:08:50,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 20:08:50,908:INFO:Checking exceptions
2025-04-19 20:08:50,922:INFO:Importing libraries
2025-04-19 20:08:50,922:INFO:Copying training dataset
2025-04-19 20:08:50,941:INFO:Defining folds
2025-04-19 20:08:50,941:INFO:Declaring metric variables
2025-04-19 20:08:50,944:INFO:Importing untrained model
2025-04-19 20:08:50,949:INFO:Ada Boost Classifier Imported successfully
2025-04-19 20:08:50,956:INFO:Starting cross validation
2025-04-19 20:08:50,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:08:56,841:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:08:56,939:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:08:56,948:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:08:57,416:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:08:57,454:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:08:58,006:INFO:Calculating mean and std
2025-04-19 20:08:58,007:INFO:Creating metrics dataframe
2025-04-19 20:08:58,012:INFO:Finalizing model
2025-04-19 20:09:00,865:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-19 20:09:01,459:INFO:Uploading results into container
2025-04-19 20:09:01,460:INFO:Uploading model into container now
2025-04-19 20:09:01,467:INFO:_master_model_container: 17
2025-04-19 20:09:01,468:INFO:_display_container: 7
2025-04-19 20:09:01,468:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-19 20:09:01,468:INFO:create_model() successfully completed......................................
2025-04-19 20:09:01,789:INFO:Initializing predict_model()
2025-04-19 20:09:01,789:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDB91E6FC0>)
2025-04-19 20:09:01,789:INFO:Checking exceptions
2025-04-19 20:09:01,789:INFO:Preloading libraries
2025-04-19 20:09:40,988:INFO:Initializing create_model()
2025-04-19 20:09:40,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 240, 'random_state': 42})
2025-04-19 20:09:40,988:INFO:Checking exceptions
2025-04-19 20:09:41,002:INFO:Importing libraries
2025-04-19 20:09:41,002:INFO:Copying training dataset
2025-04-19 20:09:41,013:INFO:Defining folds
2025-04-19 20:09:41,013:INFO:Declaring metric variables
2025-04-19 20:09:41,016:INFO:Importing untrained model
2025-04-19 20:09:41,019:INFO:Ada Boost Classifier Imported successfully
2025-04-19 20:09:41,024:INFO:Starting cross validation
2025-04-19 20:09:41,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:48,546:INFO:Calculating mean and std
2025-04-19 20:09:48,547:INFO:Creating metrics dataframe
2025-04-19 20:09:48,552:INFO:Finalizing model
2025-04-19 20:09:53,252:INFO:Uploading results into container
2025-04-19 20:09:53,254:INFO:Uploading model into container now
2025-04-19 20:09:53,260:INFO:_master_model_container: 18
2025-04-19 20:09:53,260:INFO:_display_container: 9
2025-04-19 20:09:53,260:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42)
2025-04-19 20:09:53,260:INFO:create_model() successfully completed......................................
2025-04-19 20:09:53,574:INFO:Initializing predict_model()
2025-04-19 20:09:53,575:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDD7D52DE0>)
2025-04-19 20:09:53,575:INFO:Checking exceptions
2025-04-19 20:09:53,575:INFO:Preloading libraries
2025-04-19 20:14:02,024:INFO:Initializing plot_model()
2025-04-19 20:14:02,024:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:02,024:INFO:Checking exceptions
2025-04-19 20:14:02,036:INFO:Preloading libraries
2025-04-19 20:14:02,049:INFO:Copying training dataset
2025-04-19 20:14:02,050:INFO:Plot type: auc
2025-04-19 20:14:02,132:INFO:Fitting Model
2025-04-19 20:14:02,133:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:14:02,133:INFO:Scoring test/hold-out set
2025-04-19 20:14:02,443:INFO:Visual Rendered Successfully
2025-04-19 20:14:02,764:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:02,764:INFO:Initializing plot_model()
2025-04-19 20:14:02,764:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:02,764:INFO:Checking exceptions
2025-04-19 20:14:02,774:INFO:Preloading libraries
2025-04-19 20:14:02,784:INFO:Copying training dataset
2025-04-19 20:14:02,784:INFO:Plot type: confusion_matrix
2025-04-19 20:14:02,864:INFO:Fitting Model
2025-04-19 20:14:02,864:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:14:02,864:INFO:Scoring test/hold-out set
2025-04-19 20:14:03,098:INFO:Visual Rendered Successfully
2025-04-19 20:14:03,401:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:03,401:INFO:Initializing plot_model()
2025-04-19 20:14:03,401:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:03,401:INFO:Checking exceptions
2025-04-19 20:14:03,410:INFO:Preloading libraries
2025-04-19 20:14:03,421:INFO:Copying training dataset
2025-04-19 20:14:03,421:INFO:Plot type: pr
2025-04-19 20:14:03,500:INFO:Fitting Model
2025-04-19 20:14:03,501:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:14:03,502:INFO:Scoring test/hold-out set
2025-04-19 20:14:03,778:INFO:Visual Rendered Successfully
2025-04-19 20:14:04,089:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:04,090:INFO:Initializing plot_model()
2025-04-19 20:14:04,090:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:04,090:INFO:Checking exceptions
2025-04-19 20:14:04,098:INFO:Preloading libraries
2025-04-19 20:14:04,113:INFO:Copying training dataset
2025-04-19 20:14:04,113:INFO:Plot type: class_report
2025-04-19 20:14:04,193:INFO:Fitting Model
2025-04-19 20:14:04,193:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-19 20:14:04,193:INFO:Scoring test/hold-out set
2025-04-19 20:14:04,494:INFO:Visual Rendered Successfully
2025-04-19 20:14:04,802:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:04,803:INFO:Initializing plot_model()
2025-04-19 20:14:04,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:04,803:INFO:Checking exceptions
2025-04-19 20:14:04,812:INFO:Preloading libraries
2025-04-19 20:14:04,823:INFO:Copying training dataset
2025-04-19 20:14:04,823:INFO:Plot type: lift
2025-04-19 20:14:04,823:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:14:05,096:INFO:Visual Rendered Successfully
2025-04-19 20:14:05,405:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:05,405:INFO:Initializing plot_model()
2025-04-19 20:14:05,405:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:05,405:INFO:Checking exceptions
2025-04-19 20:14:05,414:INFO:Preloading libraries
2025-04-19 20:14:05,426:INFO:Copying training dataset
2025-04-19 20:14:05,426:INFO:Plot type: gain
2025-04-19 20:14:05,427:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:14:05,668:INFO:Visual Rendered Successfully
2025-04-19 20:14:05,979:INFO:plot_model() successfully completed......................................
2025-04-19 20:14:05,980:INFO:Initializing plot_model()
2025-04-19 20:14:05,980:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.5,
                   n_estimators=240, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:14:05,980:INFO:Checking exceptions
2025-04-19 20:14:05,988:INFO:Preloading libraries
2025-04-19 20:14:06,000:INFO:Copying training dataset
2025-04-19 20:14:06,000:INFO:Plot type: feature
2025-04-19 20:14:06,000:WARNING:No coef_ found. Trying feature_importances_
2025-04-19 20:14:06,132:INFO:Visual Rendered Successfully
2025-04-19 20:14:06,438:INFO:plot_model() successfully completed......................................
2025-04-19 20:18:17,064:INFO:Initializing create_model()
2025-04-19 20:18:17,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-19 20:18:17,065:INFO:Checking exceptions
2025-04-19 20:18:17,076:INFO:Importing libraries
2025-04-19 20:18:17,076:INFO:Copying training dataset
2025-04-19 20:18:17,090:INFO:Defining folds
2025-04-19 20:18:17,090:INFO:Declaring metric variables
2025-04-19 20:18:17,093:INFO:Importing untrained model
2025-04-19 20:18:17,095:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:18:17,105:INFO:Starting cross validation
2025-04-19 20:18:17,107:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:18:24,612:INFO:Calculating mean and std
2025-04-19 20:18:24,613:INFO:Creating metrics dataframe
2025-04-19 20:18:24,620:INFO:Finalizing model
2025-04-19 20:18:27,610:INFO:[LightGBM] [Info] Number of positive: 15846, number of negative: 15846
2025-04-19 20:18:27,613:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.
2025-04-19 20:18:27,613:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-19 20:18:27,614:INFO:[LightGBM] [Info] Total Bins 1910
2025-04-19 20:18:27,614:INFO:[LightGBM] [Info] Number of data points in the train set: 31692, number of used features: 13
2025-04-19 20:18:27,614:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-19 20:18:27,735:INFO:Uploading results into container
2025-04-19 20:18:27,736:INFO:Uploading model into container now
2025-04-19 20:18:27,744:INFO:_master_model_container: 19
2025-04-19 20:18:27,744:INFO:_display_container: 11
2025-04-19 20:18:27,745:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 20:18:27,745:INFO:create_model() successfully completed......................................
2025-04-19 20:18:28,070:INFO:Initializing predict_model()
2025-04-19 20:18:28,070:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDCA39EE80>)
2025-04-19 20:18:28,070:INFO:Checking exceptions
2025-04-19 20:18:28,070:INFO:Preloading libraries
2025-04-19 20:19:51,893:INFO:Initializing create_model()
2025-04-19 20:19:51,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.7, 'bagging_freq': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'feature_fraction': 1.0, 'importance_type': 'split', 'learning_rate': 0.4, 'max_depth': -1, 'min_child_samples': 81, 'min_child_weight': 0.001, 'min_split_gain': 0.6, 'n_estimators': 170, 'n_jobs': -1, 'num_leaves': 40, 'objective': None, 'random_state': 42, 'reg_alpha': 4, 'reg_lambda': 0.4, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0})
2025-04-19 20:19:51,894:INFO:Checking exceptions
2025-04-19 20:19:51,906:INFO:Importing libraries
2025-04-19 20:19:51,906:INFO:Copying training dataset
2025-04-19 20:19:51,921:INFO:Defining folds
2025-04-19 20:19:51,921:INFO:Declaring metric variables
2025-04-19 20:19:51,924:INFO:Importing untrained model
2025-04-19 20:19:51,927:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:19:51,932:INFO:Starting cross validation
2025-04-19 20:19:51,934:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:19:57,639:INFO:Calculating mean and std
2025-04-19 20:19:57,640:INFO:Creating metrics dataframe
2025-04-19 20:19:57,645:INFO:Finalizing model
2025-04-19 20:20:00,553:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:20:00,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:20:00,553:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:20:00,561:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:20:00,561:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:20:00,561:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:20:00,561:INFO:[LightGBM] [Info] Number of positive: 15846, number of negative: 15846
2025-04-19 20:20:00,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000821 seconds.
2025-04-19 20:20:00,563:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-19 20:20:00,563:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-19 20:20:00,563:INFO:[LightGBM] [Info] Total Bins 1910
2025-04-19 20:20:00,563:INFO:[LightGBM] [Info] Number of data points in the train set: 31692, number of used features: 13
2025-04-19 20:20:00,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-19 20:20:00,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,588:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 20:20:00,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-19 20:20:00,622:INFO:Uploading results into container
2025-04-19 20:20:00,622:INFO:Uploading model into container now
2025-04-19 20:20:00,631:INFO:_master_model_container: 20
2025-04-19 20:20:00,631:INFO:_display_container: 13
2025-04-19 20:20:00,631:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 20:20:00,632:INFO:create_model() successfully completed......................................
2025-04-19 20:20:00,961:INFO:Initializing predict_model()
2025-04-19 20:20:00,961:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FDBBC2A660>)
2025-04-19 20:20:00,961:INFO:Checking exceptions
2025-04-19 20:20:00,962:INFO:Preloading libraries
2025-04-19 20:22:29,562:INFO:Initializing plot_model()
2025-04-19 20:22:29,562:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:29,562:INFO:Checking exceptions
2025-04-19 20:22:29,570:INFO:Preloading libraries
2025-04-19 20:22:29,573:INFO:Copying training dataset
2025-04-19 20:22:29,573:INFO:Plot type: confusion_matrix
2025-04-19 20:22:29,686:INFO:Fitting Model
2025-04-19 20:22:29,686:INFO:Scoring test/hold-out set
2025-04-19 20:22:29,687:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:29,687:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:29,687:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:29,691:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:29,691:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:29,691:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:29,807:INFO:Visual Rendered Successfully
2025-04-19 20:22:30,137:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:30,138:INFO:Initializing plot_model()
2025-04-19 20:22:30,138:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:30,138:INFO:Checking exceptions
2025-04-19 20:22:30,145:INFO:Preloading libraries
2025-04-19 20:22:30,146:INFO:Copying training dataset
2025-04-19 20:22:30,146:INFO:Plot type: pr
2025-04-19 20:22:30,262:INFO:Fitting Model
2025-04-19 20:22:30,263:INFO:Scoring test/hold-out set
2025-04-19 20:22:30,264:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:30,265:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:30,265:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:30,269:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:30,269:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:30,269:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:30,431:INFO:Visual Rendered Successfully
2025-04-19 20:22:30,781:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:30,782:INFO:Initializing plot_model()
2025-04-19 20:22:30,782:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:30,782:INFO:Checking exceptions
2025-04-19 20:22:30,789:INFO:Preloading libraries
2025-04-19 20:22:30,791:INFO:Copying training dataset
2025-04-19 20:22:30,791:INFO:Plot type: class_report
2025-04-19 20:22:30,913:INFO:Fitting Model
2025-04-19 20:22:30,913:INFO:Scoring test/hold-out set
2025-04-19 20:22:30,914:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:30,914:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:30,915:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:30,918:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:30,919:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:30,919:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:31,107:INFO:Visual Rendered Successfully
2025-04-19 20:22:31,412:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:31,413:INFO:Initializing plot_model()
2025-04-19 20:22:31,413:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:31,413:INFO:Checking exceptions
2025-04-19 20:22:31,418:INFO:Preloading libraries
2025-04-19 20:22:31,420:INFO:Copying training dataset
2025-04-19 20:22:31,420:INFO:Plot type: lift
2025-04-19 20:22:31,421:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:22:31,495:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:31,496:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:31,496:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:31,658:INFO:Visual Rendered Successfully
2025-04-19 20:22:31,982:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:31,983:INFO:Initializing plot_model()
2025-04-19 20:22:31,983:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:31,983:INFO:Checking exceptions
2025-04-19 20:22:31,989:INFO:Preloading libraries
2025-04-19 20:22:31,990:INFO:Copying training dataset
2025-04-19 20:22:31,990:INFO:Plot type: gain
2025-04-19 20:22:31,991:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:22:32,059:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:22:32,059:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:22:32,059:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:22:32,219:INFO:Visual Rendered Successfully
2025-04-19 20:22:32,537:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:32,538:INFO:Initializing plot_model()
2025-04-19 20:22:32,538:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:22:32,538:INFO:Checking exceptions
2025-04-19 20:22:32,545:INFO:Preloading libraries
2025-04-19 20:22:32,546:INFO:Copying training dataset
2025-04-19 20:22:32,546:INFO:Plot type: feature
2025-04-19 20:22:32,547:WARNING:No coef_ found. Trying feature_importances_
2025-04-19 20:22:32,725:INFO:Visual Rendered Successfully
2025-04-19 20:22:33,041:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:38,378:INFO:Initializing plot_model()
2025-04-19 20:23:38,378:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:38,379:INFO:Checking exceptions
2025-04-19 20:23:38,387:INFO:Preloading libraries
2025-04-19 20:23:38,390:INFO:Copying training dataset
2025-04-19 20:23:38,390:INFO:Plot type: auc
2025-04-19 20:23:38,521:INFO:Fitting Model
2025-04-19 20:23:38,522:INFO:Scoring test/hold-out set
2025-04-19 20:23:38,524:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:38,524:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:38,524:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:38,531:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:38,531:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:38,531:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:38,715:INFO:Visual Rendered Successfully
2025-04-19 20:23:39,047:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:39,048:INFO:Initializing plot_model()
2025-04-19 20:23:39,048:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:39,048:INFO:Checking exceptions
2025-04-19 20:23:39,054:INFO:Preloading libraries
2025-04-19 20:23:39,055:INFO:Copying training dataset
2025-04-19 20:23:39,055:INFO:Plot type: confusion_matrix
2025-04-19 20:23:39,173:INFO:Fitting Model
2025-04-19 20:23:39,173:INFO:Scoring test/hold-out set
2025-04-19 20:23:39,175:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:39,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:39,175:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:39,179:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:39,180:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:39,180:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:39,299:INFO:Visual Rendered Successfully
2025-04-19 20:23:39,625:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:39,626:INFO:Initializing plot_model()
2025-04-19 20:23:39,626:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:39,626:INFO:Checking exceptions
2025-04-19 20:23:39,632:INFO:Preloading libraries
2025-04-19 20:23:39,633:INFO:Copying training dataset
2025-04-19 20:23:39,633:INFO:Plot type: pr
2025-04-19 20:23:39,751:INFO:Fitting Model
2025-04-19 20:23:39,752:INFO:Scoring test/hold-out set
2025-04-19 20:23:39,753:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:39,753:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:39,753:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:39,756:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:39,756:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:39,756:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:39,926:INFO:Visual Rendered Successfully
2025-04-19 20:23:40,243:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:40,244:INFO:Initializing plot_model()
2025-04-19 20:23:40,244:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:40,244:INFO:Checking exceptions
2025-04-19 20:23:40,251:INFO:Preloading libraries
2025-04-19 20:23:40,252:INFO:Copying training dataset
2025-04-19 20:23:40,252:INFO:Plot type: class_report
2025-04-19 20:23:40,374:INFO:Fitting Model
2025-04-19 20:23:40,374:INFO:Scoring test/hold-out set
2025-04-19 20:23:40,375:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:40,375:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:40,375:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:40,379:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:40,380:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:40,380:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:40,578:INFO:Visual Rendered Successfully
2025-04-19 20:23:40,935:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:40,936:INFO:Initializing plot_model()
2025-04-19 20:23:40,936:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:40,936:INFO:Checking exceptions
2025-04-19 20:23:40,944:INFO:Preloading libraries
2025-04-19 20:23:40,947:INFO:Copying training dataset
2025-04-19 20:23:40,947:INFO:Plot type: lift
2025-04-19 20:23:40,948:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:23:41,026:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:41,027:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:41,027:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:41,199:INFO:Visual Rendered Successfully
2025-04-19 20:23:41,533:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:41,533:INFO:Initializing plot_model()
2025-04-19 20:23:41,534:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:41,534:INFO:Checking exceptions
2025-04-19 20:23:41,539:INFO:Preloading libraries
2025-04-19 20:23:41,541:INFO:Copying training dataset
2025-04-19 20:23:41,541:INFO:Plot type: gain
2025-04-19 20:23:41,541:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:23:41,613:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:23:41,613:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:23:41,613:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:23:41,775:INFO:Visual Rendered Successfully
2025-04-19 20:23:42,089:INFO:plot_model() successfully completed......................................
2025-04-19 20:23:42,090:INFO:Initializing plot_model()
2025-04-19 20:23:42,090:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:23:42,090:INFO:Checking exceptions
2025-04-19 20:23:42,096:INFO:Preloading libraries
2025-04-19 20:23:42,097:INFO:Copying training dataset
2025-04-19 20:23:42,097:INFO:Plot type: feature
2025-04-19 20:23:42,098:WARNING:No coef_ found. Trying feature_importances_
2025-04-19 20:23:42,256:INFO:Visual Rendered Successfully
2025-04-19 20:23:42,578:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:11,342:INFO:Initializing plot_model()
2025-04-19 20:26:11,342:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:11,343:INFO:Checking exceptions
2025-04-19 20:26:11,350:INFO:Preloading libraries
2025-04-19 20:26:11,352:INFO:Copying training dataset
2025-04-19 20:26:11,352:INFO:Plot type: auc
2025-04-19 20:26:11,474:INFO:Fitting Model
2025-04-19 20:26:11,475:INFO:Scoring test/hold-out set
2025-04-19 20:26:11,476:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:11,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:11,476:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:11,480:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:11,480:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:11,480:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:11,661:INFO:Visual Rendered Successfully
2025-04-19 20:26:11,970:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:11,971:INFO:Initializing plot_model()
2025-04-19 20:26:11,971:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:11,971:INFO:Checking exceptions
2025-04-19 20:26:11,976:INFO:Preloading libraries
2025-04-19 20:26:11,978:INFO:Copying training dataset
2025-04-19 20:26:11,978:INFO:Plot type: confusion_matrix
2025-04-19 20:26:12,091:INFO:Fitting Model
2025-04-19 20:26:12,091:INFO:Scoring test/hold-out set
2025-04-19 20:26:12,092:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:12,092:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:12,092:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:12,096:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:12,096:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:12,096:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:12,202:INFO:Visual Rendered Successfully
2025-04-19 20:26:12,516:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:12,516:INFO:Initializing plot_model()
2025-04-19 20:26:12,516:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:12,516:INFO:Checking exceptions
2025-04-19 20:26:12,522:INFO:Preloading libraries
2025-04-19 20:26:12,523:INFO:Copying training dataset
2025-04-19 20:26:12,523:INFO:Plot type: pr
2025-04-19 20:26:12,638:INFO:Fitting Model
2025-04-19 20:26:12,639:INFO:Scoring test/hold-out set
2025-04-19 20:26:12,640:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:12,640:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:12,640:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:12,643:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:12,643:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:12,643:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:12,787:INFO:Visual Rendered Successfully
2025-04-19 20:26:13,091:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:13,092:INFO:Initializing plot_model()
2025-04-19 20:26:13,092:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:13,092:INFO:Checking exceptions
2025-04-19 20:26:13,098:INFO:Preloading libraries
2025-04-19 20:26:13,100:INFO:Copying training dataset
2025-04-19 20:26:13,100:INFO:Plot type: class_report
2025-04-19 20:26:13,214:INFO:Fitting Model
2025-04-19 20:26:13,215:INFO:Scoring test/hold-out set
2025-04-19 20:26:13,216:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:13,216:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:13,216:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:13,219:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:13,219:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:13,219:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:13,390:INFO:Visual Rendered Successfully
2025-04-19 20:26:13,692:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:13,693:INFO:Initializing plot_model()
2025-04-19 20:26:13,693:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:13,693:INFO:Checking exceptions
2025-04-19 20:26:13,699:INFO:Preloading libraries
2025-04-19 20:26:13,700:INFO:Copying training dataset
2025-04-19 20:26:13,700:INFO:Plot type: lift
2025-04-19 20:26:13,700:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:26:13,775:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:13,775:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:13,776:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:13,951:INFO:Visual Rendered Successfully
2025-04-19 20:26:14,264:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:14,265:INFO:Initializing plot_model()
2025-04-19 20:26:14,266:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:14,266:INFO:Checking exceptions
2025-04-19 20:26:14,271:INFO:Preloading libraries
2025-04-19 20:26:14,272:INFO:Copying training dataset
2025-04-19 20:26:14,272:INFO:Plot type: gain
2025-04-19 20:26:14,272:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:26:14,341:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:14,341:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:14,341:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:14,485:INFO:Visual Rendered Successfully
2025-04-19 20:26:14,790:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:14,791:INFO:Initializing interpret_model()
2025-04-19 20:26:14,791:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-04-19 20:26:14,791:INFO:Checking exceptions
2025-04-19 20:26:14,791:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-04-19 20:26:22,662:INFO:Initializing plot_model()
2025-04-19 20:26:22,662:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:22,662:INFO:Checking exceptions
2025-04-19 20:26:22,671:INFO:Preloading libraries
2025-04-19 20:26:22,673:INFO:Copying training dataset
2025-04-19 20:26:22,673:INFO:Plot type: auc
2025-04-19 20:26:22,795:INFO:Fitting Model
2025-04-19 20:26:22,796:INFO:Scoring test/hold-out set
2025-04-19 20:26:22,797:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:22,797:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:22,797:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:22,802:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:22,802:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:22,802:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:22,984:INFO:Visual Rendered Successfully
2025-04-19 20:26:23,317:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:23,317:INFO:Initializing plot_model()
2025-04-19 20:26:23,318:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:23,318:INFO:Checking exceptions
2025-04-19 20:26:23,323:INFO:Preloading libraries
2025-04-19 20:26:23,324:INFO:Copying training dataset
2025-04-19 20:26:23,325:INFO:Plot type: confusion_matrix
2025-04-19 20:26:23,438:INFO:Fitting Model
2025-04-19 20:26:23,438:INFO:Scoring test/hold-out set
2025-04-19 20:26:23,439:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:23,439:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:23,439:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:23,442:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:23,442:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:23,442:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:23,562:INFO:Visual Rendered Successfully
2025-04-19 20:26:23,877:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:23,878:INFO:Initializing plot_model()
2025-04-19 20:26:23,878:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:23,878:INFO:Checking exceptions
2025-04-19 20:26:23,886:INFO:Preloading libraries
2025-04-19 20:26:23,887:INFO:Copying training dataset
2025-04-19 20:26:23,887:INFO:Plot type: pr
2025-04-19 20:26:24,004:INFO:Fitting Model
2025-04-19 20:26:24,005:INFO:Scoring test/hold-out set
2025-04-19 20:26:24,006:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:24,006:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:24,006:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:24,010:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:24,010:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:24,010:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:24,172:INFO:Visual Rendered Successfully
2025-04-19 20:26:24,482:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:24,483:INFO:Initializing plot_model()
2025-04-19 20:26:24,483:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:24,483:INFO:Checking exceptions
2025-04-19 20:26:24,488:INFO:Preloading libraries
2025-04-19 20:26:24,489:INFO:Copying training dataset
2025-04-19 20:26:24,489:INFO:Plot type: class_report
2025-04-19 20:26:24,603:INFO:Fitting Model
2025-04-19 20:26:24,603:INFO:Scoring test/hold-out set
2025-04-19 20:26:24,604:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:24,604:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:24,604:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:24,608:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:24,608:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:24,608:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:24,786:INFO:Visual Rendered Successfully
2025-04-19 20:26:25,096:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:25,097:INFO:Initializing plot_model()
2025-04-19 20:26:25,097:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:25,097:INFO:Checking exceptions
2025-04-19 20:26:25,103:INFO:Preloading libraries
2025-04-19 20:26:25,104:INFO:Copying training dataset
2025-04-19 20:26:25,104:INFO:Plot type: lift
2025-04-19 20:26:25,105:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:26:25,175:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:25,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:25,176:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:25,333:INFO:Visual Rendered Successfully
2025-04-19 20:26:25,645:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:25,646:INFO:Initializing plot_model()
2025-04-19 20:26:25,646:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:25,646:INFO:Checking exceptions
2025-04-19 20:26:25,652:INFO:Preloading libraries
2025-04-19 20:26:25,653:INFO:Copying training dataset
2025-04-19 20:26:25,653:INFO:Plot type: gain
2025-04-19 20:26:25,653:INFO:Generating predictions / predict_proba on X_test
2025-04-19 20:26:25,720:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2025-04-19 20:26:25,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2025-04-19 20:26:25,720:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2025-04-19 20:26:25,869:INFO:Visual Rendered Successfully
2025-04-19 20:26:26,188:INFO:plot_model() successfully completed......................................
2025-04-19 20:26:26,190:INFO:Initializing plot_model()
2025-04-19 20:26:26,190:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDC50CADD0>, estimator=LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=170, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=4, reg_lambda=0.4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-19 20:26:26,190:INFO:Checking exceptions
2025-04-19 20:26:26,196:INFO:Preloading libraries
2025-04-19 20:26:26,197:INFO:Copying training dataset
2025-04-19 20:26:26,197:INFO:Plot type: feature
2025-04-19 20:26:26,197:WARNING:No coef_ found. Trying feature_importances_
2025-04-19 20:26:26,351:INFO:Visual Rendered Successfully
2025-04-19 20:26:26,660:INFO:plot_model() successfully completed......................................
