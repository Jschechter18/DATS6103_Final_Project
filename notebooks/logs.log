2025-04-21 23:00:01,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 23:00:01,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 23:00:01,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 23:00:01,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 23:01:18,967:WARNING:<ipython-input-17-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-21 23:01:23,667:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:23,668:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:23,845:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:23,846:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:24,023:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:24,023:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:24,204:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:24,205:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:24,513:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:24,514:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:24,690:WARNING:<ipython-input-18-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-21 23:01:24,691:WARNING:<ipython-input-18-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-21 23:01:29,510:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-21 23:01:29,954:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-21 23:01:29,955:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 00:58:31,155:INFO:PyCaret ClassificationExperiment
2025-04-22 00:58:31,155:INFO:Logging name: baseline_after_selection
2025-04-22 00:58:31,155:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 00:58:31,155:INFO:version 3.3.2
2025-04-22 00:58:31,156:INFO:Initializing setup()
2025-04-22 00:58:31,156:INFO:self.USI: 3805
2025-04-22 00:58:31,156:INFO:self._variable_keys: {'pipeline', 'logging_param', 'y', '_available_plots', 'log_plots_param', 'y_train', 'idx', 'exp_id', 'gpu_param', 'fold_shuffle_param', 'X', 'html_param', 'y_test', 'X_train', 'n_jobs_param', 'seed', 'fold_generator', 'X_test', 'fix_imbalance', 'target_param', 'data', 'exp_name_log', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'is_multiclass', '_ml_usecase', 'USI'}
2025-04-22 00:58:31,156:INFO:Checking environment
2025-04-22 00:58:31,156:INFO:python_version: 3.11.4
2025-04-22 00:58:31,156:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 00:58:31,156:INFO:machine: AMD64
2025-04-22 00:58:31,156:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 00:58:31,166:INFO:Memory: svmem(total=16498810880, available=4231168000, percent=74.4, used=12267642880, free=4231168000)
2025-04-22 00:58:31,167:INFO:Physical Core: 8
2025-04-22 00:58:31,167:INFO:Logical Core: 16
2025-04-22 00:58:31,167:INFO:Checking libraries
2025-04-22 00:58:31,167:INFO:System:
2025-04-22 00:58:31,167:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 00:58:31,167:INFO:executable: c:\Python311\python.exe
2025-04-22 00:58:31,167:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 00:58:31,167:INFO:PyCaret required dependencies:
2025-04-22 00:58:31,169:INFO:                 pip: 23.1.2
2025-04-22 00:58:31,170:INFO:          setuptools: 65.5.0
2025-04-22 00:58:31,170:INFO:             pycaret: 3.3.2
2025-04-22 00:58:31,170:INFO:             IPython: 8.20.0
2025-04-22 00:58:31,170:INFO:          ipywidgets: 8.1.6
2025-04-22 00:58:31,170:INFO:                tqdm: 4.66.2
2025-04-22 00:58:31,170:INFO:               numpy: 1.26.2
2025-04-22 00:58:31,170:INFO:              pandas: 2.1.4
2025-04-22 00:58:31,170:INFO:              jinja2: 3.1.2
2025-04-22 00:58:31,170:INFO:               scipy: 1.11.4
2025-04-22 00:58:31,170:INFO:              joblib: 1.3.2
2025-04-22 00:58:31,170:INFO:             sklearn: 1.4.2
2025-04-22 00:58:31,170:INFO:                pyod: 2.0.4
2025-04-22 00:58:31,170:INFO:            imblearn: 0.12.0
2025-04-22 00:58:31,170:INFO:   category_encoders: 2.7.0
2025-04-22 00:58:31,170:INFO:            lightgbm: 4.6.0
2025-04-22 00:58:31,170:INFO:               numba: 0.61.2
2025-04-22 00:58:31,170:INFO:            requests: 2.31.0
2025-04-22 00:58:31,170:INFO:          matplotlib: 3.7.5
2025-04-22 00:58:31,170:INFO:          scikitplot: 0.3.7
2025-04-22 00:58:31,170:INFO:         yellowbrick: 1.5
2025-04-22 00:58:31,170:INFO:              plotly: 5.24.1
2025-04-22 00:58:31,170:INFO:    plotly-resampler: Not installed
2025-04-22 00:58:31,170:INFO:             kaleido: 0.2.1
2025-04-22 00:58:31,170:INFO:           schemdraw: 0.15
2025-04-22 00:58:31,170:INFO:         statsmodels: 0.14.4
2025-04-22 00:58:31,170:INFO:              sktime: 0.26.0
2025-04-22 00:58:31,170:INFO:               tbats: 1.1.3
2025-04-22 00:58:31,170:INFO:            pmdarima: 2.0.4
2025-04-22 00:58:31,170:INFO:              psutil: 5.9.8
2025-04-22 00:58:31,170:INFO:          markupsafe: 2.1.3
2025-04-22 00:58:31,170:INFO:             pickle5: Not installed
2025-04-22 00:58:31,170:INFO:         cloudpickle: 3.1.1
2025-04-22 00:58:31,171:INFO:         deprecation: 2.1.0
2025-04-22 00:58:31,171:INFO:              xxhash: 3.5.0
2025-04-22 00:58:31,171:INFO:           wurlitzer: Not installed
2025-04-22 00:58:31,171:INFO:PyCaret optional dependencies:
2025-04-22 00:58:31,185:INFO:                shap: Not installed
2025-04-22 00:58:31,185:INFO:           interpret: Not installed
2025-04-22 00:58:31,185:INFO:                umap: Not installed
2025-04-22 00:58:31,186:INFO:     ydata_profiling: Not installed
2025-04-22 00:58:31,186:INFO:  explainerdashboard: Not installed
2025-04-22 00:58:31,186:INFO:             autoviz: Not installed
2025-04-22 00:58:31,186:INFO:           fairlearn: Not installed
2025-04-22 00:58:31,186:INFO:          deepchecks: Not installed
2025-04-22 00:58:31,186:INFO:             xgboost: Not installed
2025-04-22 00:58:31,186:INFO:            catboost: Not installed
2025-04-22 00:58:31,186:INFO:              kmodes: Not installed
2025-04-22 00:58:31,186:INFO:             mlxtend: 0.23.4
2025-04-22 00:58:31,186:INFO:       statsforecast: Not installed
2025-04-22 00:58:31,186:INFO:        tune_sklearn: Not installed
2025-04-22 00:58:31,186:INFO:                 ray: Not installed
2025-04-22 00:58:31,186:INFO:            hyperopt: Not installed
2025-04-22 00:58:31,186:INFO:              optuna: Not installed
2025-04-22 00:58:31,186:INFO:               skopt: Not installed
2025-04-22 00:58:31,186:INFO:              mlflow: Not installed
2025-04-22 00:58:31,186:INFO:              gradio: Not installed
2025-04-22 00:58:31,186:INFO:             fastapi: Not installed
2025-04-22 00:58:31,186:INFO:             uvicorn: Not installed
2025-04-22 00:58:31,186:INFO:              m2cgen: Not installed
2025-04-22 00:58:31,186:INFO:           evidently: Not installed
2025-04-22 00:58:31,186:INFO:               fugue: Not installed
2025-04-22 00:58:31,186:INFO:           streamlit: Not installed
2025-04-22 00:58:31,186:INFO:             prophet: Not installed
2025-04-22 00:58:31,186:INFO:None
2025-04-22 00:58:31,186:INFO:Set up data.
2025-04-22 00:58:31,194:INFO:Set up folding strategy.
2025-04-22 00:58:31,194:INFO:Set up train/test split.
2025-04-22 00:58:31,208:INFO:Set up index.
2025-04-22 00:58:31,208:INFO:Assigning column types.
2025-04-22 00:58:31,211:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 00:58:31,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,251:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,321:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,344:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 00:58:31,379:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 00:58:31,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,461:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 00:58:31,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:31,581:INFO:Preparing preprocessing pipeline...
2025-04-22 00:58:31,582:INFO:Set up simple imputation.
2025-04-22 00:58:31,582:INFO:Set up imbalanced handling.
2025-04-22 00:58:31,582:INFO:Set up feature normalization.
2025-04-22 00:58:33,122:INFO:Finished creating preprocessing pipeline.
2025-04-22 00:58:33,128:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['super_default_score_final_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transfor...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-22 00:58:33,128:INFO:Creating final display dataframe.
2025-04-22 00:58:34,700:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                  (29163, 2)
4        Transformed data shape                  (40377, 2)
5   Transformed train set shape                  (31628, 2)
6    Transformed test set shape                   (8749, 2)
7              Numeric features                           1
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name    baseline_after_selection
22                          USI                        3805
2025-04-22 00:58:34,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:34,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:34,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:34,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 00:58:34,825:INFO:setup() successfully completed in 3.72s...............
2025-04-22 00:58:34,826:INFO:Initializing compare_models()
2025-04-22 00:58:34,826:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 00:58:34,826:INFO:Checking exceptions
2025-04-22 00:58:34,830:INFO:Preparing display monitor
2025-04-22 00:58:34,848:INFO:Initializing Logistic Regression
2025-04-22 00:58:34,848:INFO:Total runtime is 0.0 minutes
2025-04-22 00:58:34,851:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:34,851:INFO:Initializing create_model()
2025-04-22 00:58:34,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:34,851:INFO:Checking exceptions
2025-04-22 00:58:34,851:INFO:Importing libraries
2025-04-22 00:58:34,852:INFO:Copying training dataset
2025-04-22 00:58:34,856:INFO:Defining folds
2025-04-22 00:58:34,856:INFO:Declaring metric variables
2025-04-22 00:58:34,859:INFO:Importing untrained model
2025-04-22 00:58:34,862:INFO:Logistic Regression Imported successfully
2025-04-22 00:58:34,868:INFO:Starting cross validation
2025-04-22 00:58:34,869:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:41,797:INFO:Calculating mean and std
2025-04-22 00:58:41,798:INFO:Creating metrics dataframe
2025-04-22 00:58:41,800:INFO:Uploading results into container
2025-04-22 00:58:41,800:INFO:Uploading model into container now
2025-04-22 00:58:41,800:INFO:_master_model_container: 1
2025-04-22 00:58:41,800:INFO:_display_container: 2
2025-04-22 00:58:41,801:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 00:58:41,801:INFO:create_model() successfully completed......................................
2025-04-22 00:58:41,976:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:41,976:INFO:Creating metrics dataframe
2025-04-22 00:58:41,982:INFO:Initializing K Neighbors Classifier
2025-04-22 00:58:41,982:INFO:Total runtime is 0.1189053217569987 minutes
2025-04-22 00:58:41,985:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:41,985:INFO:Initializing create_model()
2025-04-22 00:58:41,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:41,985:INFO:Checking exceptions
2025-04-22 00:58:41,985:INFO:Importing libraries
2025-04-22 00:58:41,985:INFO:Copying training dataset
2025-04-22 00:58:41,989:INFO:Defining folds
2025-04-22 00:58:41,990:INFO:Declaring metric variables
2025-04-22 00:58:41,992:INFO:Importing untrained model
2025-04-22 00:58:41,996:INFO:K Neighbors Classifier Imported successfully
2025-04-22 00:58:42,001:INFO:Starting cross validation
2025-04-22 00:58:42,002:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:47,507:INFO:Calculating mean and std
2025-04-22 00:58:47,508:INFO:Creating metrics dataframe
2025-04-22 00:58:47,509:INFO:Uploading results into container
2025-04-22 00:58:47,510:INFO:Uploading model into container now
2025-04-22 00:58:47,510:INFO:_master_model_container: 2
2025-04-22 00:58:47,510:INFO:_display_container: 2
2025-04-22 00:58:47,510:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 00:58:47,510:INFO:create_model() successfully completed......................................
2025-04-22 00:58:47,667:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:47,667:INFO:Creating metrics dataframe
2025-04-22 00:58:47,672:INFO:Initializing Naive Bayes
2025-04-22 00:58:47,672:INFO:Total runtime is 0.21374156475067138 minutes
2025-04-22 00:58:47,675:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:47,675:INFO:Initializing create_model()
2025-04-22 00:58:47,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:47,675:INFO:Checking exceptions
2025-04-22 00:58:47,675:INFO:Importing libraries
2025-04-22 00:58:47,675:INFO:Copying training dataset
2025-04-22 00:58:47,680:INFO:Defining folds
2025-04-22 00:58:47,680:INFO:Declaring metric variables
2025-04-22 00:58:47,683:INFO:Importing untrained model
2025-04-22 00:58:47,686:INFO:Naive Bayes Imported successfully
2025-04-22 00:58:47,692:INFO:Starting cross validation
2025-04-22 00:58:47,696:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:51,203:INFO:Calculating mean and std
2025-04-22 00:58:51,205:INFO:Creating metrics dataframe
2025-04-22 00:58:51,206:INFO:Uploading results into container
2025-04-22 00:58:51,207:INFO:Uploading model into container now
2025-04-22 00:58:51,208:INFO:_master_model_container: 3
2025-04-22 00:58:51,208:INFO:_display_container: 2
2025-04-22 00:58:51,208:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 00:58:51,208:INFO:create_model() successfully completed......................................
2025-04-22 00:58:51,379:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:51,379:INFO:Creating metrics dataframe
2025-04-22 00:58:51,384:INFO:Initializing Decision Tree Classifier
2025-04-22 00:58:51,384:INFO:Total runtime is 0.275603179136912 minutes
2025-04-22 00:58:51,387:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:51,387:INFO:Initializing create_model()
2025-04-22 00:58:51,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:51,387:INFO:Checking exceptions
2025-04-22 00:58:51,387:INFO:Importing libraries
2025-04-22 00:58:51,387:INFO:Copying training dataset
2025-04-22 00:58:51,391:INFO:Defining folds
2025-04-22 00:58:51,391:INFO:Declaring metric variables
2025-04-22 00:58:51,394:INFO:Importing untrained model
2025-04-22 00:58:51,398:INFO:Decision Tree Classifier Imported successfully
2025-04-22 00:58:51,403:INFO:Starting cross validation
2025-04-22 00:58:51,404:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:54,548:INFO:Calculating mean and std
2025-04-22 00:58:54,549:INFO:Creating metrics dataframe
2025-04-22 00:58:54,551:INFO:Uploading results into container
2025-04-22 00:58:54,551:INFO:Uploading model into container now
2025-04-22 00:58:54,552:INFO:_master_model_container: 4
2025-04-22 00:58:54,552:INFO:_display_container: 2
2025-04-22 00:58:54,552:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 00:58:54,552:INFO:create_model() successfully completed......................................
2025-04-22 00:58:54,704:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:54,704:INFO:Creating metrics dataframe
2025-04-22 00:58:54,710:INFO:Initializing SVM - Linear Kernel
2025-04-22 00:58:54,710:INFO:Total runtime is 0.33104407787323 minutes
2025-04-22 00:58:54,712:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:54,712:INFO:Initializing create_model()
2025-04-22 00:58:54,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:54,713:INFO:Checking exceptions
2025-04-22 00:58:54,713:INFO:Importing libraries
2025-04-22 00:58:54,713:INFO:Copying training dataset
2025-04-22 00:58:54,717:INFO:Defining folds
2025-04-22 00:58:54,717:INFO:Declaring metric variables
2025-04-22 00:58:54,720:INFO:Importing untrained model
2025-04-22 00:58:54,722:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 00:58:54,729:INFO:Starting cross validation
2025-04-22 00:58:54,730:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:55,972:INFO:Calculating mean and std
2025-04-22 00:58:55,973:INFO:Creating metrics dataframe
2025-04-22 00:58:55,974:INFO:Uploading results into container
2025-04-22 00:58:55,975:INFO:Uploading model into container now
2025-04-22 00:58:55,975:INFO:_master_model_container: 5
2025-04-22 00:58:55,975:INFO:_display_container: 2
2025-04-22 00:58:55,976:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 00:58:55,976:INFO:create_model() successfully completed......................................
2025-04-22 00:58:56,124:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:56,124:INFO:Creating metrics dataframe
2025-04-22 00:58:56,130:INFO:Initializing Ridge Classifier
2025-04-22 00:58:56,130:INFO:Total runtime is 0.35470077991485593 minutes
2025-04-22 00:58:56,133:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:56,133:INFO:Initializing create_model()
2025-04-22 00:58:56,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:56,133:INFO:Checking exceptions
2025-04-22 00:58:56,133:INFO:Importing libraries
2025-04-22 00:58:56,134:INFO:Copying training dataset
2025-04-22 00:58:56,139:INFO:Defining folds
2025-04-22 00:58:56,139:INFO:Declaring metric variables
2025-04-22 00:58:56,141:INFO:Importing untrained model
2025-04-22 00:58:56,145:INFO:Ridge Classifier Imported successfully
2025-04-22 00:58:56,149:INFO:Starting cross validation
2025-04-22 00:58:56,150:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:57,370:INFO:Calculating mean and std
2025-04-22 00:58:57,371:INFO:Creating metrics dataframe
2025-04-22 00:58:57,373:INFO:Uploading results into container
2025-04-22 00:58:57,373:INFO:Uploading model into container now
2025-04-22 00:58:57,373:INFO:_master_model_container: 6
2025-04-22 00:58:57,374:INFO:_display_container: 2
2025-04-22 00:58:57,374:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 00:58:57,374:INFO:create_model() successfully completed......................................
2025-04-22 00:58:57,526:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:57,527:INFO:Creating metrics dataframe
2025-04-22 00:58:57,532:INFO:Initializing Random Forest Classifier
2025-04-22 00:58:57,532:INFO:Total runtime is 0.3780770381291707 minutes
2025-04-22 00:58:57,535:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:57,536:INFO:Initializing create_model()
2025-04-22 00:58:57,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:57,536:INFO:Checking exceptions
2025-04-22 00:58:57,536:INFO:Importing libraries
2025-04-22 00:58:57,536:INFO:Copying training dataset
2025-04-22 00:58:57,542:INFO:Defining folds
2025-04-22 00:58:57,542:INFO:Declaring metric variables
2025-04-22 00:58:57,544:INFO:Importing untrained model
2025-04-22 00:58:57,547:INFO:Random Forest Classifier Imported successfully
2025-04-22 00:58:57,551:INFO:Starting cross validation
2025-04-22 00:58:57,552:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:58:59,577:INFO:Calculating mean and std
2025-04-22 00:58:59,578:INFO:Creating metrics dataframe
2025-04-22 00:58:59,580:INFO:Uploading results into container
2025-04-22 00:58:59,580:INFO:Uploading model into container now
2025-04-22 00:58:59,581:INFO:_master_model_container: 7
2025-04-22 00:58:59,581:INFO:_display_container: 2
2025-04-22 00:58:59,581:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 00:58:59,581:INFO:create_model() successfully completed......................................
2025-04-22 00:58:59,744:INFO:SubProcess create_model() end ==================================
2025-04-22 00:58:59,744:INFO:Creating metrics dataframe
2025-04-22 00:58:59,750:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 00:58:59,750:INFO:Total runtime is 0.4150350213050842 minutes
2025-04-22 00:58:59,752:INFO:SubProcess create_model() called ==================================
2025-04-22 00:58:59,752:INFO:Initializing create_model()
2025-04-22 00:58:59,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:58:59,753:INFO:Checking exceptions
2025-04-22 00:58:59,753:INFO:Importing libraries
2025-04-22 00:58:59,753:INFO:Copying training dataset
2025-04-22 00:58:59,758:INFO:Defining folds
2025-04-22 00:58:59,758:INFO:Declaring metric variables
2025-04-22 00:58:59,761:INFO:Importing untrained model
2025-04-22 00:58:59,764:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 00:58:59,769:INFO:Starting cross validation
2025-04-22 00:58:59,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:01,116:INFO:Calculating mean and std
2025-04-22 00:59:01,117:INFO:Creating metrics dataframe
2025-04-22 00:59:01,118:INFO:Uploading results into container
2025-04-22 00:59:01,119:INFO:Uploading model into container now
2025-04-22 00:59:01,119:INFO:_master_model_container: 8
2025-04-22 00:59:01,119:INFO:_display_container: 2
2025-04-22 00:59:01,119:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 00:59:01,119:INFO:create_model() successfully completed......................................
2025-04-22 00:59:01,275:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:01,275:INFO:Creating metrics dataframe
2025-04-22 00:59:01,283:INFO:Initializing Ada Boost Classifier
2025-04-22 00:59:01,283:INFO:Total runtime is 0.44058723847071324 minutes
2025-04-22 00:59:01,286:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:01,286:INFO:Initializing create_model()
2025-04-22 00:59:01,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:01,286:INFO:Checking exceptions
2025-04-22 00:59:01,286:INFO:Importing libraries
2025-04-22 00:59:01,286:INFO:Copying training dataset
2025-04-22 00:59:01,292:INFO:Defining folds
2025-04-22 00:59:01,292:INFO:Declaring metric variables
2025-04-22 00:59:01,295:INFO:Importing untrained model
2025-04-22 00:59:01,298:INFO:Ada Boost Classifier Imported successfully
2025-04-22 00:59:01,303:INFO:Starting cross validation
2025-04-22 00:59:01,304:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:02,495:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 00:59:02,542:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 00:59:02,953:INFO:Calculating mean and std
2025-04-22 00:59:02,954:INFO:Creating metrics dataframe
2025-04-22 00:59:02,955:INFO:Uploading results into container
2025-04-22 00:59:02,956:INFO:Uploading model into container now
2025-04-22 00:59:02,956:INFO:_master_model_container: 9
2025-04-22 00:59:02,956:INFO:_display_container: 2
2025-04-22 00:59:02,956:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 00:59:02,956:INFO:create_model() successfully completed......................................
2025-04-22 00:59:03,103:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:03,104:INFO:Creating metrics dataframe
2025-04-22 00:59:03,111:INFO:Initializing Gradient Boosting Classifier
2025-04-22 00:59:03,111:INFO:Total runtime is 0.47105099360148106 minutes
2025-04-22 00:59:03,114:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:03,114:INFO:Initializing create_model()
2025-04-22 00:59:03,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:03,114:INFO:Checking exceptions
2025-04-22 00:59:03,114:INFO:Importing libraries
2025-04-22 00:59:03,114:INFO:Copying training dataset
2025-04-22 00:59:03,118:INFO:Defining folds
2025-04-22 00:59:03,119:INFO:Declaring metric variables
2025-04-22 00:59:03,121:INFO:Importing untrained model
2025-04-22 00:59:03,124:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 00:59:03,130:INFO:Starting cross validation
2025-04-22 00:59:03,131:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:05,067:INFO:Calculating mean and std
2025-04-22 00:59:05,068:INFO:Creating metrics dataframe
2025-04-22 00:59:05,070:INFO:Uploading results into container
2025-04-22 00:59:05,070:INFO:Uploading model into container now
2025-04-22 00:59:05,071:INFO:_master_model_container: 10
2025-04-22 00:59:05,071:INFO:_display_container: 2
2025-04-22 00:59:05,071:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 00:59:05,071:INFO:create_model() successfully completed......................................
2025-04-22 00:59:05,213:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:05,213:INFO:Creating metrics dataframe
2025-04-22 00:59:05,220:INFO:Initializing Linear Discriminant Analysis
2025-04-22 00:59:05,220:INFO:Total runtime is 0.5061990141868591 minutes
2025-04-22 00:59:05,223:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:05,223:INFO:Initializing create_model()
2025-04-22 00:59:05,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:05,223:INFO:Checking exceptions
2025-04-22 00:59:05,223:INFO:Importing libraries
2025-04-22 00:59:05,223:INFO:Copying training dataset
2025-04-22 00:59:05,228:INFO:Defining folds
2025-04-22 00:59:05,228:INFO:Declaring metric variables
2025-04-22 00:59:05,231:INFO:Importing untrained model
2025-04-22 00:59:05,234:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 00:59:05,240:INFO:Starting cross validation
2025-04-22 00:59:05,241:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:06,472:INFO:Calculating mean and std
2025-04-22 00:59:06,474:INFO:Creating metrics dataframe
2025-04-22 00:59:06,476:INFO:Uploading results into container
2025-04-22 00:59:06,476:INFO:Uploading model into container now
2025-04-22 00:59:06,477:INFO:_master_model_container: 11
2025-04-22 00:59:06,477:INFO:_display_container: 2
2025-04-22 00:59:06,477:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 00:59:06,477:INFO:create_model() successfully completed......................................
2025-04-22 00:59:06,618:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:06,619:INFO:Creating metrics dataframe
2025-04-22 00:59:06,625:INFO:Initializing Extra Trees Classifier
2025-04-22 00:59:06,625:INFO:Total runtime is 0.5296194950739542 minutes
2025-04-22 00:59:06,628:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:06,628:INFO:Initializing create_model()
2025-04-22 00:59:06,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:06,629:INFO:Checking exceptions
2025-04-22 00:59:06,629:INFO:Importing libraries
2025-04-22 00:59:06,629:INFO:Copying training dataset
2025-04-22 00:59:06,633:INFO:Defining folds
2025-04-22 00:59:06,633:INFO:Declaring metric variables
2025-04-22 00:59:06,636:INFO:Importing untrained model
2025-04-22 00:59:06,639:INFO:Extra Trees Classifier Imported successfully
2025-04-22 00:59:06,644:INFO:Starting cross validation
2025-04-22 00:59:06,645:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:08,291:INFO:Calculating mean and std
2025-04-22 00:59:08,292:INFO:Creating metrics dataframe
2025-04-22 00:59:08,294:INFO:Uploading results into container
2025-04-22 00:59:08,294:INFO:Uploading model into container now
2025-04-22 00:59:08,295:INFO:_master_model_container: 12
2025-04-22 00:59:08,295:INFO:_display_container: 2
2025-04-22 00:59:08,295:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 00:59:08,295:INFO:create_model() successfully completed......................................
2025-04-22 00:59:08,445:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:08,445:INFO:Creating metrics dataframe
2025-04-22 00:59:08,453:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 00:59:08,453:INFO:Total runtime is 0.5600837548573812 minutes
2025-04-22 00:59:08,455:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:08,455:INFO:Initializing create_model()
2025-04-22 00:59:08,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:08,456:INFO:Checking exceptions
2025-04-22 00:59:08,456:INFO:Importing libraries
2025-04-22 00:59:08,456:INFO:Copying training dataset
2025-04-22 00:59:08,461:INFO:Defining folds
2025-04-22 00:59:08,461:INFO:Declaring metric variables
2025-04-22 00:59:08,464:INFO:Importing untrained model
2025-04-22 00:59:08,467:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 00:59:08,472:INFO:Starting cross validation
2025-04-22 00:59:08,473:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:10,155:INFO:Calculating mean and std
2025-04-22 00:59:10,157:INFO:Creating metrics dataframe
2025-04-22 00:59:10,159:INFO:Uploading results into container
2025-04-22 00:59:10,160:INFO:Uploading model into container now
2025-04-22 00:59:10,160:INFO:_master_model_container: 13
2025-04-22 00:59:10,160:INFO:_display_container: 2
2025-04-22 00:59:10,161:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 00:59:10,161:INFO:create_model() successfully completed......................................
2025-04-22 00:59:10,326:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:10,326:INFO:Creating metrics dataframe
2025-04-22 00:59:10,333:INFO:Initializing Dummy Classifier
2025-04-22 00:59:10,333:INFO:Total runtime is 0.5914240360260009 minutes
2025-04-22 00:59:10,336:INFO:SubProcess create_model() called ==================================
2025-04-22 00:59:10,336:INFO:Initializing create_model()
2025-04-22 00:59:10,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4ADFAC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:10,336:INFO:Checking exceptions
2025-04-22 00:59:10,336:INFO:Importing libraries
2025-04-22 00:59:10,336:INFO:Copying training dataset
2025-04-22 00:59:10,342:INFO:Defining folds
2025-04-22 00:59:10,342:INFO:Declaring metric variables
2025-04-22 00:59:10,345:INFO:Importing untrained model
2025-04-22 00:59:10,348:INFO:Dummy Classifier Imported successfully
2025-04-22 00:59:10,352:INFO:Starting cross validation
2025-04-22 00:59:10,353:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 00:59:11,543:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 00:59:11,556:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 00:59:11,560:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 00:59:11,571:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 00:59:11,586:INFO:Calculating mean and std
2025-04-22 00:59:11,587:INFO:Creating metrics dataframe
2025-04-22 00:59:11,589:INFO:Uploading results into container
2025-04-22 00:59:11,589:INFO:Uploading model into container now
2025-04-22 00:59:11,589:INFO:_master_model_container: 14
2025-04-22 00:59:11,589:INFO:_display_container: 2
2025-04-22 00:59:11,589:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 00:59:11,591:INFO:create_model() successfully completed......................................
2025-04-22 00:59:11,739:INFO:SubProcess create_model() end ==================================
2025-04-22 00:59:11,739:INFO:Creating metrics dataframe
2025-04-22 00:59:11,749:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 00:59:11,755:INFO:Initializing create_model()
2025-04-22 00:59:11,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 00:59:11,755:INFO:Checking exceptions
2025-04-22 00:59:11,756:INFO:Importing libraries
2025-04-22 00:59:11,757:INFO:Copying training dataset
2025-04-22 00:59:11,761:INFO:Defining folds
2025-04-22 00:59:11,761:INFO:Declaring metric variables
2025-04-22 00:59:11,761:INFO:Importing untrained model
2025-04-22 00:59:11,761:INFO:Declaring custom model
2025-04-22 00:59:11,761:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 00:59:11,763:INFO:Cross validation set to False
2025-04-22 00:59:11,763:INFO:Fitting Model
2025-04-22 00:59:14,022:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 00:59:14,022:INFO:create_model() successfully completed......................................
2025-04-22 00:59:14,185:INFO:_master_model_container: 14
2025-04-22 00:59:14,185:INFO:_display_container: 2
2025-04-22 00:59:14,186:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 00:59:14,186:INFO:compare_models() successfully completed......................................
2025-04-22 01:01:34,699:INFO:Initializing create_model()
2025-04-22 01:01:34,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:01:34,699:INFO:Checking exceptions
2025-04-22 01:01:34,713:INFO:Importing libraries
2025-04-22 01:01:34,713:INFO:Copying training dataset
2025-04-22 01:01:34,719:INFO:Defining folds
2025-04-22 01:01:34,720:INFO:Declaring metric variables
2025-04-22 01:01:34,723:INFO:Importing untrained model
2025-04-22 01:01:34,726:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 01:01:34,733:INFO:Starting cross validation
2025-04-22 01:01:34,734:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:01:36,595:INFO:Calculating mean and std
2025-04-22 01:01:36,597:INFO:Creating metrics dataframe
2025-04-22 01:01:36,601:INFO:Finalizing model
2025-04-22 01:01:38,859:INFO:Uploading results into container
2025-04-22 01:01:38,860:INFO:Uploading model into container now
2025-04-22 01:01:38,867:INFO:_master_model_container: 15
2025-04-22 01:01:38,867:INFO:_display_container: 3
2025-04-22 01:01:38,868:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 01:01:38,868:INFO:create_model() successfully completed......................................
2025-04-22 01:01:39,014:INFO:Initializing predict_model()
2025-04-22 01:01:39,014:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017E4CBEB560>)
2025-04-22 01:01:39,014:INFO:Checking exceptions
2025-04-22 01:01:39,014:INFO:Preloading libraries
2025-04-22 01:01:42,541:INFO:Initializing tune_model()
2025-04-22 01:01:42,541:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E4B22B6D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 01:01:42,541:INFO:Checking exceptions
2025-04-22 01:01:42,555:INFO:Copying training dataset
2025-04-22 01:01:42,559:INFO:Checking base model
2025-04-22 01:01:42,559:INFO:Base model : Gradient Boosting Classifier
2025-04-22 01:01:42,562:INFO:Declaring metric variables
2025-04-22 01:01:42,565:INFO:Defining Hyperparameters
2025-04-22 01:01:42,717:INFO:Tuning with n_jobs=-1
2025-04-22 01:01:42,717:INFO:Initializing RandomizedSearchCV
2025-04-22 01:05:36,763:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:36,764:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:36,842:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:36,844:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:36,923:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:36,924:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:37,006:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:37,007:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:37,085:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:37,086:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:37,167:WARNING:<ipython-input-69-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:37,168:WARNING:<ipython-input-69-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 01:05:54,015:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:54,016:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:54,202:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:54,204:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:54,705:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:54,706:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:54,884:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:54,885:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:55,064:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:55,065:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:55,241:WARNING:<ipython-input-73-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 01:05:55,242:WARNING:<ipython-input-73-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 01:05:56,688:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-22 01:05:57,125:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-22 01:05:57,126:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 01:54:21,246:INFO:PyCaret ClassificationExperiment
2025-04-22 01:54:21,246:INFO:Logging name: baseline_after_selection
2025-04-22 01:54:21,246:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 01:54:21,246:INFO:version 3.3.2
2025-04-22 01:54:21,246:INFO:Initializing setup()
2025-04-22 01:54:21,246:INFO:self.USI: 8f1b
2025-04-22 01:54:21,246:INFO:self._variable_keys: {'pipeline', 'logging_param', 'y', '_available_plots', 'log_plots_param', 'y_train', 'idx', 'exp_id', 'gpu_param', 'fold_shuffle_param', 'X', 'html_param', 'y_test', 'X_train', 'n_jobs_param', 'seed', 'fold_generator', 'X_test', 'fix_imbalance', 'target_param', 'data', 'exp_name_log', 'memory', 'gpu_n_jobs_param', 'fold_groups_param', 'is_multiclass', '_ml_usecase', 'USI'}
2025-04-22 01:54:21,246:INFO:Checking environment
2025-04-22 01:54:21,246:INFO:python_version: 3.11.4
2025-04-22 01:54:21,246:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 01:54:21,246:INFO:machine: AMD64
2025-04-22 01:54:21,246:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 01:54:21,256:INFO:Memory: svmem(total=16498810880, available=3799953408, percent=77.0, used=12698857472, free=3799953408)
2025-04-22 01:54:21,257:INFO:Physical Core: 8
2025-04-22 01:54:21,257:INFO:Logical Core: 16
2025-04-22 01:54:21,257:INFO:Checking libraries
2025-04-22 01:54:21,257:INFO:System:
2025-04-22 01:54:21,257:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 01:54:21,257:INFO:executable: c:\Python311\python.exe
2025-04-22 01:54:21,257:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 01:54:21,257:INFO:PyCaret required dependencies:
2025-04-22 01:54:21,257:INFO:                 pip: 23.1.2
2025-04-22 01:54:21,257:INFO:          setuptools: 65.5.0
2025-04-22 01:54:21,257:INFO:             pycaret: 3.3.2
2025-04-22 01:54:21,257:INFO:             IPython: 8.20.0
2025-04-22 01:54:21,257:INFO:          ipywidgets: 8.1.6
2025-04-22 01:54:21,257:INFO:                tqdm: 4.66.2
2025-04-22 01:54:21,257:INFO:               numpy: 1.26.2
2025-04-22 01:54:21,257:INFO:              pandas: 2.1.4
2025-04-22 01:54:21,257:INFO:              jinja2: 3.1.2
2025-04-22 01:54:21,257:INFO:               scipy: 1.11.4
2025-04-22 01:54:21,257:INFO:              joblib: 1.3.2
2025-04-22 01:54:21,257:INFO:             sklearn: 1.4.2
2025-04-22 01:54:21,257:INFO:                pyod: 2.0.4
2025-04-22 01:54:21,257:INFO:            imblearn: 0.12.0
2025-04-22 01:54:21,257:INFO:   category_encoders: 2.7.0
2025-04-22 01:54:21,257:INFO:            lightgbm: 4.6.0
2025-04-22 01:54:21,257:INFO:               numba: 0.61.2
2025-04-22 01:54:21,257:INFO:            requests: 2.31.0
2025-04-22 01:54:21,257:INFO:          matplotlib: 3.7.5
2025-04-22 01:54:21,257:INFO:          scikitplot: 0.3.7
2025-04-22 01:54:21,257:INFO:         yellowbrick: 1.5
2025-04-22 01:54:21,258:INFO:              plotly: 5.24.1
2025-04-22 01:54:21,258:INFO:    plotly-resampler: Not installed
2025-04-22 01:54:21,258:INFO:             kaleido: 0.2.1
2025-04-22 01:54:21,258:INFO:           schemdraw: 0.15
2025-04-22 01:54:21,258:INFO:         statsmodels: 0.14.4
2025-04-22 01:54:21,258:INFO:              sktime: 0.26.0
2025-04-22 01:54:21,258:INFO:               tbats: 1.1.3
2025-04-22 01:54:21,258:INFO:            pmdarima: 2.0.4
2025-04-22 01:54:21,258:INFO:              psutil: 5.9.8
2025-04-22 01:54:21,258:INFO:          markupsafe: 2.1.3
2025-04-22 01:54:21,258:INFO:             pickle5: Not installed
2025-04-22 01:54:21,258:INFO:         cloudpickle: 3.1.1
2025-04-22 01:54:21,258:INFO:         deprecation: 2.1.0
2025-04-22 01:54:21,258:INFO:              xxhash: 3.5.0
2025-04-22 01:54:21,258:INFO:           wurlitzer: Not installed
2025-04-22 01:54:21,258:INFO:PyCaret optional dependencies:
2025-04-22 01:54:21,258:INFO:                shap: Not installed
2025-04-22 01:54:21,258:INFO:           interpret: Not installed
2025-04-22 01:54:21,258:INFO:                umap: Not installed
2025-04-22 01:54:21,258:INFO:     ydata_profiling: Not installed
2025-04-22 01:54:21,258:INFO:  explainerdashboard: Not installed
2025-04-22 01:54:21,258:INFO:             autoviz: Not installed
2025-04-22 01:54:21,258:INFO:           fairlearn: Not installed
2025-04-22 01:54:21,258:INFO:          deepchecks: Not installed
2025-04-22 01:54:21,258:INFO:             xgboost: Not installed
2025-04-22 01:54:21,258:INFO:            catboost: Not installed
2025-04-22 01:54:21,258:INFO:              kmodes: Not installed
2025-04-22 01:54:21,258:INFO:             mlxtend: 0.23.4
2025-04-22 01:54:21,258:INFO:       statsforecast: Not installed
2025-04-22 01:54:21,258:INFO:        tune_sklearn: Not installed
2025-04-22 01:54:21,259:INFO:                 ray: Not installed
2025-04-22 01:54:21,259:INFO:            hyperopt: Not installed
2025-04-22 01:54:21,259:INFO:              optuna: Not installed
2025-04-22 01:54:21,259:INFO:               skopt: Not installed
2025-04-22 01:54:21,259:INFO:              mlflow: Not installed
2025-04-22 01:54:21,259:INFO:              gradio: Not installed
2025-04-22 01:54:21,259:INFO:             fastapi: Not installed
2025-04-22 01:54:21,259:INFO:             uvicorn: Not installed
2025-04-22 01:54:21,259:INFO:              m2cgen: Not installed
2025-04-22 01:54:21,259:INFO:           evidently: Not installed
2025-04-22 01:54:21,259:INFO:               fugue: Not installed
2025-04-22 01:54:21,259:INFO:           streamlit: Not installed
2025-04-22 01:54:21,259:INFO:             prophet: Not installed
2025-04-22 01:54:21,259:INFO:None
2025-04-22 01:54:21,259:INFO:Set up data.
2025-04-22 01:54:21,264:INFO:Set up folding strategy.
2025-04-22 01:54:21,264:INFO:Set up train/test split.
2025-04-22 01:54:21,273:INFO:Set up index.
2025-04-22 01:54:21,273:INFO:Assigning column types.
2025-04-22 01:54:21,277:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 01:54:21,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,315:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,371:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,372:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,395:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 01:54:21,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 01:54:21,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,513:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 01:54:21,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:21,635:INFO:Preparing preprocessing pipeline...
2025-04-22 01:54:21,636:INFO:Set up simple imputation.
2025-04-22 01:54:21,636:INFO:Set up imbalanced handling.
2025-04-22 01:54:21,636:INFO:Set up feature normalization.
2025-04-22 01:54:22,975:INFO:Finished creating preprocessing pipeline.
2025-04-22 01:54:22,982:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sept_Pay_status',
                                             'May_Pay_status',
                                             'momentum_stability_flag',
                                             'low_repayment_months_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_value...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-22 01:54:22,982:INFO:Creating final display dataframe.
2025-04-22 01:54:24,321:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                  (29163, 5)
4        Transformed data shape                  (40453, 5)
5   Transformed train set shape                  (31704, 5)
6    Transformed test set shape                   (8749, 5)
7              Numeric features                           4
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name    baseline_after_selection
22                          USI                        8f1b
2025-04-22 01:54:24,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:24,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:24,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:24,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 01:54:24,447:INFO:setup() successfully completed in 3.22s...............
2025-04-22 01:54:24,448:INFO:Initializing compare_models()
2025-04-22 01:54:24,448:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 01:54:24,448:INFO:Checking exceptions
2025-04-22 01:54:24,451:INFO:Preparing display monitor
2025-04-22 01:54:24,468:INFO:Initializing Logistic Regression
2025-04-22 01:54:24,469:INFO:Total runtime is 1.671314239501953e-05 minutes
2025-04-22 01:54:24,471:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:24,471:INFO:Initializing create_model()
2025-04-22 01:54:24,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:24,472:INFO:Checking exceptions
2025-04-22 01:54:24,472:INFO:Importing libraries
2025-04-22 01:54:24,472:INFO:Copying training dataset
2025-04-22 01:54:24,479:INFO:Defining folds
2025-04-22 01:54:24,479:INFO:Declaring metric variables
2025-04-22 01:54:24,482:INFO:Importing untrained model
2025-04-22 01:54:24,484:INFO:Logistic Regression Imported successfully
2025-04-22 01:54:24,489:INFO:Starting cross validation
2025-04-22 01:54:24,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:28,926:INFO:Calculating mean and std
2025-04-22 01:54:28,928:INFO:Creating metrics dataframe
2025-04-22 01:54:28,930:INFO:Uploading results into container
2025-04-22 01:54:28,930:INFO:Uploading model into container now
2025-04-22 01:54:28,931:INFO:_master_model_container: 1
2025-04-22 01:54:28,931:INFO:_display_container: 2
2025-04-22 01:54:28,931:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 01:54:28,931:INFO:create_model() successfully completed......................................
2025-04-22 01:54:29,258:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:29,259:INFO:Creating metrics dataframe
2025-04-22 01:54:29,264:INFO:Initializing K Neighbors Classifier
2025-04-22 01:54:29,264:INFO:Total runtime is 0.07994310855865477 minutes
2025-04-22 01:54:29,268:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:29,268:INFO:Initializing create_model()
2025-04-22 01:54:29,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:29,268:INFO:Checking exceptions
2025-04-22 01:54:29,269:INFO:Importing libraries
2025-04-22 01:54:29,269:INFO:Copying training dataset
2025-04-22 01:54:29,274:INFO:Defining folds
2025-04-22 01:54:29,275:INFO:Declaring metric variables
2025-04-22 01:54:29,277:INFO:Importing untrained model
2025-04-22 01:54:29,280:INFO:K Neighbors Classifier Imported successfully
2025-04-22 01:54:29,284:INFO:Starting cross validation
2025-04-22 01:54:29,285:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:33,917:INFO:Calculating mean and std
2025-04-22 01:54:33,919:INFO:Creating metrics dataframe
2025-04-22 01:54:33,921:INFO:Uploading results into container
2025-04-22 01:54:33,921:INFO:Uploading model into container now
2025-04-22 01:54:33,922:INFO:_master_model_container: 2
2025-04-22 01:54:33,922:INFO:_display_container: 2
2025-04-22 01:54:33,922:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 01:54:33,922:INFO:create_model() successfully completed......................................
2025-04-22 01:54:34,113:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:34,114:INFO:Creating metrics dataframe
2025-04-22 01:54:34,118:INFO:Initializing Naive Bayes
2025-04-22 01:54:34,119:INFO:Total runtime is 0.16085832118988036 minutes
2025-04-22 01:54:34,121:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:34,121:INFO:Initializing create_model()
2025-04-22 01:54:34,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:34,121:INFO:Checking exceptions
2025-04-22 01:54:34,121:INFO:Importing libraries
2025-04-22 01:54:34,122:INFO:Copying training dataset
2025-04-22 01:54:34,127:INFO:Defining folds
2025-04-22 01:54:34,128:INFO:Declaring metric variables
2025-04-22 01:54:34,131:INFO:Importing untrained model
2025-04-22 01:54:34,134:INFO:Naive Bayes Imported successfully
2025-04-22 01:54:34,139:INFO:Starting cross validation
2025-04-22 01:54:34,140:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:37,822:INFO:Calculating mean and std
2025-04-22 01:54:37,823:INFO:Creating metrics dataframe
2025-04-22 01:54:37,826:INFO:Uploading results into container
2025-04-22 01:54:37,827:INFO:Uploading model into container now
2025-04-22 01:54:37,827:INFO:_master_model_container: 3
2025-04-22 01:54:37,827:INFO:_display_container: 2
2025-04-22 01:54:37,828:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 01:54:37,828:INFO:create_model() successfully completed......................................
2025-04-22 01:54:38,050:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:38,051:INFO:Creating metrics dataframe
2025-04-22 01:54:38,056:INFO:Initializing Decision Tree Classifier
2025-04-22 01:54:38,056:INFO:Total runtime is 0.22647013664245605 minutes
2025-04-22 01:54:38,060:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:38,060:INFO:Initializing create_model()
2025-04-22 01:54:38,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:38,060:INFO:Checking exceptions
2025-04-22 01:54:38,060:INFO:Importing libraries
2025-04-22 01:54:38,060:INFO:Copying training dataset
2025-04-22 01:54:38,067:INFO:Defining folds
2025-04-22 01:54:38,067:INFO:Declaring metric variables
2025-04-22 01:54:38,069:INFO:Importing untrained model
2025-04-22 01:54:38,073:INFO:Decision Tree Classifier Imported successfully
2025-04-22 01:54:38,079:INFO:Starting cross validation
2025-04-22 01:54:38,080:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:41,298:INFO:Calculating mean and std
2025-04-22 01:54:41,299:INFO:Creating metrics dataframe
2025-04-22 01:54:41,301:INFO:Uploading results into container
2025-04-22 01:54:41,301:INFO:Uploading model into container now
2025-04-22 01:54:41,302:INFO:_master_model_container: 4
2025-04-22 01:54:41,302:INFO:_display_container: 2
2025-04-22 01:54:41,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 01:54:41,302:INFO:create_model() successfully completed......................................
2025-04-22 01:54:41,510:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:41,510:INFO:Creating metrics dataframe
2025-04-22 01:54:41,517:INFO:Initializing SVM - Linear Kernel
2025-04-22 01:54:41,517:INFO:Total runtime is 0.28414895534515383 minutes
2025-04-22 01:54:41,520:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:41,520:INFO:Initializing create_model()
2025-04-22 01:54:41,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:41,520:INFO:Checking exceptions
2025-04-22 01:54:41,520:INFO:Importing libraries
2025-04-22 01:54:41,520:INFO:Copying training dataset
2025-04-22 01:54:41,527:INFO:Defining folds
2025-04-22 01:54:41,528:INFO:Declaring metric variables
2025-04-22 01:54:41,531:INFO:Importing untrained model
2025-04-22 01:54:41,534:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 01:54:41,541:INFO:Starting cross validation
2025-04-22 01:54:41,542:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:42,914:INFO:Calculating mean and std
2025-04-22 01:54:42,915:INFO:Creating metrics dataframe
2025-04-22 01:54:42,917:INFO:Uploading results into container
2025-04-22 01:54:42,918:INFO:Uploading model into container now
2025-04-22 01:54:42,918:INFO:_master_model_container: 5
2025-04-22 01:54:42,918:INFO:_display_container: 2
2025-04-22 01:54:42,919:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 01:54:42,919:INFO:create_model() successfully completed......................................
2025-04-22 01:54:43,113:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:43,113:INFO:Creating metrics dataframe
2025-04-22 01:54:43,119:INFO:Initializing Ridge Classifier
2025-04-22 01:54:43,119:INFO:Total runtime is 0.3108614524205526 minutes
2025-04-22 01:54:43,122:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:43,122:INFO:Initializing create_model()
2025-04-22 01:54:43,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:43,122:INFO:Checking exceptions
2025-04-22 01:54:43,122:INFO:Importing libraries
2025-04-22 01:54:43,122:INFO:Copying training dataset
2025-04-22 01:54:43,130:INFO:Defining folds
2025-04-22 01:54:43,130:INFO:Declaring metric variables
2025-04-22 01:54:43,133:INFO:Importing untrained model
2025-04-22 01:54:43,136:INFO:Ridge Classifier Imported successfully
2025-04-22 01:54:43,141:INFO:Starting cross validation
2025-04-22 01:54:43,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:44,271:INFO:Calculating mean and std
2025-04-22 01:54:44,273:INFO:Creating metrics dataframe
2025-04-22 01:54:44,275:INFO:Uploading results into container
2025-04-22 01:54:44,276:INFO:Uploading model into container now
2025-04-22 01:54:44,277:INFO:_master_model_container: 6
2025-04-22 01:54:44,277:INFO:_display_container: 2
2025-04-22 01:54:44,278:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 01:54:44,278:INFO:create_model() successfully completed......................................
2025-04-22 01:54:44,471:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:44,471:INFO:Creating metrics dataframe
2025-04-22 01:54:44,477:INFO:Initializing Random Forest Classifier
2025-04-22 01:54:44,477:INFO:Total runtime is 0.3334807316462199 minutes
2025-04-22 01:54:44,480:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:44,481:INFO:Initializing create_model()
2025-04-22 01:54:44,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:44,481:INFO:Checking exceptions
2025-04-22 01:54:44,481:INFO:Importing libraries
2025-04-22 01:54:44,481:INFO:Copying training dataset
2025-04-22 01:54:44,487:INFO:Defining folds
2025-04-22 01:54:44,487:INFO:Declaring metric variables
2025-04-22 01:54:44,490:INFO:Importing untrained model
2025-04-22 01:54:44,495:INFO:Random Forest Classifier Imported successfully
2025-04-22 01:54:44,501:INFO:Starting cross validation
2025-04-22 01:54:44,503:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:46,186:INFO:Calculating mean and std
2025-04-22 01:54:46,187:INFO:Creating metrics dataframe
2025-04-22 01:54:46,189:INFO:Uploading results into container
2025-04-22 01:54:46,189:INFO:Uploading model into container now
2025-04-22 01:54:46,190:INFO:_master_model_container: 7
2025-04-22 01:54:46,190:INFO:_display_container: 2
2025-04-22 01:54:46,190:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 01:54:46,190:INFO:create_model() successfully completed......................................
2025-04-22 01:54:46,380:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:46,380:INFO:Creating metrics dataframe
2025-04-22 01:54:46,386:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 01:54:46,386:INFO:Total runtime is 0.3653108874956767 minutes
2025-04-22 01:54:46,389:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:46,389:INFO:Initializing create_model()
2025-04-22 01:54:46,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:46,389:INFO:Checking exceptions
2025-04-22 01:54:46,389:INFO:Importing libraries
2025-04-22 01:54:46,389:INFO:Copying training dataset
2025-04-22 01:54:46,396:INFO:Defining folds
2025-04-22 01:54:46,396:INFO:Declaring metric variables
2025-04-22 01:54:46,399:INFO:Importing untrained model
2025-04-22 01:54:46,402:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 01:54:46,406:INFO:Starting cross validation
2025-04-22 01:54:46,408:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:47,540:INFO:Calculating mean and std
2025-04-22 01:54:47,542:INFO:Creating metrics dataframe
2025-04-22 01:54:47,544:INFO:Uploading results into container
2025-04-22 01:54:47,545:INFO:Uploading model into container now
2025-04-22 01:54:47,546:INFO:_master_model_container: 8
2025-04-22 01:54:47,546:INFO:_display_container: 2
2025-04-22 01:54:47,547:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 01:54:47,547:INFO:create_model() successfully completed......................................
2025-04-22 01:54:47,756:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:47,756:INFO:Creating metrics dataframe
2025-04-22 01:54:47,762:INFO:Initializing Ada Boost Classifier
2025-04-22 01:54:47,763:INFO:Total runtime is 0.3882359345753988 minutes
2025-04-22 01:54:47,765:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:47,765:INFO:Initializing create_model()
2025-04-22 01:54:47,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:47,765:INFO:Checking exceptions
2025-04-22 01:54:47,765:INFO:Importing libraries
2025-04-22 01:54:47,766:INFO:Copying training dataset
2025-04-22 01:54:47,772:INFO:Defining folds
2025-04-22 01:54:47,772:INFO:Declaring metric variables
2025-04-22 01:54:47,775:INFO:Importing untrained model
2025-04-22 01:54:47,778:INFO:Ada Boost Classifier Imported successfully
2025-04-22 01:54:47,784:INFO:Starting cross validation
2025-04-22 01:54:47,785:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:48,823:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 01:54:48,848:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 01:54:48,864:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 01:54:48,884:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 01:54:48,890:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 01:54:49,374:INFO:Calculating mean and std
2025-04-22 01:54:49,375:INFO:Creating metrics dataframe
2025-04-22 01:54:49,376:INFO:Uploading results into container
2025-04-22 01:54:49,377:INFO:Uploading model into container now
2025-04-22 01:54:49,378:INFO:_master_model_container: 9
2025-04-22 01:54:49,378:INFO:_display_container: 2
2025-04-22 01:54:49,378:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 01:54:49,378:INFO:create_model() successfully completed......................................
2025-04-22 01:54:49,571:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:49,571:INFO:Creating metrics dataframe
2025-04-22 01:54:49,578:INFO:Initializing Gradient Boosting Classifier
2025-04-22 01:54:49,578:INFO:Total runtime is 0.41851118803024295 minutes
2025-04-22 01:54:49,581:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:49,581:INFO:Initializing create_model()
2025-04-22 01:54:49,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:49,581:INFO:Checking exceptions
2025-04-22 01:54:49,581:INFO:Importing libraries
2025-04-22 01:54:49,581:INFO:Copying training dataset
2025-04-22 01:54:49,588:INFO:Defining folds
2025-04-22 01:54:49,588:INFO:Declaring metric variables
2025-04-22 01:54:49,591:INFO:Importing untrained model
2025-04-22 01:54:49,594:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 01:54:49,601:INFO:Starting cross validation
2025-04-22 01:54:49,602:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:51,405:INFO:Calculating mean and std
2025-04-22 01:54:51,405:INFO:Creating metrics dataframe
2025-04-22 01:54:51,408:INFO:Uploading results into container
2025-04-22 01:54:51,408:INFO:Uploading model into container now
2025-04-22 01:54:51,408:INFO:_master_model_container: 10
2025-04-22 01:54:51,409:INFO:_display_container: 2
2025-04-22 01:54:51,409:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 01:54:51,409:INFO:create_model() successfully completed......................................
2025-04-22 01:54:51,598:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:51,598:INFO:Creating metrics dataframe
2025-04-22 01:54:51,605:INFO:Initializing Linear Discriminant Analysis
2025-04-22 01:54:51,605:INFO:Total runtime is 0.45228931109110515 minutes
2025-04-22 01:54:51,607:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:51,608:INFO:Initializing create_model()
2025-04-22 01:54:51,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:51,608:INFO:Checking exceptions
2025-04-22 01:54:51,608:INFO:Importing libraries
2025-04-22 01:54:51,608:INFO:Copying training dataset
2025-04-22 01:54:51,614:INFO:Defining folds
2025-04-22 01:54:51,614:INFO:Declaring metric variables
2025-04-22 01:54:51,617:INFO:Importing untrained model
2025-04-22 01:54:51,620:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 01:54:51,625:INFO:Starting cross validation
2025-04-22 01:54:51,626:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:52,824:INFO:Calculating mean and std
2025-04-22 01:54:52,826:INFO:Creating metrics dataframe
2025-04-22 01:54:52,827:INFO:Uploading results into container
2025-04-22 01:54:52,828:INFO:Uploading model into container now
2025-04-22 01:54:52,828:INFO:_master_model_container: 11
2025-04-22 01:54:52,828:INFO:_display_container: 2
2025-04-22 01:54:52,829:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 01:54:52,829:INFO:create_model() successfully completed......................................
2025-04-22 01:54:53,080:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:53,081:INFO:Creating metrics dataframe
2025-04-22 01:54:53,088:INFO:Initializing Extra Trees Classifier
2025-04-22 01:54:53,088:INFO:Total runtime is 0.4770101189613342 minutes
2025-04-22 01:54:53,091:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:53,092:INFO:Initializing create_model()
2025-04-22 01:54:53,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:53,094:INFO:Checking exceptions
2025-04-22 01:54:53,094:INFO:Importing libraries
2025-04-22 01:54:53,094:INFO:Copying training dataset
2025-04-22 01:54:53,105:INFO:Defining folds
2025-04-22 01:54:53,106:INFO:Declaring metric variables
2025-04-22 01:54:53,108:INFO:Importing untrained model
2025-04-22 01:54:53,112:INFO:Extra Trees Classifier Imported successfully
2025-04-22 01:54:53,118:INFO:Starting cross validation
2025-04-22 01:54:53,120:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:54,800:INFO:Calculating mean and std
2025-04-22 01:54:54,800:INFO:Creating metrics dataframe
2025-04-22 01:54:54,802:INFO:Uploading results into container
2025-04-22 01:54:54,802:INFO:Uploading model into container now
2025-04-22 01:54:54,802:INFO:_master_model_container: 12
2025-04-22 01:54:54,802:INFO:_display_container: 2
2025-04-22 01:54:54,803:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 01:54:54,803:INFO:create_model() successfully completed......................................
2025-04-22 01:54:54,988:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:54,988:INFO:Creating metrics dataframe
2025-04-22 01:54:54,995:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 01:54:54,995:INFO:Total runtime is 0.5087887406349182 minutes
2025-04-22 01:54:54,998:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:54,998:INFO:Initializing create_model()
2025-04-22 01:54:54,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:54,998:INFO:Checking exceptions
2025-04-22 01:54:54,998:INFO:Importing libraries
2025-04-22 01:54:54,998:INFO:Copying training dataset
2025-04-22 01:54:55,004:INFO:Defining folds
2025-04-22 01:54:55,004:INFO:Declaring metric variables
2025-04-22 01:54:55,007:INFO:Importing untrained model
2025-04-22 01:54:55,011:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 01:54:55,016:INFO:Starting cross validation
2025-04-22 01:54:55,017:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:56,746:INFO:Calculating mean and std
2025-04-22 01:54:56,747:INFO:Creating metrics dataframe
2025-04-22 01:54:56,749:INFO:Uploading results into container
2025-04-22 01:54:56,750:INFO:Uploading model into container now
2025-04-22 01:54:56,750:INFO:_master_model_container: 13
2025-04-22 01:54:56,751:INFO:_display_container: 2
2025-04-22 01:54:56,752:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 01:54:56,752:INFO:create_model() successfully completed......................................
2025-04-22 01:54:56,958:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:56,959:INFO:Creating metrics dataframe
2025-04-22 01:54:56,966:INFO:Initializing Dummy Classifier
2025-04-22 01:54:56,966:INFO:Total runtime is 0.5416369875272115 minutes
2025-04-22 01:54:56,969:INFO:SubProcess create_model() called ==================================
2025-04-22 01:54:56,969:INFO:Initializing create_model()
2025-04-22 01:54:56,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E4B34AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:56,969:INFO:Checking exceptions
2025-04-22 01:54:56,969:INFO:Importing libraries
2025-04-22 01:54:56,970:INFO:Copying training dataset
2025-04-22 01:54:56,976:INFO:Defining folds
2025-04-22 01:54:56,976:INFO:Declaring metric variables
2025-04-22 01:54:56,980:INFO:Importing untrained model
2025-04-22 01:54:56,982:INFO:Dummy Classifier Imported successfully
2025-04-22 01:54:56,986:INFO:Starting cross validation
2025-04-22 01:54:56,988:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:54:58,085:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 01:54:58,104:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 01:54:58,156:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 01:54:58,168:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 01:54:58,195:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 01:54:58,203:INFO:Calculating mean and std
2025-04-22 01:54:58,204:INFO:Creating metrics dataframe
2025-04-22 01:54:58,205:INFO:Uploading results into container
2025-04-22 01:54:58,205:INFO:Uploading model into container now
2025-04-22 01:54:58,206:INFO:_master_model_container: 14
2025-04-22 01:54:58,206:INFO:_display_container: 2
2025-04-22 01:54:58,206:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 01:54:58,206:INFO:create_model() successfully completed......................................
2025-04-22 01:54:58,394:INFO:SubProcess create_model() end ==================================
2025-04-22 01:54:58,395:INFO:Creating metrics dataframe
2025-04-22 01:54:58,403:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 01:54:58,410:INFO:Initializing create_model()
2025-04-22 01:54:58,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:54:58,410:INFO:Checking exceptions
2025-04-22 01:54:58,413:INFO:Importing libraries
2025-04-22 01:54:58,413:INFO:Copying training dataset
2025-04-22 01:54:58,418:INFO:Defining folds
2025-04-22 01:54:58,418:INFO:Declaring metric variables
2025-04-22 01:54:58,418:INFO:Importing untrained model
2025-04-22 01:54:58,418:INFO:Declaring custom model
2025-04-22 01:54:58,419:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 01:54:58,420:INFO:Cross validation set to False
2025-04-22 01:54:58,420:INFO:Fitting Model
2025-04-22 01:55:00,297:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 01:55:00,297:INFO:create_model() successfully completed......................................
2025-04-22 01:55:00,501:INFO:_master_model_container: 14
2025-04-22 01:55:00,501:INFO:_display_container: 2
2025-04-22 01:55:00,501:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 01:55:00,501:INFO:compare_models() successfully completed......................................
2025-04-22 01:57:12,315:INFO:Initializing create_model()
2025-04-22 01:57:12,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 01:57:12,316:INFO:Checking exceptions
2025-04-22 01:57:12,328:INFO:Importing libraries
2025-04-22 01:57:12,328:INFO:Copying training dataset
2025-04-22 01:57:12,336:INFO:Defining folds
2025-04-22 01:57:12,336:INFO:Declaring metric variables
2025-04-22 01:57:12,340:INFO:Importing untrained model
2025-04-22 01:57:12,342:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 01:57:12,348:INFO:Starting cross validation
2025-04-22 01:57:12,349:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 01:57:14,024:INFO:Calculating mean and std
2025-04-22 01:57:14,025:INFO:Creating metrics dataframe
2025-04-22 01:57:14,030:INFO:Finalizing model
2025-04-22 01:57:15,927:INFO:Uploading results into container
2025-04-22 01:57:15,928:INFO:Uploading model into container now
2025-04-22 01:57:15,935:INFO:_master_model_container: 15
2025-04-22 01:57:15,935:INFO:_display_container: 3
2025-04-22 01:57:15,935:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 01:57:15,935:INFO:create_model() successfully completed......................................
2025-04-22 01:57:16,125:INFO:Initializing predict_model()
2025-04-22 01:57:16,125:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017E55D18720>)
2025-04-22 01:57:16,125:INFO:Checking exceptions
2025-04-22 01:57:16,125:INFO:Preloading libraries
2025-04-22 01:59:16,025:INFO:Initializing tune_model()
2025-04-22 01:59:16,025:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 01:59:16,025:INFO:Checking exceptions
2025-04-22 01:59:16,041:INFO:Copying training dataset
2025-04-22 01:59:16,046:INFO:Checking base model
2025-04-22 01:59:16,046:INFO:Base model : Gradient Boosting Classifier
2025-04-22 01:59:16,050:INFO:Declaring metric variables
2025-04-22 01:59:16,052:INFO:Defining Hyperparameters
2025-04-22 01:59:16,255:INFO:Tuning with n_jobs=-1
2025-04-22 01:59:16,255:INFO:Initializing RandomizedSearchCV
2025-04-22 02:00:28,404:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-04-22 02:00:28,405:INFO:Hyperparameter search completed
2025-04-22 02:00:28,405:INFO:SubProcess create_model() called ==================================
2025-04-22 02:00:28,406:INFO:Initializing create_model()
2025-04-22 02:00:28,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E48589E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-04-22 02:00:28,406:INFO:Checking exceptions
2025-04-22 02:00:28,406:INFO:Importing libraries
2025-04-22 02:00:28,406:INFO:Copying training dataset
2025-04-22 02:00:28,413:INFO:Defining folds
2025-04-22 02:00:28,413:INFO:Declaring metric variables
2025-04-22 02:00:28,416:INFO:Importing untrained model
2025-04-22 02:00:28,416:INFO:Declaring custom model
2025-04-22 02:00:28,419:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 02:00:28,424:INFO:Starting cross validation
2025-04-22 02:00:28,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:00:30,317:INFO:Calculating mean and std
2025-04-22 02:00:30,319:INFO:Creating metrics dataframe
2025-04-22 02:00:30,322:INFO:Finalizing model
2025-04-22 02:00:32,219:INFO:Uploading results into container
2025-04-22 02:00:32,220:INFO:Uploading model into container now
2025-04-22 02:00:32,221:INFO:_master_model_container: 16
2025-04-22 02:00:32,221:INFO:_display_container: 5
2025-04-22 02:00:32,221:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 02:00:32,221:INFO:create_model() successfully completed......................................
2025-04-22 02:00:32,419:INFO:SubProcess create_model() end ==================================
2025-04-22 02:00:32,419:INFO:choose_better activated
2025-04-22 02:00:32,422:INFO:SubProcess create_model() called ==================================
2025-04-22 02:00:32,423:INFO:Initializing create_model()
2025-04-22 02:00:32,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 02:00:32,423:INFO:Checking exceptions
2025-04-22 02:00:32,424:INFO:Importing libraries
2025-04-22 02:00:32,424:INFO:Copying training dataset
2025-04-22 02:00:32,430:INFO:Defining folds
2025-04-22 02:00:32,430:INFO:Declaring metric variables
2025-04-22 02:00:32,430:INFO:Importing untrained model
2025-04-22 02:00:32,430:INFO:Declaring custom model
2025-04-22 02:00:32,431:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 02:00:32,431:INFO:Starting cross validation
2025-04-22 02:00:32,432:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:00:34,430:INFO:Calculating mean and std
2025-04-22 02:00:34,431:INFO:Creating metrics dataframe
2025-04-22 02:00:34,432:INFO:Finalizing model
2025-04-22 02:00:36,374:INFO:Uploading results into container
2025-04-22 02:00:36,375:INFO:Uploading model into container now
2025-04-22 02:00:36,375:INFO:_master_model_container: 17
2025-04-22 02:00:36,375:INFO:_display_container: 6
2025-04-22 02:00:36,376:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 02:00:36,376:INFO:create_model() successfully completed......................................
2025-04-22 02:00:36,561:INFO:SubProcess create_model() end ==================================
2025-04-22 02:00:36,562:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5349
2025-04-22 02:00:36,562:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5383
2025-04-22 02:00:36,562:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-04-22 02:00:36,562:INFO:choose_better completed
2025-04-22 02:00:36,569:INFO:_master_model_container: 17
2025-04-22 02:00:36,569:INFO:_display_container: 5
2025-04-22 02:00:36,569:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 02:00:36,569:INFO:tune_model() successfully completed......................................
2025-04-22 02:10:06,188:INFO:Initializing create_model()
2025-04-22 02:10:06,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=0, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.4, 'loss': 'log_loss', 'max_depth': 1, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 130, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.6, 'tol': 0.0001, 'validation_fraction': 0.1, 'warm_start': False})
2025-04-22 02:10:06,189:INFO:Checking exceptions
2025-04-22 02:10:17,887:INFO:Initializing create_model()
2025-04-22 02:10:17,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.4, 'loss': 'log_loss', 'max_depth': 1, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 130, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.6, 'tol': 0.0001, 'validation_fraction': 0.1, 'warm_start': False})
2025-04-22 02:10:17,887:INFO:Checking exceptions
2025-04-22 02:10:17,902:INFO:Importing libraries
2025-04-22 02:10:17,902:INFO:Copying training dataset
2025-04-22 02:10:17,913:INFO:Defining folds
2025-04-22 02:10:17,913:INFO:Declaring metric variables
2025-04-22 02:10:17,917:INFO:Importing untrained model
2025-04-22 02:10:17,921:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 02:10:17,927:INFO:Starting cross validation
2025-04-22 02:10:17,929:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:10:23,553:INFO:Calculating mean and std
2025-04-22 02:10:23,554:INFO:Creating metrics dataframe
2025-04-22 02:10:23,560:INFO:Finalizing model
2025-04-22 02:10:25,462:INFO:Uploading results into container
2025-04-22 02:10:25,463:INFO:Uploading model into container now
2025-04-22 02:10:25,470:INFO:_master_model_container: 18
2025-04-22 02:10:25,470:INFO:_display_container: 6
2025-04-22 02:10:25,471:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 02:10:25,471:INFO:create_model() successfully completed......................................
2025-04-22 02:10:25,700:INFO:Initializing predict_model()
2025-04-22 02:10:25,701:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017E52EC1120>)
2025-04-22 02:10:25,701:INFO:Checking exceptions
2025-04-22 02:10:25,701:INFO:Preloading libraries
2025-04-22 02:13:14,772:INFO:Initializing plot_model()
2025-04-22 02:13:14,772:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:14,772:INFO:Checking exceptions
2025-04-22 02:13:14,778:INFO:Preloading libraries
2025-04-22 02:13:14,785:INFO:Copying training dataset
2025-04-22 02:13:14,785:INFO:Plot type: auc
2025-04-22 02:13:14,842:INFO:Fitting Model
2025-04-22 02:13:14,843:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:13:14,843:INFO:Scoring test/hold-out set
2025-04-22 02:13:15,006:INFO:Visual Rendered Successfully
2025-04-22 02:13:15,201:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:15,202:INFO:Initializing plot_model()
2025-04-22 02:13:15,202:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:15,202:INFO:Checking exceptions
2025-04-22 02:13:15,207:INFO:Preloading libraries
2025-04-22 02:13:15,214:INFO:Copying training dataset
2025-04-22 02:13:15,214:INFO:Plot type: confusion_matrix
2025-04-22 02:13:15,269:INFO:Fitting Model
2025-04-22 02:13:15,269:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:13:15,269:INFO:Scoring test/hold-out set
2025-04-22 02:13:15,360:INFO:Visual Rendered Successfully
2025-04-22 02:13:15,548:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:15,549:INFO:Initializing plot_model()
2025-04-22 02:13:15,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:15,549:INFO:Checking exceptions
2025-04-22 02:13:15,554:INFO:Preloading libraries
2025-04-22 02:13:15,560:INFO:Copying training dataset
2025-04-22 02:13:15,560:INFO:Plot type: pr
2025-04-22 02:13:15,615:INFO:Fitting Model
2025-04-22 02:13:15,615:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:13:15,617:INFO:Scoring test/hold-out set
2025-04-22 02:13:15,756:INFO:Visual Rendered Successfully
2025-04-22 02:13:15,945:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:15,946:INFO:Initializing plot_model()
2025-04-22 02:13:15,946:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:15,946:INFO:Checking exceptions
2025-04-22 02:13:15,951:INFO:Preloading libraries
2025-04-22 02:13:15,958:INFO:Copying training dataset
2025-04-22 02:13:15,958:INFO:Plot type: class_report
2025-04-22 02:13:16,012:INFO:Fitting Model
2025-04-22 02:13:16,012:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:13:16,013:INFO:Scoring test/hold-out set
2025-04-22 02:13:16,173:INFO:Visual Rendered Successfully
2025-04-22 02:13:16,366:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:16,366:INFO:Initializing plot_model()
2025-04-22 02:13:16,366:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:16,366:INFO:Checking exceptions
2025-04-22 02:13:16,371:INFO:Preloading libraries
2025-04-22 02:13:16,378:INFO:Copying training dataset
2025-04-22 02:13:16,378:INFO:Plot type: lift
2025-04-22 02:13:16,378:INFO:Generating predictions / predict_proba on X_test
2025-04-22 02:13:16,558:INFO:Visual Rendered Successfully
2025-04-22 02:13:16,750:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:16,751:INFO:Initializing plot_model()
2025-04-22 02:13:16,751:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:16,751:INFO:Checking exceptions
2025-04-22 02:13:16,755:INFO:Preloading libraries
2025-04-22 02:13:16,764:INFO:Copying training dataset
2025-04-22 02:13:16,764:INFO:Plot type: gain
2025-04-22 02:13:16,764:INFO:Generating predictions / predict_proba on X_test
2025-04-22 02:13:16,925:INFO:Visual Rendered Successfully
2025-04-22 02:13:17,120:INFO:plot_model() successfully completed......................................
2025-04-22 02:13:17,120:INFO:Initializing plot_model()
2025-04-22 02:13:17,121:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:13:17,121:INFO:Checking exceptions
2025-04-22 02:13:17,125:INFO:Preloading libraries
2025-04-22 02:13:17,131:INFO:Copying training dataset
2025-04-22 02:13:17,132:INFO:Plot type: feature
2025-04-22 02:13:17,132:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 02:13:17,233:INFO:Visual Rendered Successfully
2025-04-22 02:13:17,430:INFO:plot_model() successfully completed......................................
2025-04-22 02:17:28,745:INFO:Initializing create_model()
2025-04-22 02:17:28,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 02:17:28,745:INFO:Checking exceptions
2025-04-22 02:17:28,760:INFO:Importing libraries
2025-04-22 02:17:28,760:INFO:Copying training dataset
2025-04-22 02:17:28,772:INFO:Defining folds
2025-04-22 02:17:28,772:INFO:Declaring metric variables
2025-04-22 02:17:28,777:INFO:Importing untrained model
2025-04-22 02:17:28,781:INFO:Ada Boost Classifier Imported successfully
2025-04-22 02:17:28,788:INFO:Starting cross validation
2025-04-22 02:17:28,789:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:17:33,093:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:33,103:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:33,139:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:33,139:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:33,145:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:33,641:INFO:Calculating mean and std
2025-04-22 02:17:33,643:INFO:Creating metrics dataframe
2025-04-22 02:17:33,649:INFO:Finalizing model
2025-04-22 02:17:34,929:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:17:35,373:INFO:Uploading results into container
2025-04-22 02:17:35,374:INFO:Uploading model into container now
2025-04-22 02:17:35,380:INFO:_master_model_container: 19
2025-04-22 02:17:35,380:INFO:_display_container: 8
2025-04-22 02:17:35,381:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 02:17:35,381:INFO:create_model() successfully completed......................................
2025-04-22 02:17:35,583:INFO:Initializing predict_model()
2025-04-22 02:17:35,583:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017E4ABD1440>)
2025-04-22 02:17:35,583:INFO:Checking exceptions
2025-04-22 02:17:35,583:INFO:Preloading libraries
2025-04-22 02:17:38,087:INFO:Initializing tune_model()
2025-04-22 02:17:38,087:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 02:17:38,087:INFO:Checking exceptions
2025-04-22 02:17:38,101:INFO:Copying training dataset
2025-04-22 02:17:38,106:INFO:Checking base model
2025-04-22 02:17:38,107:INFO:Base model : Ada Boost Classifier
2025-04-22 02:17:38,109:INFO:Declaring metric variables
2025-04-22 02:17:38,112:INFO:Defining Hyperparameters
2025-04-22 02:17:38,309:INFO:Tuning with n_jobs=-1
2025-04-22 02:17:38,309:INFO:Initializing RandomizedSearchCV
2025-04-22 02:18:43,830:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-04-22 02:18:43,832:INFO:Hyperparameter search completed
2025-04-22 02:18:43,832:INFO:SubProcess create_model() called ==================================
2025-04-22 02:18:43,833:INFO:Initializing create_model()
2025-04-22 02:18:43,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017E48543790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 70, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-04-22 02:18:43,833:INFO:Checking exceptions
2025-04-22 02:18:43,833:INFO:Importing libraries
2025-04-22 02:18:43,833:INFO:Copying training dataset
2025-04-22 02:18:43,841:INFO:Defining folds
2025-04-22 02:18:43,841:INFO:Declaring metric variables
2025-04-22 02:18:43,844:INFO:Importing untrained model
2025-04-22 02:18:43,844:INFO:Declaring custom model
2025-04-22 02:18:43,848:INFO:Ada Boost Classifier Imported successfully
2025-04-22 02:18:43,854:INFO:Starting cross validation
2025-04-22 02:18:43,856:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:18:45,861:INFO:Calculating mean and std
2025-04-22 02:18:45,862:INFO:Creating metrics dataframe
2025-04-22 02:18:45,868:INFO:Finalizing model
2025-04-22 02:18:47,739:INFO:Uploading results into container
2025-04-22 02:18:47,740:INFO:Uploading model into container now
2025-04-22 02:18:47,741:INFO:_master_model_container: 20
2025-04-22 02:18:47,741:INFO:_display_container: 10
2025-04-22 02:18:47,741:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42)
2025-04-22 02:18:47,741:INFO:create_model() successfully completed......................................
2025-04-22 02:18:47,949:INFO:SubProcess create_model() end ==================================
2025-04-22 02:18:47,949:INFO:choose_better activated
2025-04-22 02:18:47,952:INFO:SubProcess create_model() called ==================================
2025-04-22 02:18:47,953:INFO:Initializing create_model()
2025-04-22 02:18:47,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 02:18:47,953:INFO:Checking exceptions
2025-04-22 02:18:47,955:INFO:Importing libraries
2025-04-22 02:18:47,955:INFO:Copying training dataset
2025-04-22 02:18:47,961:INFO:Defining folds
2025-04-22 02:18:47,961:INFO:Declaring metric variables
2025-04-22 02:18:47,961:INFO:Importing untrained model
2025-04-22 02:18:47,961:INFO:Declaring custom model
2025-04-22 02:18:47,961:INFO:Ada Boost Classifier Imported successfully
2025-04-22 02:18:47,961:INFO:Starting cross validation
2025-04-22 02:18:47,962:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:18:49,386:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:49,394:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:49,406:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:49,474:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:49,477:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:50,026:INFO:Calculating mean and std
2025-04-22 02:18:50,026:INFO:Creating metrics dataframe
2025-04-22 02:18:50,028:INFO:Finalizing model
2025-04-22 02:18:51,384:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 02:18:51,826:INFO:Uploading results into container
2025-04-22 02:18:51,827:INFO:Uploading model into container now
2025-04-22 02:18:51,827:INFO:_master_model_container: 21
2025-04-22 02:18:51,827:INFO:_display_container: 11
2025-04-22 02:18:51,827:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 02:18:51,828:INFO:create_model() successfully completed......................................
2025-04-22 02:18:52,020:INFO:SubProcess create_model() end ==================================
2025-04-22 02:18:52,022:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for F1 is 0.5341
2025-04-22 02:18:52,022:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42) result for F1 is 0.5383
2025-04-22 02:18:52,022:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42) is best model
2025-04-22 02:18:52,022:INFO:choose_better completed
2025-04-22 02:18:52,029:INFO:_master_model_container: 21
2025-04-22 02:18:52,029:INFO:_display_container: 10
2025-04-22 02:18:52,030:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42)
2025-04-22 02:18:52,030:INFO:tune_model() successfully completed......................................
2025-04-22 02:21:19,955:INFO:Initializing create_model()
2025-04-22 02:21:19,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'algorithm': 'SAMME', 'learning_rate': 0.2, 'n_estimators': 70, 'random_state': 42})
2025-04-22 02:21:19,956:INFO:Checking exceptions
2025-04-22 02:21:19,968:INFO:Importing libraries
2025-04-22 02:21:19,968:INFO:Copying training dataset
2025-04-22 02:21:19,977:INFO:Defining folds
2025-04-22 02:21:19,977:INFO:Declaring metric variables
2025-04-22 02:21:19,980:INFO:Importing untrained model
2025-04-22 02:21:19,983:INFO:Ada Boost Classifier Imported successfully
2025-04-22 02:21:19,988:INFO:Starting cross validation
2025-04-22 02:21:19,989:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 02:21:21,494:INFO:Calculating mean and std
2025-04-22 02:21:21,495:INFO:Creating metrics dataframe
2025-04-22 02:21:21,499:INFO:Finalizing model
2025-04-22 02:21:23,140:INFO:Uploading results into container
2025-04-22 02:21:23,140:INFO:Uploading model into container now
2025-04-22 02:21:23,148:INFO:_master_model_container: 22
2025-04-22 02:21:23,148:INFO:_display_container: 11
2025-04-22 02:21:23,149:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42)
2025-04-22 02:21:23,149:INFO:create_model() successfully completed......................................
2025-04-22 02:21:23,351:INFO:Initializing predict_model()
2025-04-22 02:21:23,351:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017E48E0D4E0>)
2025-04-22 02:21:23,351:INFO:Checking exceptions
2025-04-22 02:21:23,351:INFO:Preloading libraries
2025-04-22 02:23:03,596:INFO:Initializing plot_model()
2025-04-22 02:23:03,596:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:03,596:INFO:Checking exceptions
2025-04-22 02:23:03,602:INFO:Preloading libraries
2025-04-22 02:23:03,606:INFO:Copying training dataset
2025-04-22 02:23:03,606:INFO:Plot type: auc
2025-04-22 02:23:03,660:INFO:Fitting Model
2025-04-22 02:23:03,661:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:23:03,661:INFO:Scoring test/hold-out set
2025-04-22 02:23:03,852:INFO:Visual Rendered Successfully
2025-04-22 02:23:04,049:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:04,050:INFO:Initializing plot_model()
2025-04-22 02:23:04,050:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:04,050:INFO:Checking exceptions
2025-04-22 02:23:04,055:INFO:Preloading libraries
2025-04-22 02:23:04,058:INFO:Copying training dataset
2025-04-22 02:23:04,059:INFO:Plot type: confusion_matrix
2025-04-22 02:23:04,114:INFO:Fitting Model
2025-04-22 02:23:04,114:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:23:04,115:INFO:Scoring test/hold-out set
2025-04-22 02:23:04,238:INFO:Visual Rendered Successfully
2025-04-22 02:23:04,431:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:04,431:INFO:Initializing plot_model()
2025-04-22 02:23:04,431:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:04,431:INFO:Checking exceptions
2025-04-22 02:23:04,436:INFO:Preloading libraries
2025-04-22 02:23:04,440:INFO:Copying training dataset
2025-04-22 02:23:04,440:INFO:Plot type: pr
2025-04-22 02:23:04,492:INFO:Fitting Model
2025-04-22 02:23:04,493:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:23:04,494:INFO:Scoring test/hold-out set
2025-04-22 02:23:04,661:INFO:Visual Rendered Successfully
2025-04-22 02:23:04,855:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:04,857:INFO:Initializing plot_model()
2025-04-22 02:23:04,857:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:04,857:INFO:Checking exceptions
2025-04-22 02:23:04,862:INFO:Preloading libraries
2025-04-22 02:23:04,866:INFO:Copying training dataset
2025-04-22 02:23:04,866:INFO:Plot type: class_report
2025-04-22 02:23:04,924:INFO:Fitting Model
2025-04-22 02:23:04,924:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-04-22 02:23:04,925:INFO:Scoring test/hold-out set
2025-04-22 02:23:05,115:INFO:Visual Rendered Successfully
2025-04-22 02:23:05,311:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:05,311:INFO:Initializing plot_model()
2025-04-22 02:23:05,313:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:05,313:INFO:Checking exceptions
2025-04-22 02:23:05,318:INFO:Preloading libraries
2025-04-22 02:23:05,322:INFO:Copying training dataset
2025-04-22 02:23:05,322:INFO:Plot type: lift
2025-04-22 02:23:05,322:INFO:Generating predictions / predict_proba on X_test
2025-04-22 02:23:05,505:INFO:Visual Rendered Successfully
2025-04-22 02:23:05,700:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:05,701:INFO:Initializing plot_model()
2025-04-22 02:23:05,701:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:05,701:INFO:Checking exceptions
2025-04-22 02:23:05,706:INFO:Preloading libraries
2025-04-22 02:23:05,710:INFO:Copying training dataset
2025-04-22 02:23:05,710:INFO:Plot type: gain
2025-04-22 02:23:05,710:INFO:Generating predictions / predict_proba on X_test
2025-04-22 02:23:05,888:INFO:Visual Rendered Successfully
2025-04-22 02:23:06,084:INFO:plot_model() successfully completed......................................
2025-04-22 02:23:06,084:INFO:Initializing plot_model()
2025-04-22 02:23:06,084:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017E018EEE90>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 02:23:06,084:INFO:Checking exceptions
2025-04-22 02:23:06,089:INFO:Preloading libraries
2025-04-22 02:23:06,094:INFO:Copying training dataset
2025-04-22 02:23:06,094:INFO:Plot type: feature
2025-04-22 02:23:06,094:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 02:23:06,196:INFO:Visual Rendered Successfully
2025-04-22 02:23:06,387:INFO:plot_model() successfully completed......................................
2025-04-22 19:41:28,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:41:28,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:41:28,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:41:28,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:43:12,108:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-22 19:43:12,554:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-22 19:43:12,555:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 19:44:50,450:WARNING:<ipython-input-34-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:44:50,451:WARNING:<ipython-input-34-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:44:50,542:WARNING:<ipython-input-34-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:44:50,545:WARNING:<ipython-input-34-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:44:50,629:WARNING:<ipython-input-34-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:44:50,630:WARNING:<ipython-input-34-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:44:50,712:WARNING:<ipython-input-34-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:44:50,714:WARNING:<ipython-input-34-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:01,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:45:01,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:45:01,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:45:01,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 19:45:04,210:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,212:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:04,294:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,295:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:04,378:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,379:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:04,465:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,466:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:04,550:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,551:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:04,632:WARNING:<ipython-input-16-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:04,633:WARNING:<ipython-input-16-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:45:05,934:WARNING:<ipython-input-20-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-22 19:45:06,386:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:06,387:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:06,705:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:06,706:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:06,885:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:06,886:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:07,067:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:07,068:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:07,249:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:07,250:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:07,428:WARNING:<ipython-input-21-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:45:07,428:WARNING:<ipython-input-21-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:45:08,856:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-22 19:45:09,299:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-22 19:45:09,300:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 19:53:03,161:INFO:PyCaret ClassificationExperiment
2025-04-22 19:53:03,161:INFO:Logging name: baseline
2025-04-22 19:53:03,161:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 19:53:03,161:INFO:version 3.3.2
2025-04-22 19:53:03,161:INFO:Initializing setup()
2025-04-22 19:53:03,161:INFO:self.USI: 57c4
2025-04-22 19:53:03,161:INFO:self._variable_keys: {'fold_generator', 'y', 'target_param', '_ml_usecase', '_available_plots', 'X_test', 'idx', 'exp_name_log', 'X_train', 'USI', 'logging_param', 'seed', 'html_param', 'gpu_param', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'exp_id', 'y_test', 'y_train', 'X', 'memory', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'is_multiclass'}
2025-04-22 19:53:03,161:INFO:Checking environment
2025-04-22 19:53:03,161:INFO:python_version: 3.11.4
2025-04-22 19:53:03,161:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 19:53:03,161:INFO:machine: AMD64
2025-04-22 19:53:03,161:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 19:53:03,171:INFO:Memory: svmem(total=16498810880, available=5302419456, percent=67.9, used=11196391424, free=5302419456)
2025-04-22 19:53:03,171:INFO:Physical Core: 8
2025-04-22 19:53:03,171:INFO:Logical Core: 16
2025-04-22 19:53:03,171:INFO:Checking libraries
2025-04-22 19:53:03,171:INFO:System:
2025-04-22 19:53:03,171:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 19:53:03,171:INFO:executable: c:\Python311\python.exe
2025-04-22 19:53:03,171:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 19:53:03,171:INFO:PyCaret required dependencies:
2025-04-22 19:53:03,293:INFO:                 pip: 23.1.2
2025-04-22 19:53:03,293:INFO:          setuptools: 65.5.0
2025-04-22 19:53:03,293:INFO:             pycaret: 3.3.2
2025-04-22 19:53:03,293:INFO:             IPython: 8.20.0
2025-04-22 19:53:03,293:INFO:          ipywidgets: 8.1.6
2025-04-22 19:53:03,293:INFO:                tqdm: 4.66.2
2025-04-22 19:53:03,293:INFO:               numpy: 1.26.2
2025-04-22 19:53:03,293:INFO:              pandas: 2.1.4
2025-04-22 19:53:03,293:INFO:              jinja2: 3.1.2
2025-04-22 19:53:03,293:INFO:               scipy: 1.11.4
2025-04-22 19:53:03,293:INFO:              joblib: 1.3.2
2025-04-22 19:53:03,293:INFO:             sklearn: 1.4.2
2025-04-22 19:53:03,293:INFO:                pyod: 2.0.4
2025-04-22 19:53:03,293:INFO:            imblearn: 0.12.0
2025-04-22 19:53:03,293:INFO:   category_encoders: 2.7.0
2025-04-22 19:53:03,293:INFO:            lightgbm: 4.6.0
2025-04-22 19:53:03,293:INFO:               numba: 0.61.2
2025-04-22 19:53:03,293:INFO:            requests: 2.31.0
2025-04-22 19:53:03,294:INFO:          matplotlib: 3.7.5
2025-04-22 19:53:03,294:INFO:          scikitplot: 0.3.7
2025-04-22 19:53:03,294:INFO:         yellowbrick: 1.5
2025-04-22 19:53:03,294:INFO:              plotly: 5.24.1
2025-04-22 19:53:03,294:INFO:    plotly-resampler: Not installed
2025-04-22 19:53:03,294:INFO:             kaleido: 0.2.1
2025-04-22 19:53:03,294:INFO:           schemdraw: 0.15
2025-04-22 19:53:03,294:INFO:         statsmodels: 0.14.4
2025-04-22 19:53:03,294:INFO:              sktime: 0.26.0
2025-04-22 19:53:03,294:INFO:               tbats: 1.1.3
2025-04-22 19:53:03,294:INFO:            pmdarima: 2.0.4
2025-04-22 19:53:03,294:INFO:              psutil: 5.9.8
2025-04-22 19:53:03,294:INFO:          markupsafe: 2.1.3
2025-04-22 19:53:03,294:INFO:             pickle5: Not installed
2025-04-22 19:53:03,294:INFO:         cloudpickle: 3.1.1
2025-04-22 19:53:03,294:INFO:         deprecation: 2.1.0
2025-04-22 19:53:03,294:INFO:              xxhash: 3.5.0
2025-04-22 19:53:03,294:INFO:           wurlitzer: Not installed
2025-04-22 19:53:03,294:INFO:PyCaret optional dependencies:
2025-04-22 19:53:03,307:INFO:                shap: Not installed
2025-04-22 19:53:03,308:INFO:           interpret: Not installed
2025-04-22 19:53:03,308:INFO:                umap: Not installed
2025-04-22 19:53:03,308:INFO:     ydata_profiling: Not installed
2025-04-22 19:53:03,308:INFO:  explainerdashboard: Not installed
2025-04-22 19:53:03,308:INFO:             autoviz: Not installed
2025-04-22 19:53:03,308:INFO:           fairlearn: Not installed
2025-04-22 19:53:03,308:INFO:          deepchecks: Not installed
2025-04-22 19:53:03,308:INFO:             xgboost: Not installed
2025-04-22 19:53:03,308:INFO:            catboost: Not installed
2025-04-22 19:53:03,308:INFO:              kmodes: Not installed
2025-04-22 19:53:03,308:INFO:             mlxtend: 0.23.4
2025-04-22 19:53:03,308:INFO:       statsforecast: Not installed
2025-04-22 19:53:03,308:INFO:        tune_sklearn: Not installed
2025-04-22 19:53:03,308:INFO:                 ray: Not installed
2025-04-22 19:53:03,308:INFO:            hyperopt: Not installed
2025-04-22 19:53:03,308:INFO:              optuna: Not installed
2025-04-22 19:53:03,308:INFO:               skopt: Not installed
2025-04-22 19:53:03,308:INFO:              mlflow: Not installed
2025-04-22 19:53:03,308:INFO:              gradio: Not installed
2025-04-22 19:53:03,308:INFO:             fastapi: Not installed
2025-04-22 19:53:03,308:INFO:             uvicorn: Not installed
2025-04-22 19:53:03,308:INFO:              m2cgen: Not installed
2025-04-22 19:53:03,308:INFO:           evidently: Not installed
2025-04-22 19:53:03,308:INFO:               fugue: Not installed
2025-04-22 19:53:03,308:INFO:           streamlit: Not installed
2025-04-22 19:53:03,308:INFO:             prophet: Not installed
2025-04-22 19:53:03,308:INFO:None
2025-04-22 19:53:03,308:INFO:Set up data.
2025-04-22 19:53:03,324:INFO:Set up folding strategy.
2025-04-22 19:53:03,324:INFO:Set up train/test split.
2025-04-22 19:53:03,351:INFO:Set up index.
2025-04-22 19:53:03,352:INFO:Assigning column types.
2025-04-22 19:53:03,368:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 19:53:03,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,409:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,501:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 19:53:03,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:53:03,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,622:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 19:53:03,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:03,743:INFO:Preparing preprocessing pipeline...
2025-04-22 19:53:03,745:INFO:Set up simple imputation.
2025-04-22 19:53:03,752:INFO:Set up encoding of ordinal features.
2025-04-22 19:53:03,759:INFO:Set up encoding of categorical features.
2025-04-22 19:53:03,894:INFO:Finished creating preprocessing pipeline.
2025-04-22 19:53:03,921:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-22 19:53:03,922:INFO:Creating final display dataframe.
2025-04-22 19:53:04,198:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        57c4
2025-04-22 19:53:04,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:04,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:04,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:04,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:53:04,338:INFO:setup() successfully completed in 1.22s...............
2025-04-22 19:53:12,671:INFO:Initializing compare_models()
2025-04-22 19:53:12,671:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 19:53:12,671:INFO:Checking exceptions
2025-04-22 19:53:12,684:INFO:Preparing display monitor
2025-04-22 19:53:12,705:INFO:Initializing Logistic Regression
2025-04-22 19:53:12,705:INFO:Total runtime is 0.0 minutes
2025-04-22 19:53:12,709:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:12,709:INFO:Initializing create_model()
2025-04-22 19:53:12,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:12,710:INFO:Checking exceptions
2025-04-22 19:53:12,710:INFO:Importing libraries
2025-04-22 19:53:12,710:INFO:Copying training dataset
2025-04-22 19:53:12,737:INFO:Defining folds
2025-04-22 19:53:12,737:INFO:Declaring metric variables
2025-04-22 19:53:12,741:INFO:Importing untrained model
2025-04-22 19:53:12,745:INFO:Logistic Regression Imported successfully
2025-04-22 19:53:12,752:INFO:Starting cross validation
2025-04-22 19:53:12,754:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:17,796:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 19:53:17,802:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 19:53:17,809:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 19:53:17,818:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 19:53:17,876:INFO:Calculating mean and std
2025-04-22 19:53:17,877:INFO:Creating metrics dataframe
2025-04-22 19:53:17,880:INFO:Uploading results into container
2025-04-22 19:53:17,881:INFO:Uploading model into container now
2025-04-22 19:53:17,882:INFO:_master_model_container: 1
2025-04-22 19:53:17,882:INFO:_display_container: 2
2025-04-22 19:53:17,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 19:53:17,883:INFO:create_model() successfully completed......................................
2025-04-22 19:53:18,119:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:18,119:INFO:Creating metrics dataframe
2025-04-22 19:53:18,125:INFO:Initializing K Neighbors Classifier
2025-04-22 19:53:18,125:INFO:Total runtime is 0.09031793673833212 minutes
2025-04-22 19:53:18,128:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:18,128:INFO:Initializing create_model()
2025-04-22 19:53:18,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:18,128:INFO:Checking exceptions
2025-04-22 19:53:18,128:INFO:Importing libraries
2025-04-22 19:53:18,128:INFO:Copying training dataset
2025-04-22 19:53:18,146:INFO:Defining folds
2025-04-22 19:53:18,146:INFO:Declaring metric variables
2025-04-22 19:53:18,150:INFO:Importing untrained model
2025-04-22 19:53:18,153:INFO:K Neighbors Classifier Imported successfully
2025-04-22 19:53:18,159:INFO:Starting cross validation
2025-04-22 19:53:18,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:21,927:INFO:Calculating mean and std
2025-04-22 19:53:21,929:INFO:Creating metrics dataframe
2025-04-22 19:53:21,931:INFO:Uploading results into container
2025-04-22 19:53:21,932:INFO:Uploading model into container now
2025-04-22 19:53:21,933:INFO:_master_model_container: 2
2025-04-22 19:53:21,933:INFO:_display_container: 2
2025-04-22 19:53:21,933:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 19:53:21,933:INFO:create_model() successfully completed......................................
2025-04-22 19:53:22,117:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:22,117:INFO:Creating metrics dataframe
2025-04-22 19:53:22,124:INFO:Initializing Naive Bayes
2025-04-22 19:53:22,124:INFO:Total runtime is 0.15696973005930584 minutes
2025-04-22 19:53:22,127:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:22,127:INFO:Initializing create_model()
2025-04-22 19:53:22,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:22,127:INFO:Checking exceptions
2025-04-22 19:53:22,127:INFO:Importing libraries
2025-04-22 19:53:22,127:INFO:Copying training dataset
2025-04-22 19:53:22,148:INFO:Defining folds
2025-04-22 19:53:22,148:INFO:Declaring metric variables
2025-04-22 19:53:22,152:INFO:Importing untrained model
2025-04-22 19:53:22,156:INFO:Naive Bayes Imported successfully
2025-04-22 19:53:22,162:INFO:Starting cross validation
2025-04-22 19:53:22,165:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:25,297:INFO:Calculating mean and std
2025-04-22 19:53:25,299:INFO:Creating metrics dataframe
2025-04-22 19:53:25,302:INFO:Uploading results into container
2025-04-22 19:53:25,303:INFO:Uploading model into container now
2025-04-22 19:53:25,303:INFO:_master_model_container: 3
2025-04-22 19:53:25,304:INFO:_display_container: 2
2025-04-22 19:53:25,304:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 19:53:25,304:INFO:create_model() successfully completed......................................
2025-04-22 19:53:25,474:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:25,475:INFO:Creating metrics dataframe
2025-04-22 19:53:25,480:INFO:Initializing Decision Tree Classifier
2025-04-22 19:53:25,480:INFO:Total runtime is 0.21291609605153403 minutes
2025-04-22 19:53:25,484:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:25,484:INFO:Initializing create_model()
2025-04-22 19:53:25,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:25,485:INFO:Checking exceptions
2025-04-22 19:53:25,485:INFO:Importing libraries
2025-04-22 19:53:25,485:INFO:Copying training dataset
2025-04-22 19:53:25,501:INFO:Defining folds
2025-04-22 19:53:25,501:INFO:Declaring metric variables
2025-04-22 19:53:25,505:INFO:Importing untrained model
2025-04-22 19:53:25,508:INFO:Decision Tree Classifier Imported successfully
2025-04-22 19:53:25,515:INFO:Starting cross validation
2025-04-22 19:53:25,517:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:28,362:INFO:Calculating mean and std
2025-04-22 19:53:28,363:INFO:Creating metrics dataframe
2025-04-22 19:53:28,366:INFO:Uploading results into container
2025-04-22 19:53:28,366:INFO:Uploading model into container now
2025-04-22 19:53:28,367:INFO:_master_model_container: 4
2025-04-22 19:53:28,367:INFO:_display_container: 2
2025-04-22 19:53:28,367:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 19:53:28,367:INFO:create_model() successfully completed......................................
2025-04-22 19:53:28,533:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:28,533:INFO:Creating metrics dataframe
2025-04-22 19:53:28,540:INFO:Initializing SVM - Linear Kernel
2025-04-22 19:53:28,540:INFO:Total runtime is 0.2639160513877869 minutes
2025-04-22 19:53:28,544:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:28,544:INFO:Initializing create_model()
2025-04-22 19:53:28,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:28,544:INFO:Checking exceptions
2025-04-22 19:53:28,544:INFO:Importing libraries
2025-04-22 19:53:28,544:INFO:Copying training dataset
2025-04-22 19:53:28,564:INFO:Defining folds
2025-04-22 19:53:28,564:INFO:Declaring metric variables
2025-04-22 19:53:28,567:INFO:Importing untrained model
2025-04-22 19:53:28,572:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 19:53:28,578:INFO:Starting cross validation
2025-04-22 19:53:28,580:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:29,176:INFO:Calculating mean and std
2025-04-22 19:53:29,177:INFO:Creating metrics dataframe
2025-04-22 19:53:29,179:INFO:Uploading results into container
2025-04-22 19:53:29,179:INFO:Uploading model into container now
2025-04-22 19:53:29,180:INFO:_master_model_container: 5
2025-04-22 19:53:29,180:INFO:_display_container: 2
2025-04-22 19:53:29,180:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 19:53:29,181:INFO:create_model() successfully completed......................................
2025-04-22 19:53:29,323:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:29,323:INFO:Creating metrics dataframe
2025-04-22 19:53:29,331:INFO:Initializing Ridge Classifier
2025-04-22 19:53:29,331:INFO:Total runtime is 0.2770905494689942 minutes
2025-04-22 19:53:29,335:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:29,335:INFO:Initializing create_model()
2025-04-22 19:53:29,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:29,335:INFO:Checking exceptions
2025-04-22 19:53:29,335:INFO:Importing libraries
2025-04-22 19:53:29,335:INFO:Copying training dataset
2025-04-22 19:53:29,354:INFO:Defining folds
2025-04-22 19:53:29,354:INFO:Declaring metric variables
2025-04-22 19:53:29,357:INFO:Importing untrained model
2025-04-22 19:53:29,361:INFO:Ridge Classifier Imported successfully
2025-04-22 19:53:29,367:INFO:Starting cross validation
2025-04-22 19:53:29,369:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:29,609:INFO:Calculating mean and std
2025-04-22 19:53:29,611:INFO:Creating metrics dataframe
2025-04-22 19:53:29,612:INFO:Uploading results into container
2025-04-22 19:53:29,614:INFO:Uploading model into container now
2025-04-22 19:53:29,614:INFO:_master_model_container: 6
2025-04-22 19:53:29,614:INFO:_display_container: 2
2025-04-22 19:53:29,615:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 19:53:29,615:INFO:create_model() successfully completed......................................
2025-04-22 19:53:29,761:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:29,761:INFO:Creating metrics dataframe
2025-04-22 19:53:29,768:INFO:Initializing Random Forest Classifier
2025-04-22 19:53:29,768:INFO:Total runtime is 0.28436886469523115 minutes
2025-04-22 19:53:29,771:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:29,771:INFO:Initializing create_model()
2025-04-22 19:53:29,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:29,771:INFO:Checking exceptions
2025-04-22 19:53:29,771:INFO:Importing libraries
2025-04-22 19:53:29,771:INFO:Copying training dataset
2025-04-22 19:53:29,790:INFO:Defining folds
2025-04-22 19:53:29,790:INFO:Declaring metric variables
2025-04-22 19:53:29,795:INFO:Importing untrained model
2025-04-22 19:53:29,798:INFO:Random Forest Classifier Imported successfully
2025-04-22 19:53:29,806:INFO:Starting cross validation
2025-04-22 19:53:29,807:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:32,493:INFO:Calculating mean and std
2025-04-22 19:53:32,494:INFO:Creating metrics dataframe
2025-04-22 19:53:32,497:INFO:Uploading results into container
2025-04-22 19:53:32,498:INFO:Uploading model into container now
2025-04-22 19:53:32,498:INFO:_master_model_container: 7
2025-04-22 19:53:32,498:INFO:_display_container: 2
2025-04-22 19:53:32,499:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 19:53:32,499:INFO:create_model() successfully completed......................................
2025-04-22 19:53:32,644:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:32,644:INFO:Creating metrics dataframe
2025-04-22 19:53:32,651:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 19:53:32,651:INFO:Total runtime is 0.3324211835861206 minutes
2025-04-22 19:53:32,655:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:32,655:INFO:Initializing create_model()
2025-04-22 19:53:32,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:32,655:INFO:Checking exceptions
2025-04-22 19:53:32,656:INFO:Importing libraries
2025-04-22 19:53:32,656:INFO:Copying training dataset
2025-04-22 19:53:32,673:INFO:Defining folds
2025-04-22 19:53:32,673:INFO:Declaring metric variables
2025-04-22 19:53:32,677:INFO:Importing untrained model
2025-04-22 19:53:32,680:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 19:53:32,687:INFO:Starting cross validation
2025-04-22 19:53:32,689:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:32,873:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 19:53:32,887:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 19:53:32,957:INFO:Calculating mean and std
2025-04-22 19:53:32,958:INFO:Creating metrics dataframe
2025-04-22 19:53:32,960:INFO:Uploading results into container
2025-04-22 19:53:32,960:INFO:Uploading model into container now
2025-04-22 19:53:32,961:INFO:_master_model_container: 8
2025-04-22 19:53:32,961:INFO:_display_container: 2
2025-04-22 19:53:32,961:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 19:53:32,961:INFO:create_model() successfully completed......................................
2025-04-22 19:53:33,126:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:33,126:INFO:Creating metrics dataframe
2025-04-22 19:53:33,137:INFO:Initializing Ada Boost Classifier
2025-04-22 19:53:33,137:INFO:Total runtime is 0.3405210614204407 minutes
2025-04-22 19:53:33,140:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:33,140:INFO:Initializing create_model()
2025-04-22 19:53:33,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:33,141:INFO:Checking exceptions
2025-04-22 19:53:33,141:INFO:Importing libraries
2025-04-22 19:53:33,141:INFO:Copying training dataset
2025-04-22 19:53:33,163:INFO:Defining folds
2025-04-22 19:53:33,163:INFO:Declaring metric variables
2025-04-22 19:53:33,167:INFO:Importing untrained model
2025-04-22 19:53:33,171:INFO:Ada Boost Classifier Imported successfully
2025-04-22 19:53:33,178:INFO:Starting cross validation
2025-04-22 19:53:33,179:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:33,352:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:53:33,352:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:53:33,352:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:53:33,358:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:53:35,031:INFO:Calculating mean and std
2025-04-22 19:53:35,032:INFO:Creating metrics dataframe
2025-04-22 19:53:35,033:INFO:Uploading results into container
2025-04-22 19:53:35,033:INFO:Uploading model into container now
2025-04-22 19:53:35,035:INFO:_master_model_container: 9
2025-04-22 19:53:35,035:INFO:_display_container: 2
2025-04-22 19:53:35,035:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 19:53:35,035:INFO:create_model() successfully completed......................................
2025-04-22 19:53:35,179:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:35,179:INFO:Creating metrics dataframe
2025-04-22 19:53:35,187:INFO:Initializing Gradient Boosting Classifier
2025-04-22 19:53:35,187:INFO:Total runtime is 0.3746852318445842 minutes
2025-04-22 19:53:35,190:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:35,190:INFO:Initializing create_model()
2025-04-22 19:53:35,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:35,190:INFO:Checking exceptions
2025-04-22 19:53:35,190:INFO:Importing libraries
2025-04-22 19:53:35,191:INFO:Copying training dataset
2025-04-22 19:53:35,210:INFO:Defining folds
2025-04-22 19:53:35,210:INFO:Declaring metric variables
2025-04-22 19:53:35,212:INFO:Importing untrained model
2025-04-22 19:53:35,216:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 19:53:35,223:INFO:Starting cross validation
2025-04-22 19:53:35,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:41,948:INFO:Calculating mean and std
2025-04-22 19:53:41,949:INFO:Creating metrics dataframe
2025-04-22 19:53:41,951:INFO:Uploading results into container
2025-04-22 19:53:41,951:INFO:Uploading model into container now
2025-04-22 19:53:41,952:INFO:_master_model_container: 10
2025-04-22 19:53:41,952:INFO:_display_container: 2
2025-04-22 19:53:41,952:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 19:53:41,952:INFO:create_model() successfully completed......................................
2025-04-22 19:53:42,105:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:42,105:INFO:Creating metrics dataframe
2025-04-22 19:53:42,112:INFO:Initializing Linear Discriminant Analysis
2025-04-22 19:53:42,114:INFO:Total runtime is 0.49013535976409917 minutes
2025-04-22 19:53:42,118:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:42,119:INFO:Initializing create_model()
2025-04-22 19:53:42,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:42,119:INFO:Checking exceptions
2025-04-22 19:53:42,119:INFO:Importing libraries
2025-04-22 19:53:42,119:INFO:Copying training dataset
2025-04-22 19:53:42,151:INFO:Defining folds
2025-04-22 19:53:42,151:INFO:Declaring metric variables
2025-04-22 19:53:42,155:INFO:Importing untrained model
2025-04-22 19:53:42,159:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 19:53:42,169:INFO:Starting cross validation
2025-04-22 19:53:42,171:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:42,453:INFO:Calculating mean and std
2025-04-22 19:53:42,455:INFO:Creating metrics dataframe
2025-04-22 19:53:42,456:INFO:Uploading results into container
2025-04-22 19:53:42,457:INFO:Uploading model into container now
2025-04-22 19:53:42,457:INFO:_master_model_container: 11
2025-04-22 19:53:42,457:INFO:_display_container: 2
2025-04-22 19:53:42,457:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 19:53:42,458:INFO:create_model() successfully completed......................................
2025-04-22 19:53:42,614:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:42,614:INFO:Creating metrics dataframe
2025-04-22 19:53:42,622:INFO:Initializing Extra Trees Classifier
2025-04-22 19:53:42,622:INFO:Total runtime is 0.4986175139745077 minutes
2025-04-22 19:53:42,625:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:42,626:INFO:Initializing create_model()
2025-04-22 19:53:42,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:42,626:INFO:Checking exceptions
2025-04-22 19:53:42,626:INFO:Importing libraries
2025-04-22 19:53:42,626:INFO:Copying training dataset
2025-04-22 19:53:42,643:INFO:Defining folds
2025-04-22 19:53:42,643:INFO:Declaring metric variables
2025-04-22 19:53:42,648:INFO:Importing untrained model
2025-04-22 19:53:42,651:INFO:Extra Trees Classifier Imported successfully
2025-04-22 19:53:42,657:INFO:Starting cross validation
2025-04-22 19:53:42,658:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:44,196:INFO:Calculating mean and std
2025-04-22 19:53:44,198:INFO:Creating metrics dataframe
2025-04-22 19:53:44,200:INFO:Uploading results into container
2025-04-22 19:53:44,200:INFO:Uploading model into container now
2025-04-22 19:53:44,202:INFO:_master_model_container: 12
2025-04-22 19:53:44,202:INFO:_display_container: 2
2025-04-22 19:53:44,202:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 19:53:44,203:INFO:create_model() successfully completed......................................
2025-04-22 19:53:44,383:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:44,383:INFO:Creating metrics dataframe
2025-04-22 19:53:44,392:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 19:53:44,392:INFO:Total runtime is 0.5281042814254762 minutes
2025-04-22 19:53:44,396:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:44,396:INFO:Initializing create_model()
2025-04-22 19:53:44,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:44,397:INFO:Checking exceptions
2025-04-22 19:53:44,397:INFO:Importing libraries
2025-04-22 19:53:44,397:INFO:Copying training dataset
2025-04-22 19:53:44,421:INFO:Defining folds
2025-04-22 19:53:44,421:INFO:Declaring metric variables
2025-04-22 19:53:44,425:INFO:Importing untrained model
2025-04-22 19:53:44,430:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 19:53:44,438:INFO:Starting cross validation
2025-04-22 19:53:44,439:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:45,881:INFO:Calculating mean and std
2025-04-22 19:53:45,883:INFO:Creating metrics dataframe
2025-04-22 19:53:45,886:INFO:Uploading results into container
2025-04-22 19:53:45,887:INFO:Uploading model into container now
2025-04-22 19:53:45,888:INFO:_master_model_container: 13
2025-04-22 19:53:45,888:INFO:_display_container: 2
2025-04-22 19:53:45,889:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 19:53:45,889:INFO:create_model() successfully completed......................................
2025-04-22 19:53:46,182:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:46,182:INFO:Creating metrics dataframe
2025-04-22 19:53:46,193:INFO:Initializing Dummy Classifier
2025-04-22 19:53:46,194:INFO:Total runtime is 0.5581448554992676 minutes
2025-04-22 19:53:46,199:INFO:SubProcess create_model() called ==================================
2025-04-22 19:53:46,200:INFO:Initializing create_model()
2025-04-22 19:53:46,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CC09350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:46,200:INFO:Checking exceptions
2025-04-22 19:53:46,200:INFO:Importing libraries
2025-04-22 19:53:46,200:INFO:Copying training dataset
2025-04-22 19:53:46,229:INFO:Defining folds
2025-04-22 19:53:46,229:INFO:Declaring metric variables
2025-04-22 19:53:46,234:INFO:Importing untrained model
2025-04-22 19:53:46,237:INFO:Dummy Classifier Imported successfully
2025-04-22 19:53:46,245:INFO:Starting cross validation
2025-04-22 19:53:46,248:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:53:46,500:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:53:46,500:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:53:46,500:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:53:46,506:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:53:46,524:INFO:Calculating mean and std
2025-04-22 19:53:46,526:INFO:Creating metrics dataframe
2025-04-22 19:53:46,529:INFO:Uploading results into container
2025-04-22 19:53:46,529:INFO:Uploading model into container now
2025-04-22 19:53:46,530:INFO:_master_model_container: 14
2025-04-22 19:53:46,530:INFO:_display_container: 2
2025-04-22 19:53:46,530:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 19:53:46,530:INFO:create_model() successfully completed......................................
2025-04-22 19:53:46,724:INFO:SubProcess create_model() end ==================================
2025-04-22 19:53:46,724:INFO:Creating metrics dataframe
2025-04-22 19:53:46,737:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 19:53:46,747:INFO:Initializing create_model()
2025-04-22 19:53:46,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21FCEC250>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:53:46,747:INFO:Checking exceptions
2025-04-22 19:53:46,749:INFO:Importing libraries
2025-04-22 19:53:46,750:INFO:Copying training dataset
2025-04-22 19:53:46,780:INFO:Defining folds
2025-04-22 19:53:46,780:INFO:Declaring metric variables
2025-04-22 19:53:46,780:INFO:Importing untrained model
2025-04-22 19:53:46,780:INFO:Declaring custom model
2025-04-22 19:53:46,780:INFO:Naive Bayes Imported successfully
2025-04-22 19:53:46,781:INFO:Cross validation set to False
2025-04-22 19:53:46,781:INFO:Fitting Model
2025-04-22 19:53:46,937:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 19:53:46,937:INFO:create_model() successfully completed......................................
2025-04-22 19:53:47,172:INFO:_master_model_container: 14
2025-04-22 19:53:47,172:INFO:_display_container: 2
2025-04-22 19:53:47,172:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 19:53:47,172:INFO:compare_models() successfully completed......................................
2025-04-22 19:57:24,667:INFO:PyCaret ClassificationExperiment
2025-04-22 19:57:24,667:INFO:Logging name: baseline_after_selection
2025-04-22 19:57:24,667:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 19:57:24,668:INFO:version 3.3.2
2025-04-22 19:57:24,668:INFO:Initializing setup()
2025-04-22 19:57:24,668:INFO:self.USI: 90a7
2025-04-22 19:57:24,668:INFO:self._variable_keys: {'fold_generator', 'y', 'target_param', '_ml_usecase', '_available_plots', 'X_test', 'idx', 'exp_name_log', 'X_train', 'USI', 'logging_param', 'seed', 'html_param', 'gpu_param', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'exp_id', 'y_test', 'y_train', 'X', 'memory', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'is_multiclass'}
2025-04-22 19:57:24,668:INFO:Checking environment
2025-04-22 19:57:24,668:INFO:python_version: 3.11.4
2025-04-22 19:57:24,668:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 19:57:24,668:INFO:machine: AMD64
2025-04-22 19:57:24,668:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 19:57:24,678:INFO:Memory: svmem(total=16498810880, available=2703454208, percent=83.6, used=13795356672, free=2703454208)
2025-04-22 19:57:24,678:INFO:Physical Core: 8
2025-04-22 19:57:24,678:INFO:Logical Core: 16
2025-04-22 19:57:24,679:INFO:Checking libraries
2025-04-22 19:57:24,679:INFO:System:
2025-04-22 19:57:24,679:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 19:57:24,679:INFO:executable: c:\Python311\python.exe
2025-04-22 19:57:24,679:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 19:57:24,679:INFO:PyCaret required dependencies:
2025-04-22 19:57:24,679:INFO:                 pip: 23.1.2
2025-04-22 19:57:24,679:INFO:          setuptools: 65.5.0
2025-04-22 19:57:24,679:INFO:             pycaret: 3.3.2
2025-04-22 19:57:24,679:INFO:             IPython: 8.20.0
2025-04-22 19:57:24,679:INFO:          ipywidgets: 8.1.6
2025-04-22 19:57:24,679:INFO:                tqdm: 4.66.2
2025-04-22 19:57:24,679:INFO:               numpy: 1.26.2
2025-04-22 19:57:24,679:INFO:              pandas: 2.1.4
2025-04-22 19:57:24,679:INFO:              jinja2: 3.1.2
2025-04-22 19:57:24,679:INFO:               scipy: 1.11.4
2025-04-22 19:57:24,679:INFO:              joblib: 1.3.2
2025-04-22 19:57:24,679:INFO:             sklearn: 1.4.2
2025-04-22 19:57:24,679:INFO:                pyod: 2.0.4
2025-04-22 19:57:24,679:INFO:            imblearn: 0.12.0
2025-04-22 19:57:24,679:INFO:   category_encoders: 2.7.0
2025-04-22 19:57:24,679:INFO:            lightgbm: 4.6.0
2025-04-22 19:57:24,679:INFO:               numba: 0.61.2
2025-04-22 19:57:24,680:INFO:            requests: 2.31.0
2025-04-22 19:57:24,680:INFO:          matplotlib: 3.7.5
2025-04-22 19:57:24,680:INFO:          scikitplot: 0.3.7
2025-04-22 19:57:24,680:INFO:         yellowbrick: 1.5
2025-04-22 19:57:24,680:INFO:              plotly: 5.24.1
2025-04-22 19:57:24,680:INFO:    plotly-resampler: Not installed
2025-04-22 19:57:24,680:INFO:             kaleido: 0.2.1
2025-04-22 19:57:24,680:INFO:           schemdraw: 0.15
2025-04-22 19:57:24,680:INFO:         statsmodels: 0.14.4
2025-04-22 19:57:24,680:INFO:              sktime: 0.26.0
2025-04-22 19:57:24,680:INFO:               tbats: 1.1.3
2025-04-22 19:57:24,680:INFO:            pmdarima: 2.0.4
2025-04-22 19:57:24,680:INFO:              psutil: 5.9.8
2025-04-22 19:57:24,680:INFO:          markupsafe: 2.1.3
2025-04-22 19:57:24,680:INFO:             pickle5: Not installed
2025-04-22 19:57:24,680:INFO:         cloudpickle: 3.1.1
2025-04-22 19:57:24,680:INFO:         deprecation: 2.1.0
2025-04-22 19:57:24,680:INFO:              xxhash: 3.5.0
2025-04-22 19:57:24,680:INFO:           wurlitzer: Not installed
2025-04-22 19:57:24,680:INFO:PyCaret optional dependencies:
2025-04-22 19:57:24,680:INFO:                shap: Not installed
2025-04-22 19:57:24,680:INFO:           interpret: Not installed
2025-04-22 19:57:24,680:INFO:                umap: Not installed
2025-04-22 19:57:24,680:INFO:     ydata_profiling: Not installed
2025-04-22 19:57:24,680:INFO:  explainerdashboard: Not installed
2025-04-22 19:57:24,680:INFO:             autoviz: Not installed
2025-04-22 19:57:24,680:INFO:           fairlearn: Not installed
2025-04-22 19:57:24,680:INFO:          deepchecks: Not installed
2025-04-22 19:57:24,680:INFO:             xgboost: Not installed
2025-04-22 19:57:24,680:INFO:            catboost: Not installed
2025-04-22 19:57:24,680:INFO:              kmodes: Not installed
2025-04-22 19:57:24,680:INFO:             mlxtend: 0.23.4
2025-04-22 19:57:24,680:INFO:       statsforecast: Not installed
2025-04-22 19:57:24,680:INFO:        tune_sklearn: Not installed
2025-04-22 19:57:24,680:INFO:                 ray: Not installed
2025-04-22 19:57:24,680:INFO:            hyperopt: Not installed
2025-04-22 19:57:24,680:INFO:              optuna: Not installed
2025-04-22 19:57:24,680:INFO:               skopt: Not installed
2025-04-22 19:57:24,681:INFO:              mlflow: Not installed
2025-04-22 19:57:24,681:INFO:              gradio: Not installed
2025-04-22 19:57:24,681:INFO:             fastapi: Not installed
2025-04-22 19:57:24,681:INFO:             uvicorn: Not installed
2025-04-22 19:57:24,681:INFO:              m2cgen: Not installed
2025-04-22 19:57:24,681:INFO:           evidently: Not installed
2025-04-22 19:57:24,681:INFO:               fugue: Not installed
2025-04-22 19:57:24,681:INFO:           streamlit: Not installed
2025-04-22 19:57:24,681:INFO:             prophet: Not installed
2025-04-22 19:57:24,681:INFO:None
2025-04-22 19:57:24,681:INFO:Set up data.
2025-04-22 19:57:24,684:INFO:Set up folding strategy.
2025-04-22 19:57:24,685:INFO:Set up train/test split.
2025-04-22 19:57:24,694:INFO:Set up index.
2025-04-22 19:57:24,695:INFO:Assigning column types.
2025-04-22 19:57:24,699:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 19:57:24,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,797:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,819:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 19:57:24,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,916:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 19:57:24,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,939:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 19:57:24,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:24,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:25,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:25,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:25,057:INFO:Preparing preprocessing pipeline...
2025-04-22 19:57:25,058:INFO:Set up simple imputation.
2025-04-22 19:57:25,058:INFO:Set up imbalanced handling.
2025-04-22 19:57:25,058:INFO:Set up feature normalization.
2025-04-22 19:57:26,370:INFO:Finished creating preprocessing pipeline.
2025-04-22 19:57:26,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sept_Pay_status',
                                             'May_Pay_status',
                                             'momentum_stability_flag',
                                             'low_repayment_months_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_value...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-22 19:57:26,376:INFO:Creating final display dataframe.
2025-04-22 19:57:27,769:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                  (29163, 5)
4        Transformed data shape                  (40455, 5)
5   Transformed train set shape                  (31706, 5)
6    Transformed test set shape                   (8749, 5)
7              Numeric features                           4
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name    baseline_after_selection
22                          USI                        90a7
2025-04-22 19:57:27,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:27,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:27,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:27,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 19:57:27,899:INFO:setup() successfully completed in 3.25s...............
2025-04-22 19:57:27,899:INFO:Initializing compare_models()
2025-04-22 19:57:27,899:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 19:57:27,899:INFO:Checking exceptions
2025-04-22 19:57:27,903:INFO:Preparing display monitor
2025-04-22 19:57:27,920:INFO:Initializing Logistic Regression
2025-04-22 19:57:27,920:INFO:Total runtime is 0.0 minutes
2025-04-22 19:57:27,924:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:27,925:INFO:Initializing create_model()
2025-04-22 19:57:27,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:27,925:INFO:Checking exceptions
2025-04-22 19:57:27,925:INFO:Importing libraries
2025-04-22 19:57:27,925:INFO:Copying training dataset
2025-04-22 19:57:27,937:INFO:Defining folds
2025-04-22 19:57:27,937:INFO:Declaring metric variables
2025-04-22 19:57:27,943:INFO:Importing untrained model
2025-04-22 19:57:27,947:INFO:Logistic Regression Imported successfully
2025-04-22 19:57:27,956:INFO:Starting cross validation
2025-04-22 19:57:27,958:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:29,167:INFO:Calculating mean and std
2025-04-22 19:57:29,168:INFO:Creating metrics dataframe
2025-04-22 19:57:29,169:INFO:Uploading results into container
2025-04-22 19:57:29,170:INFO:Uploading model into container now
2025-04-22 19:57:29,170:INFO:_master_model_container: 1
2025-04-22 19:57:29,170:INFO:_display_container: 2
2025-04-22 19:57:29,170:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 19:57:29,170:INFO:create_model() successfully completed......................................
2025-04-22 19:57:29,410:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:29,410:INFO:Creating metrics dataframe
2025-04-22 19:57:29,415:INFO:Initializing K Neighbors Classifier
2025-04-22 19:57:29,415:INFO:Total runtime is 0.024913187821706137 minutes
2025-04-22 19:57:29,418:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:29,418:INFO:Initializing create_model()
2025-04-22 19:57:29,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:29,418:INFO:Checking exceptions
2025-04-22 19:57:29,418:INFO:Importing libraries
2025-04-22 19:57:29,418:INFO:Copying training dataset
2025-04-22 19:57:29,424:INFO:Defining folds
2025-04-22 19:57:29,424:INFO:Declaring metric variables
2025-04-22 19:57:29,427:INFO:Importing untrained model
2025-04-22 19:57:29,431:INFO:K Neighbors Classifier Imported successfully
2025-04-22 19:57:29,440:INFO:Starting cross validation
2025-04-22 19:57:29,441:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:31,452:INFO:Calculating mean and std
2025-04-22 19:57:31,453:INFO:Creating metrics dataframe
2025-04-22 19:57:31,455:INFO:Uploading results into container
2025-04-22 19:57:31,456:INFO:Uploading model into container now
2025-04-22 19:57:31,456:INFO:_master_model_container: 2
2025-04-22 19:57:31,456:INFO:_display_container: 2
2025-04-22 19:57:31,456:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 19:57:31,456:INFO:create_model() successfully completed......................................
2025-04-22 19:57:31,597:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:31,597:INFO:Creating metrics dataframe
2025-04-22 19:57:31,602:INFO:Initializing Naive Bayes
2025-04-22 19:57:31,602:INFO:Total runtime is 0.06136994361877442 minutes
2025-04-22 19:57:31,604:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:31,604:INFO:Initializing create_model()
2025-04-22 19:57:31,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:31,605:INFO:Checking exceptions
2025-04-22 19:57:31,605:INFO:Importing libraries
2025-04-22 19:57:31,605:INFO:Copying training dataset
2025-04-22 19:57:31,611:INFO:Defining folds
2025-04-22 19:57:31,611:INFO:Declaring metric variables
2025-04-22 19:57:31,614:INFO:Importing untrained model
2025-04-22 19:57:31,618:INFO:Naive Bayes Imported successfully
2025-04-22 19:57:31,623:INFO:Starting cross validation
2025-04-22 19:57:31,624:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:32,951:INFO:Calculating mean and std
2025-04-22 19:57:32,952:INFO:Creating metrics dataframe
2025-04-22 19:57:32,954:INFO:Uploading results into container
2025-04-22 19:57:32,955:INFO:Uploading model into container now
2025-04-22 19:57:32,955:INFO:_master_model_container: 3
2025-04-22 19:57:32,956:INFO:_display_container: 2
2025-04-22 19:57:32,956:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 19:57:32,956:INFO:create_model() successfully completed......................................
2025-04-22 19:57:33,102:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:33,102:INFO:Creating metrics dataframe
2025-04-22 19:57:33,109:INFO:Initializing Decision Tree Classifier
2025-04-22 19:57:33,109:INFO:Total runtime is 0.08647674322128296 minutes
2025-04-22 19:57:33,112:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:33,112:INFO:Initializing create_model()
2025-04-22 19:57:33,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:33,112:INFO:Checking exceptions
2025-04-22 19:57:33,112:INFO:Importing libraries
2025-04-22 19:57:33,113:INFO:Copying training dataset
2025-04-22 19:57:33,120:INFO:Defining folds
2025-04-22 19:57:33,120:INFO:Declaring metric variables
2025-04-22 19:57:33,124:INFO:Importing untrained model
2025-04-22 19:57:33,128:INFO:Decision Tree Classifier Imported successfully
2025-04-22 19:57:33,134:INFO:Starting cross validation
2025-04-22 19:57:33,137:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:34,574:INFO:Calculating mean and std
2025-04-22 19:57:34,575:INFO:Creating metrics dataframe
2025-04-22 19:57:34,577:INFO:Uploading results into container
2025-04-22 19:57:34,577:INFO:Uploading model into container now
2025-04-22 19:57:34,578:INFO:_master_model_container: 4
2025-04-22 19:57:34,578:INFO:_display_container: 2
2025-04-22 19:57:34,578:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 19:57:34,578:INFO:create_model() successfully completed......................................
2025-04-22 19:57:34,726:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:34,726:INFO:Creating metrics dataframe
2025-04-22 19:57:34,733:INFO:Initializing SVM - Linear Kernel
2025-04-22 19:57:34,733:INFO:Total runtime is 0.11354807615280152 minutes
2025-04-22 19:57:34,736:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:34,738:INFO:Initializing create_model()
2025-04-22 19:57:34,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:34,738:INFO:Checking exceptions
2025-04-22 19:57:34,738:INFO:Importing libraries
2025-04-22 19:57:34,738:INFO:Copying training dataset
2025-04-22 19:57:34,746:INFO:Defining folds
2025-04-22 19:57:34,746:INFO:Declaring metric variables
2025-04-22 19:57:34,750:INFO:Importing untrained model
2025-04-22 19:57:34,754:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 19:57:34,762:INFO:Starting cross validation
2025-04-22 19:57:34,764:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:36,256:INFO:Calculating mean and std
2025-04-22 19:57:36,257:INFO:Creating metrics dataframe
2025-04-22 19:57:36,259:INFO:Uploading results into container
2025-04-22 19:57:36,259:INFO:Uploading model into container now
2025-04-22 19:57:36,260:INFO:_master_model_container: 5
2025-04-22 19:57:36,260:INFO:_display_container: 2
2025-04-22 19:57:36,260:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 19:57:36,260:INFO:create_model() successfully completed......................................
2025-04-22 19:57:36,406:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:36,406:INFO:Creating metrics dataframe
2025-04-22 19:57:36,412:INFO:Initializing Ridge Classifier
2025-04-22 19:57:36,412:INFO:Total runtime is 0.14152544339497886 minutes
2025-04-22 19:57:36,416:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:36,416:INFO:Initializing create_model()
2025-04-22 19:57:36,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:36,416:INFO:Checking exceptions
2025-04-22 19:57:36,416:INFO:Importing libraries
2025-04-22 19:57:36,416:INFO:Copying training dataset
2025-04-22 19:57:36,423:INFO:Defining folds
2025-04-22 19:57:36,423:INFO:Declaring metric variables
2025-04-22 19:57:36,427:INFO:Importing untrained model
2025-04-22 19:57:36,430:INFO:Ridge Classifier Imported successfully
2025-04-22 19:57:36,437:INFO:Starting cross validation
2025-04-22 19:57:36,438:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:37,945:INFO:Calculating mean and std
2025-04-22 19:57:37,946:INFO:Creating metrics dataframe
2025-04-22 19:57:37,948:INFO:Uploading results into container
2025-04-22 19:57:37,949:INFO:Uploading model into container now
2025-04-22 19:57:37,949:INFO:_master_model_container: 6
2025-04-22 19:57:37,950:INFO:_display_container: 2
2025-04-22 19:57:37,950:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 19:57:37,950:INFO:create_model() successfully completed......................................
2025-04-22 19:57:38,099:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:38,099:INFO:Creating metrics dataframe
2025-04-22 19:57:38,106:INFO:Initializing Random Forest Classifier
2025-04-22 19:57:38,108:INFO:Total runtime is 0.16978788375854492 minutes
2025-04-22 19:57:38,110:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:38,111:INFO:Initializing create_model()
2025-04-22 19:57:38,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:38,111:INFO:Checking exceptions
2025-04-22 19:57:38,111:INFO:Importing libraries
2025-04-22 19:57:38,111:INFO:Copying training dataset
2025-04-22 19:57:38,118:INFO:Defining folds
2025-04-22 19:57:38,118:INFO:Declaring metric variables
2025-04-22 19:57:38,121:INFO:Importing untrained model
2025-04-22 19:57:38,125:INFO:Random Forest Classifier Imported successfully
2025-04-22 19:57:38,133:INFO:Starting cross validation
2025-04-22 19:57:38,134:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:40,162:INFO:Calculating mean and std
2025-04-22 19:57:40,163:INFO:Creating metrics dataframe
2025-04-22 19:57:40,165:INFO:Uploading results into container
2025-04-22 19:57:40,166:INFO:Uploading model into container now
2025-04-22 19:57:40,166:INFO:_master_model_container: 7
2025-04-22 19:57:40,166:INFO:_display_container: 2
2025-04-22 19:57:40,166:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 19:57:40,167:INFO:create_model() successfully completed......................................
2025-04-22 19:57:40,307:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:40,307:INFO:Creating metrics dataframe
2025-04-22 19:57:40,314:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 19:57:40,314:INFO:Total runtime is 0.20655717452367148 minutes
2025-04-22 19:57:40,317:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:40,317:INFO:Initializing create_model()
2025-04-22 19:57:40,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:40,317:INFO:Checking exceptions
2025-04-22 19:57:40,317:INFO:Importing libraries
2025-04-22 19:57:40,317:INFO:Copying training dataset
2025-04-22 19:57:40,324:INFO:Defining folds
2025-04-22 19:57:40,324:INFO:Declaring metric variables
2025-04-22 19:57:40,329:INFO:Importing untrained model
2025-04-22 19:57:40,333:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 19:57:40,339:INFO:Starting cross validation
2025-04-22 19:57:40,341:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:41,891:INFO:Calculating mean and std
2025-04-22 19:57:41,892:INFO:Creating metrics dataframe
2025-04-22 19:57:41,894:INFO:Uploading results into container
2025-04-22 19:57:41,894:INFO:Uploading model into container now
2025-04-22 19:57:41,895:INFO:_master_model_container: 8
2025-04-22 19:57:41,895:INFO:_display_container: 2
2025-04-22 19:57:41,895:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 19:57:41,895:INFO:create_model() successfully completed......................................
2025-04-22 19:57:42,054:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:42,054:INFO:Creating metrics dataframe
2025-04-22 19:57:42,062:INFO:Initializing Ada Boost Classifier
2025-04-22 19:57:42,063:INFO:Total runtime is 0.23570271730422976 minutes
2025-04-22 19:57:42,066:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:42,066:INFO:Initializing create_model()
2025-04-22 19:57:42,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:42,067:INFO:Checking exceptions
2025-04-22 19:57:42,067:INFO:Importing libraries
2025-04-22 19:57:42,067:INFO:Copying training dataset
2025-04-22 19:57:42,073:INFO:Defining folds
2025-04-22 19:57:42,073:INFO:Declaring metric variables
2025-04-22 19:57:42,077:INFO:Importing untrained model
2025-04-22 19:57:42,082:INFO:Ada Boost Classifier Imported successfully
2025-04-22 19:57:42,088:INFO:Starting cross validation
2025-04-22 19:57:42,089:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:43,422:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:57:43,446:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:57:43,454:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:57:43,459:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:57:43,503:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 19:57:44,008:INFO:Calculating mean and std
2025-04-22 19:57:44,010:INFO:Creating metrics dataframe
2025-04-22 19:57:44,012:INFO:Uploading results into container
2025-04-22 19:57:44,012:INFO:Uploading model into container now
2025-04-22 19:57:44,013:INFO:_master_model_container: 9
2025-04-22 19:57:44,013:INFO:_display_container: 2
2025-04-22 19:57:44,013:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 19:57:44,013:INFO:create_model() successfully completed......................................
2025-04-22 19:57:44,160:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:44,160:INFO:Creating metrics dataframe
2025-04-22 19:57:44,167:INFO:Initializing Gradient Boosting Classifier
2025-04-22 19:57:44,167:INFO:Total runtime is 0.2707723458607992 minutes
2025-04-22 19:57:44,169:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:44,170:INFO:Initializing create_model()
2025-04-22 19:57:44,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:44,170:INFO:Checking exceptions
2025-04-22 19:57:44,170:INFO:Importing libraries
2025-04-22 19:57:44,170:INFO:Copying training dataset
2025-04-22 19:57:44,178:INFO:Defining folds
2025-04-22 19:57:44,178:INFO:Declaring metric variables
2025-04-22 19:57:44,182:INFO:Importing untrained model
2025-04-22 19:57:44,185:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 19:57:44,192:INFO:Starting cross validation
2025-04-22 19:57:44,193:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:46,317:INFO:Calculating mean and std
2025-04-22 19:57:46,318:INFO:Creating metrics dataframe
2025-04-22 19:57:46,320:INFO:Uploading results into container
2025-04-22 19:57:46,320:INFO:Uploading model into container now
2025-04-22 19:57:46,321:INFO:_master_model_container: 10
2025-04-22 19:57:46,321:INFO:_display_container: 2
2025-04-22 19:57:46,321:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 19:57:46,322:INFO:create_model() successfully completed......................................
2025-04-22 19:57:46,464:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:46,464:INFO:Creating metrics dataframe
2025-04-22 19:57:46,474:INFO:Initializing Linear Discriminant Analysis
2025-04-22 19:57:46,474:INFO:Total runtime is 0.30922280550003056 minutes
2025-04-22 19:57:46,477:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:46,477:INFO:Initializing create_model()
2025-04-22 19:57:46,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:46,477:INFO:Checking exceptions
2025-04-22 19:57:46,478:INFO:Importing libraries
2025-04-22 19:57:46,478:INFO:Copying training dataset
2025-04-22 19:57:46,484:INFO:Defining folds
2025-04-22 19:57:46,484:INFO:Declaring metric variables
2025-04-22 19:57:46,488:INFO:Importing untrained model
2025-04-22 19:57:46,493:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 19:57:46,500:INFO:Starting cross validation
2025-04-22 19:57:46,502:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:47,999:INFO:Calculating mean and std
2025-04-22 19:57:47,999:INFO:Creating metrics dataframe
2025-04-22 19:57:48,001:INFO:Uploading results into container
2025-04-22 19:57:48,002:INFO:Uploading model into container now
2025-04-22 19:57:48,002:INFO:_master_model_container: 11
2025-04-22 19:57:48,002:INFO:_display_container: 2
2025-04-22 19:57:48,003:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 19:57:48,003:INFO:create_model() successfully completed......................................
2025-04-22 19:57:48,149:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:48,149:INFO:Creating metrics dataframe
2025-04-22 19:57:48,156:INFO:Initializing Extra Trees Classifier
2025-04-22 19:57:48,156:INFO:Total runtime is 0.3372669378916423 minutes
2025-04-22 19:57:48,160:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:48,161:INFO:Initializing create_model()
2025-04-22 19:57:48,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:48,161:INFO:Checking exceptions
2025-04-22 19:57:48,161:INFO:Importing libraries
2025-04-22 19:57:48,161:INFO:Copying training dataset
2025-04-22 19:57:48,168:INFO:Defining folds
2025-04-22 19:57:48,168:INFO:Declaring metric variables
2025-04-22 19:57:48,172:INFO:Importing untrained model
2025-04-22 19:57:48,176:INFO:Extra Trees Classifier Imported successfully
2025-04-22 19:57:48,182:INFO:Starting cross validation
2025-04-22 19:57:48,183:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:50,163:INFO:Calculating mean and std
2025-04-22 19:57:50,164:INFO:Creating metrics dataframe
2025-04-22 19:57:50,166:INFO:Uploading results into container
2025-04-22 19:57:50,167:INFO:Uploading model into container now
2025-04-22 19:57:50,167:INFO:_master_model_container: 12
2025-04-22 19:57:50,168:INFO:_display_container: 2
2025-04-22 19:57:50,168:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 19:57:50,168:INFO:create_model() successfully completed......................................
2025-04-22 19:57:50,338:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:50,338:INFO:Creating metrics dataframe
2025-04-22 19:57:50,345:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 19:57:50,345:INFO:Total runtime is 0.37375135421752936 minutes
2025-04-22 19:57:50,349:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:50,349:INFO:Initializing create_model()
2025-04-22 19:57:50,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:50,349:INFO:Checking exceptions
2025-04-22 19:57:50,349:INFO:Importing libraries
2025-04-22 19:57:50,349:INFO:Copying training dataset
2025-04-22 19:57:50,357:INFO:Defining folds
2025-04-22 19:57:50,357:INFO:Declaring metric variables
2025-04-22 19:57:50,362:INFO:Importing untrained model
2025-04-22 19:57:50,365:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 19:57:50,372:INFO:Starting cross validation
2025-04-22 19:57:50,373:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:52,262:INFO:Calculating mean and std
2025-04-22 19:57:52,264:INFO:Creating metrics dataframe
2025-04-22 19:57:52,266:INFO:Uploading results into container
2025-04-22 19:57:52,267:INFO:Uploading model into container now
2025-04-22 19:57:52,267:INFO:_master_model_container: 13
2025-04-22 19:57:52,267:INFO:_display_container: 2
2025-04-22 19:57:52,269:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 19:57:52,269:INFO:create_model() successfully completed......................................
2025-04-22 19:57:52,432:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:52,433:INFO:Creating metrics dataframe
2025-04-22 19:57:52,441:INFO:Initializing Dummy Classifier
2025-04-22 19:57:52,441:INFO:Total runtime is 0.40868560473124194 minutes
2025-04-22 19:57:52,445:INFO:SubProcess create_model() called ==================================
2025-04-22 19:57:52,445:INFO:Initializing create_model()
2025-04-22 19:57:52,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21D580E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:52,445:INFO:Checking exceptions
2025-04-22 19:57:52,445:INFO:Importing libraries
2025-04-22 19:57:52,445:INFO:Copying training dataset
2025-04-22 19:57:52,452:INFO:Defining folds
2025-04-22 19:57:52,452:INFO:Declaring metric variables
2025-04-22 19:57:52,456:INFO:Importing untrained model
2025-04-22 19:57:52,460:INFO:Dummy Classifier Imported successfully
2025-04-22 19:57:52,464:INFO:Starting cross validation
2025-04-22 19:57:52,466:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 19:57:53,829:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:57:53,903:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:57:53,922:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:57:53,969:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:57:53,998:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 19:57:54,013:INFO:Calculating mean and std
2025-04-22 19:57:54,014:INFO:Creating metrics dataframe
2025-04-22 19:57:54,016:INFO:Uploading results into container
2025-04-22 19:57:54,016:INFO:Uploading model into container now
2025-04-22 19:57:54,017:INFO:_master_model_container: 14
2025-04-22 19:57:54,017:INFO:_display_container: 2
2025-04-22 19:57:54,017:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 19:57:54,017:INFO:create_model() successfully completed......................................
2025-04-22 19:57:54,161:INFO:SubProcess create_model() end ==================================
2025-04-22 19:57:54,161:INFO:Creating metrics dataframe
2025-04-22 19:57:54,169:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 19:57:54,177:INFO:Initializing create_model()
2025-04-22 19:57:54,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21A741850>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 19:57:54,178:INFO:Checking exceptions
2025-04-22 19:57:54,179:INFO:Importing libraries
2025-04-22 19:57:54,179:INFO:Copying training dataset
2025-04-22 19:57:54,185:INFO:Defining folds
2025-04-22 19:57:54,185:INFO:Declaring metric variables
2025-04-22 19:57:54,185:INFO:Importing untrained model
2025-04-22 19:57:54,185:INFO:Declaring custom model
2025-04-22 19:57:54,186:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 19:57:54,187:INFO:Cross validation set to False
2025-04-22 19:57:54,187:INFO:Fitting Model
2025-04-22 19:57:56,189:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 19:57:56,189:INFO:create_model() successfully completed......................................
2025-04-22 19:57:56,355:INFO:_master_model_container: 14
2025-04-22 19:57:56,355:INFO:_display_container: 2
2025-04-22 19:57:56,355:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 19:57:56,355:INFO:compare_models() successfully completed......................................
2025-04-22 19:59:47,512:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,513:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:47,590:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,591:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:47,669:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,670:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:47,750:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,751:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:47,830:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,831:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:47,915:WARNING:<ipython-input-52-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:47,915:WARNING:<ipython-input-52-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 19:59:49,215:WARNING:<ipython-input-56-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-22 19:59:49,670:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:49,671:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:50,138:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:50,139:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:50,319:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:50,320:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:50,497:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:50,498:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:50,673:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:50,675:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:50,850:WARNING:<ipython-input-57-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 19:59:50,851:WARNING:<ipython-input-57-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 19:59:52,391:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-22 19:59:52,836:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-22 19:59:52,836:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 20:00:03,118:INFO:PyCaret ClassificationExperiment
2025-04-22 20:00:03,118:INFO:Logging name: baseline
2025-04-22 20:00:03,118:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 20:00:03,118:INFO:version 3.3.2
2025-04-22 20:00:03,118:INFO:Initializing setup()
2025-04-22 20:00:03,118:INFO:self.USI: a0b0
2025-04-22 20:00:03,118:INFO:self._variable_keys: {'fold_generator', 'y', 'target_param', '_ml_usecase', '_available_plots', 'X_test', 'idx', 'exp_name_log', 'X_train', 'USI', 'logging_param', 'seed', 'html_param', 'gpu_param', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'exp_id', 'y_test', 'y_train', 'X', 'memory', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'is_multiclass'}
2025-04-22 20:00:03,118:INFO:Checking environment
2025-04-22 20:00:03,118:INFO:python_version: 3.11.4
2025-04-22 20:00:03,118:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 20:00:03,118:INFO:machine: AMD64
2025-04-22 20:00:03,118:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 20:00:03,126:INFO:Memory: svmem(total=16498810880, available=2734878720, percent=83.4, used=13763932160, free=2734878720)
2025-04-22 20:00:03,126:INFO:Physical Core: 8
2025-04-22 20:00:03,126:INFO:Logical Core: 16
2025-04-22 20:00:03,126:INFO:Checking libraries
2025-04-22 20:00:03,126:INFO:System:
2025-04-22 20:00:03,126:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 20:00:03,126:INFO:executable: c:\Python311\python.exe
2025-04-22 20:00:03,126:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 20:00:03,126:INFO:PyCaret required dependencies:
2025-04-22 20:00:03,126:INFO:                 pip: 23.1.2
2025-04-22 20:00:03,126:INFO:          setuptools: 65.5.0
2025-04-22 20:00:03,126:INFO:             pycaret: 3.3.2
2025-04-22 20:00:03,126:INFO:             IPython: 8.20.0
2025-04-22 20:00:03,126:INFO:          ipywidgets: 8.1.6
2025-04-22 20:00:03,126:INFO:                tqdm: 4.66.2
2025-04-22 20:00:03,126:INFO:               numpy: 1.26.2
2025-04-22 20:00:03,126:INFO:              pandas: 2.1.4
2025-04-22 20:00:03,127:INFO:              jinja2: 3.1.2
2025-04-22 20:00:03,127:INFO:               scipy: 1.11.4
2025-04-22 20:00:03,127:INFO:              joblib: 1.3.2
2025-04-22 20:00:03,127:INFO:             sklearn: 1.4.2
2025-04-22 20:00:03,127:INFO:                pyod: 2.0.4
2025-04-22 20:00:03,127:INFO:            imblearn: 0.12.0
2025-04-22 20:00:03,127:INFO:   category_encoders: 2.7.0
2025-04-22 20:00:03,127:INFO:            lightgbm: 4.6.0
2025-04-22 20:00:03,127:INFO:               numba: 0.61.2
2025-04-22 20:00:03,127:INFO:            requests: 2.31.0
2025-04-22 20:00:03,127:INFO:          matplotlib: 3.7.5
2025-04-22 20:00:03,127:INFO:          scikitplot: 0.3.7
2025-04-22 20:00:03,127:INFO:         yellowbrick: 1.5
2025-04-22 20:00:03,127:INFO:              plotly: 5.24.1
2025-04-22 20:00:03,127:INFO:    plotly-resampler: Not installed
2025-04-22 20:00:03,127:INFO:             kaleido: 0.2.1
2025-04-22 20:00:03,127:INFO:           schemdraw: 0.15
2025-04-22 20:00:03,127:INFO:         statsmodels: 0.14.4
2025-04-22 20:00:03,127:INFO:              sktime: 0.26.0
2025-04-22 20:00:03,127:INFO:               tbats: 1.1.3
2025-04-22 20:00:03,127:INFO:            pmdarima: 2.0.4
2025-04-22 20:00:03,127:INFO:              psutil: 5.9.8
2025-04-22 20:00:03,127:INFO:          markupsafe: 2.1.3
2025-04-22 20:00:03,127:INFO:             pickle5: Not installed
2025-04-22 20:00:03,127:INFO:         cloudpickle: 3.1.1
2025-04-22 20:00:03,127:INFO:         deprecation: 2.1.0
2025-04-22 20:00:03,127:INFO:              xxhash: 3.5.0
2025-04-22 20:00:03,127:INFO:           wurlitzer: Not installed
2025-04-22 20:00:03,127:INFO:PyCaret optional dependencies:
2025-04-22 20:00:03,127:INFO:                shap: Not installed
2025-04-22 20:00:03,127:INFO:           interpret: Not installed
2025-04-22 20:00:03,127:INFO:                umap: Not installed
2025-04-22 20:00:03,127:INFO:     ydata_profiling: Not installed
2025-04-22 20:00:03,127:INFO:  explainerdashboard: Not installed
2025-04-22 20:00:03,127:INFO:             autoviz: Not installed
2025-04-22 20:00:03,127:INFO:           fairlearn: Not installed
2025-04-22 20:00:03,128:INFO:          deepchecks: Not installed
2025-04-22 20:00:03,128:INFO:             xgboost: Not installed
2025-04-22 20:00:03,128:INFO:            catboost: Not installed
2025-04-22 20:00:03,128:INFO:              kmodes: Not installed
2025-04-22 20:00:03,128:INFO:             mlxtend: 0.23.4
2025-04-22 20:00:03,128:INFO:       statsforecast: Not installed
2025-04-22 20:00:03,128:INFO:        tune_sklearn: Not installed
2025-04-22 20:00:03,128:INFO:                 ray: Not installed
2025-04-22 20:00:03,128:INFO:            hyperopt: Not installed
2025-04-22 20:00:03,128:INFO:              optuna: Not installed
2025-04-22 20:00:03,128:INFO:               skopt: Not installed
2025-04-22 20:00:03,128:INFO:              mlflow: Not installed
2025-04-22 20:00:03,128:INFO:              gradio: Not installed
2025-04-22 20:00:03,128:INFO:             fastapi: Not installed
2025-04-22 20:00:03,128:INFO:             uvicorn: Not installed
2025-04-22 20:00:03,128:INFO:              m2cgen: Not installed
2025-04-22 20:00:03,128:INFO:           evidently: Not installed
2025-04-22 20:00:03,128:INFO:               fugue: Not installed
2025-04-22 20:00:03,128:INFO:           streamlit: Not installed
2025-04-22 20:00:03,128:INFO:             prophet: Not installed
2025-04-22 20:00:03,128:INFO:None
2025-04-22 20:00:03,128:INFO:Set up data.
2025-04-22 20:00:03,141:INFO:Set up folding strategy.
2025-04-22 20:00:03,141:INFO:Set up train/test split.
2025-04-22 20:00:03,158:INFO:Set up index.
2025-04-22 20:00:03,159:INFO:Assigning column types.
2025-04-22 20:00:03,171:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 20:00:03,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,294:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 20:00:03,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:00:03,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,414:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 20:00:03,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:03,536:INFO:Preparing preprocessing pipeline...
2025-04-22 20:00:03,538:INFO:Set up simple imputation.
2025-04-22 20:00:03,545:INFO:Set up encoding of ordinal features.
2025-04-22 20:00:03,552:INFO:Set up encoding of categorical features.
2025-04-22 20:00:03,660:INFO:Finished creating preprocessing pipeline.
2025-04-22 20:00:03,686:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-22 20:00:03,686:INFO:Creating final display dataframe.
2025-04-22 20:00:03,970:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        a0b0
2025-04-22 20:00:04,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:04,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:04,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:04,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:00:04,097:INFO:setup() successfully completed in 1.0s...............
2025-04-22 20:00:04,224:INFO:Initializing compare_models()
2025-04-22 20:00:04,225:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 20:00:04,225:INFO:Checking exceptions
2025-04-22 20:00:04,240:INFO:Preparing display monitor
2025-04-22 20:00:04,259:INFO:Initializing Logistic Regression
2025-04-22 20:00:04,259:INFO:Total runtime is 0.0 minutes
2025-04-22 20:00:04,262:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:04,264:INFO:Initializing create_model()
2025-04-22 20:00:04,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:04,264:INFO:Checking exceptions
2025-04-22 20:00:04,264:INFO:Importing libraries
2025-04-22 20:00:04,264:INFO:Copying training dataset
2025-04-22 20:00:04,282:INFO:Defining folds
2025-04-22 20:00:04,282:INFO:Declaring metric variables
2025-04-22 20:00:04,286:INFO:Importing untrained model
2025-04-22 20:00:04,290:INFO:Logistic Regression Imported successfully
2025-04-22 20:00:04,299:INFO:Starting cross validation
2025-04-22 20:00:04,302:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:05,755:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:00:05,755:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:00:05,789:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:00:05,794:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:00:05,821:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:00:05,879:INFO:Calculating mean and std
2025-04-22 20:00:05,880:INFO:Creating metrics dataframe
2025-04-22 20:00:05,882:INFO:Uploading results into container
2025-04-22 20:00:05,882:INFO:Uploading model into container now
2025-04-22 20:00:05,884:INFO:_master_model_container: 1
2025-04-22 20:00:05,884:INFO:_display_container: 2
2025-04-22 20:00:05,884:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:00:05,884:INFO:create_model() successfully completed......................................
2025-04-22 20:00:06,092:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:06,092:INFO:Creating metrics dataframe
2025-04-22 20:00:06,098:INFO:Initializing K Neighbors Classifier
2025-04-22 20:00:06,098:INFO:Total runtime is 0.030647281805674234 minutes
2025-04-22 20:00:06,101:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:06,101:INFO:Initializing create_model()
2025-04-22 20:00:06,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:06,102:INFO:Checking exceptions
2025-04-22 20:00:06,102:INFO:Importing libraries
2025-04-22 20:00:06,102:INFO:Copying training dataset
2025-04-22 20:00:06,119:INFO:Defining folds
2025-04-22 20:00:06,119:INFO:Declaring metric variables
2025-04-22 20:00:06,122:INFO:Importing untrained model
2025-04-22 20:00:06,124:INFO:K Neighbors Classifier Imported successfully
2025-04-22 20:00:06,129:INFO:Starting cross validation
2025-04-22 20:00:06,130:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:07,197:INFO:Calculating mean and std
2025-04-22 20:00:07,198:INFO:Creating metrics dataframe
2025-04-22 20:00:07,199:INFO:Uploading results into container
2025-04-22 20:00:07,200:INFO:Uploading model into container now
2025-04-22 20:00:07,200:INFO:_master_model_container: 2
2025-04-22 20:00:07,200:INFO:_display_container: 2
2025-04-22 20:00:07,200:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 20:00:07,201:INFO:create_model() successfully completed......................................
2025-04-22 20:00:07,351:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:07,351:INFO:Creating metrics dataframe
2025-04-22 20:00:07,356:INFO:Initializing Naive Bayes
2025-04-22 20:00:07,356:INFO:Total runtime is 0.05161481300989787 minutes
2025-04-22 20:00:07,359:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:07,359:INFO:Initializing create_model()
2025-04-22 20:00:07,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:07,359:INFO:Checking exceptions
2025-04-22 20:00:07,359:INFO:Importing libraries
2025-04-22 20:00:07,359:INFO:Copying training dataset
2025-04-22 20:00:07,375:INFO:Defining folds
2025-04-22 20:00:07,375:INFO:Declaring metric variables
2025-04-22 20:00:07,379:INFO:Importing untrained model
2025-04-22 20:00:07,382:INFO:Naive Bayes Imported successfully
2025-04-22 20:00:07,387:INFO:Starting cross validation
2025-04-22 20:00:07,388:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:07,613:INFO:Calculating mean and std
2025-04-22 20:00:07,614:INFO:Creating metrics dataframe
2025-04-22 20:00:07,616:INFO:Uploading results into container
2025-04-22 20:00:07,617:INFO:Uploading model into container now
2025-04-22 20:00:07,617:INFO:_master_model_container: 3
2025-04-22 20:00:07,617:INFO:_display_container: 2
2025-04-22 20:00:07,617:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:00:07,617:INFO:create_model() successfully completed......................................
2025-04-22 20:00:07,771:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:07,771:INFO:Creating metrics dataframe
2025-04-22 20:00:07,775:INFO:Initializing Decision Tree Classifier
2025-04-22 20:00:07,775:INFO:Total runtime is 0.05860945781071981 minutes
2025-04-22 20:00:07,778:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:07,779:INFO:Initializing create_model()
2025-04-22 20:00:07,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:07,779:INFO:Checking exceptions
2025-04-22 20:00:07,779:INFO:Importing libraries
2025-04-22 20:00:07,779:INFO:Copying training dataset
2025-04-22 20:00:07,796:INFO:Defining folds
2025-04-22 20:00:07,796:INFO:Declaring metric variables
2025-04-22 20:00:07,799:INFO:Importing untrained model
2025-04-22 20:00:07,803:INFO:Decision Tree Classifier Imported successfully
2025-04-22 20:00:07,809:INFO:Starting cross validation
2025-04-22 20:00:07,810:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:08,487:INFO:Calculating mean and std
2025-04-22 20:00:08,489:INFO:Creating metrics dataframe
2025-04-22 20:00:08,491:INFO:Uploading results into container
2025-04-22 20:00:08,491:INFO:Uploading model into container now
2025-04-22 20:00:08,492:INFO:_master_model_container: 4
2025-04-22 20:00:08,492:INFO:_display_container: 2
2025-04-22 20:00:08,492:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 20:00:08,492:INFO:create_model() successfully completed......................................
2025-04-22 20:00:08,684:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:08,684:INFO:Creating metrics dataframe
2025-04-22 20:00:08,694:INFO:Initializing SVM - Linear Kernel
2025-04-22 20:00:08,694:INFO:Total runtime is 0.07392197052637736 minutes
2025-04-22 20:00:08,698:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:08,698:INFO:Initializing create_model()
2025-04-22 20:00:08,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:08,698:INFO:Checking exceptions
2025-04-22 20:00:08,698:INFO:Importing libraries
2025-04-22 20:00:08,699:INFO:Copying training dataset
2025-04-22 20:00:08,727:INFO:Defining folds
2025-04-22 20:00:08,728:INFO:Declaring metric variables
2025-04-22 20:00:08,738:INFO:Importing untrained model
2025-04-22 20:00:08,746:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 20:00:08,756:INFO:Starting cross validation
2025-04-22 20:00:08,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:09,684:INFO:Calculating mean and std
2025-04-22 20:00:09,684:INFO:Creating metrics dataframe
2025-04-22 20:00:09,687:INFO:Uploading results into container
2025-04-22 20:00:09,688:INFO:Uploading model into container now
2025-04-22 20:00:09,688:INFO:_master_model_container: 5
2025-04-22 20:00:09,688:INFO:_display_container: 2
2025-04-22 20:00:09,688:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 20:00:09,688:INFO:create_model() successfully completed......................................
2025-04-22 20:00:09,864:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:09,864:INFO:Creating metrics dataframe
2025-04-22 20:00:09,870:INFO:Initializing Ridge Classifier
2025-04-22 20:00:09,870:INFO:Total runtime is 0.09352061748504639 minutes
2025-04-22 20:00:09,872:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:09,873:INFO:Initializing create_model()
2025-04-22 20:00:09,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:09,873:INFO:Checking exceptions
2025-04-22 20:00:09,873:INFO:Importing libraries
2025-04-22 20:00:09,873:INFO:Copying training dataset
2025-04-22 20:00:09,889:INFO:Defining folds
2025-04-22 20:00:09,890:INFO:Declaring metric variables
2025-04-22 20:00:09,892:INFO:Importing untrained model
2025-04-22 20:00:09,895:INFO:Ridge Classifier Imported successfully
2025-04-22 20:00:09,901:INFO:Starting cross validation
2025-04-22 20:00:09,903:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:10,159:INFO:Calculating mean and std
2025-04-22 20:00:10,161:INFO:Creating metrics dataframe
2025-04-22 20:00:10,163:INFO:Uploading results into container
2025-04-22 20:00:10,163:INFO:Uploading model into container now
2025-04-22 20:00:10,164:INFO:_master_model_container: 6
2025-04-22 20:00:10,164:INFO:_display_container: 2
2025-04-22 20:00:10,164:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 20:00:10,164:INFO:create_model() successfully completed......................................
2025-04-22 20:00:10,357:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:10,357:INFO:Creating metrics dataframe
2025-04-22 20:00:10,363:INFO:Initializing Random Forest Classifier
2025-04-22 20:00:10,363:INFO:Total runtime is 0.10173333883285524 minutes
2025-04-22 20:00:10,367:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:10,367:INFO:Initializing create_model()
2025-04-22 20:00:10,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:10,367:INFO:Checking exceptions
2025-04-22 20:00:10,367:INFO:Importing libraries
2025-04-22 20:00:10,367:INFO:Copying training dataset
2025-04-22 20:00:10,387:INFO:Defining folds
2025-04-22 20:00:10,387:INFO:Declaring metric variables
2025-04-22 20:00:10,390:INFO:Importing untrained model
2025-04-22 20:00:10,394:INFO:Random Forest Classifier Imported successfully
2025-04-22 20:00:10,402:INFO:Starting cross validation
2025-04-22 20:00:10,404:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:13,321:INFO:Calculating mean and std
2025-04-22 20:00:13,322:INFO:Creating metrics dataframe
2025-04-22 20:00:13,324:INFO:Uploading results into container
2025-04-22 20:00:13,326:INFO:Uploading model into container now
2025-04-22 20:00:13,326:INFO:_master_model_container: 7
2025-04-22 20:00:13,327:INFO:_display_container: 2
2025-04-22 20:00:13,327:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 20:00:13,327:INFO:create_model() successfully completed......................................
2025-04-22 20:00:13,520:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:13,520:INFO:Creating metrics dataframe
2025-04-22 20:00:13,526:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 20:00:13,527:INFO:Total runtime is 0.15447540283203126 minutes
2025-04-22 20:00:13,531:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:13,531:INFO:Initializing create_model()
2025-04-22 20:00:13,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:13,531:INFO:Checking exceptions
2025-04-22 20:00:13,532:INFO:Importing libraries
2025-04-22 20:00:13,532:INFO:Copying training dataset
2025-04-22 20:00:13,550:INFO:Defining folds
2025-04-22 20:00:13,550:INFO:Declaring metric variables
2025-04-22 20:00:13,554:INFO:Importing untrained model
2025-04-22 20:00:13,558:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 20:00:13,566:INFO:Starting cross validation
2025-04-22 20:00:13,567:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:13,758:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:00:13,761:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:00:13,765:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:00:13,778:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:00:13,788:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:00:13,852:INFO:Calculating mean and std
2025-04-22 20:00:13,853:INFO:Creating metrics dataframe
2025-04-22 20:00:13,855:INFO:Uploading results into container
2025-04-22 20:00:13,855:INFO:Uploading model into container now
2025-04-22 20:00:13,856:INFO:_master_model_container: 8
2025-04-22 20:00:13,856:INFO:_display_container: 2
2025-04-22 20:00:13,856:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 20:00:13,856:INFO:create_model() successfully completed......................................
2025-04-22 20:00:14,019:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:14,020:INFO:Creating metrics dataframe
2025-04-22 20:00:14,030:INFO:Initializing Ada Boost Classifier
2025-04-22 20:00:14,031:INFO:Total runtime is 0.16286492745081585 minutes
2025-04-22 20:00:14,035:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:14,035:INFO:Initializing create_model()
2025-04-22 20:00:14,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:14,035:INFO:Checking exceptions
2025-04-22 20:00:14,036:INFO:Importing libraries
2025-04-22 20:00:14,036:INFO:Copying training dataset
2025-04-22 20:00:14,063:INFO:Defining folds
2025-04-22 20:00:14,063:INFO:Declaring metric variables
2025-04-22 20:00:14,070:INFO:Importing untrained model
2025-04-22 20:00:14,076:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:00:14,087:INFO:Starting cross validation
2025-04-22 20:00:14,090:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:14,256:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:00:14,259:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:00:14,272:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:00:14,280:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:00:14,294:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:00:15,999:INFO:Calculating mean and std
2025-04-22 20:00:16,000:INFO:Creating metrics dataframe
2025-04-22 20:00:16,002:INFO:Uploading results into container
2025-04-22 20:00:16,002:INFO:Uploading model into container now
2025-04-22 20:00:16,003:INFO:_master_model_container: 9
2025-04-22 20:00:16,003:INFO:_display_container: 2
2025-04-22 20:00:16,003:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 20:00:16,003:INFO:create_model() successfully completed......................................
2025-04-22 20:00:16,150:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:16,151:INFO:Creating metrics dataframe
2025-04-22 20:00:16,157:INFO:Initializing Gradient Boosting Classifier
2025-04-22 20:00:16,158:INFO:Total runtime is 0.1983266870180766 minutes
2025-04-22 20:00:16,161:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:16,161:INFO:Initializing create_model()
2025-04-22 20:00:16,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:16,161:INFO:Checking exceptions
2025-04-22 20:00:16,163:INFO:Importing libraries
2025-04-22 20:00:16,163:INFO:Copying training dataset
2025-04-22 20:00:16,180:INFO:Defining folds
2025-04-22 20:00:16,181:INFO:Declaring metric variables
2025-04-22 20:00:16,185:INFO:Importing untrained model
2025-04-22 20:00:16,189:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:00:16,194:INFO:Starting cross validation
2025-04-22 20:00:16,195:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:23,264:INFO:Calculating mean and std
2025-04-22 20:00:23,265:INFO:Creating metrics dataframe
2025-04-22 20:00:23,266:INFO:Uploading results into container
2025-04-22 20:00:23,267:INFO:Uploading model into container now
2025-04-22 20:00:23,267:INFO:_master_model_container: 10
2025-04-22 20:00:23,267:INFO:_display_container: 2
2025-04-22 20:00:23,267:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:00:23,267:INFO:create_model() successfully completed......................................
2025-04-22 20:00:23,434:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:23,434:INFO:Creating metrics dataframe
2025-04-22 20:00:23,440:INFO:Initializing Linear Discriminant Analysis
2025-04-22 20:00:23,440:INFO:Total runtime is 0.3196922898292542 minutes
2025-04-22 20:00:23,443:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:23,444:INFO:Initializing create_model()
2025-04-22 20:00:23,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:23,444:INFO:Checking exceptions
2025-04-22 20:00:23,444:INFO:Importing libraries
2025-04-22 20:00:23,444:INFO:Copying training dataset
2025-04-22 20:00:23,464:INFO:Defining folds
2025-04-22 20:00:23,464:INFO:Declaring metric variables
2025-04-22 20:00:23,467:INFO:Importing untrained model
2025-04-22 20:00:23,470:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 20:00:23,476:INFO:Starting cross validation
2025-04-22 20:00:23,477:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:23,736:INFO:Calculating mean and std
2025-04-22 20:00:23,737:INFO:Creating metrics dataframe
2025-04-22 20:00:23,738:INFO:Uploading results into container
2025-04-22 20:00:23,739:INFO:Uploading model into container now
2025-04-22 20:00:23,739:INFO:_master_model_container: 11
2025-04-22 20:00:23,739:INFO:_display_container: 2
2025-04-22 20:00:23,740:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 20:00:23,740:INFO:create_model() successfully completed......................................
2025-04-22 20:00:23,904:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:23,904:INFO:Creating metrics dataframe
2025-04-22 20:00:23,911:INFO:Initializing Extra Trees Classifier
2025-04-22 20:00:23,912:INFO:Total runtime is 0.32754537264506023 minutes
2025-04-22 20:00:23,914:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:23,915:INFO:Initializing create_model()
2025-04-22 20:00:23,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:23,915:INFO:Checking exceptions
2025-04-22 20:00:23,915:INFO:Importing libraries
2025-04-22 20:00:23,915:INFO:Copying training dataset
2025-04-22 20:00:23,931:INFO:Defining folds
2025-04-22 20:00:23,931:INFO:Declaring metric variables
2025-04-22 20:00:23,934:INFO:Importing untrained model
2025-04-22 20:00:23,937:INFO:Extra Trees Classifier Imported successfully
2025-04-22 20:00:23,944:INFO:Starting cross validation
2025-04-22 20:00:23,946:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:25,412:INFO:Calculating mean and std
2025-04-22 20:00:25,413:INFO:Creating metrics dataframe
2025-04-22 20:00:25,416:INFO:Uploading results into container
2025-04-22 20:00:25,417:INFO:Uploading model into container now
2025-04-22 20:00:25,417:INFO:_master_model_container: 12
2025-04-22 20:00:25,417:INFO:_display_container: 2
2025-04-22 20:00:25,418:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 20:00:25,418:INFO:create_model() successfully completed......................................
2025-04-22 20:00:25,617:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:25,617:INFO:Creating metrics dataframe
2025-04-22 20:00:25,624:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 20:00:25,624:INFO:Total runtime is 0.35609204371770226 minutes
2025-04-22 20:00:25,628:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:25,628:INFO:Initializing create_model()
2025-04-22 20:00:25,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:25,628:INFO:Checking exceptions
2025-04-22 20:00:25,628:INFO:Importing libraries
2025-04-22 20:00:25,628:INFO:Copying training dataset
2025-04-22 20:00:25,647:INFO:Defining folds
2025-04-22 20:00:25,647:INFO:Declaring metric variables
2025-04-22 20:00:25,652:INFO:Importing untrained model
2025-04-22 20:00:25,656:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:00:25,662:INFO:Starting cross validation
2025-04-22 20:00:25,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:26,557:INFO:Calculating mean and std
2025-04-22 20:00:26,559:INFO:Creating metrics dataframe
2025-04-22 20:00:26,561:INFO:Uploading results into container
2025-04-22 20:00:26,562:INFO:Uploading model into container now
2025-04-22 20:00:26,562:INFO:_master_model_container: 13
2025-04-22 20:00:26,562:INFO:_display_container: 2
2025-04-22 20:00:26,563:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:00:26,564:INFO:create_model() successfully completed......................................
2025-04-22 20:00:26,758:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:26,759:INFO:Creating metrics dataframe
2025-04-22 20:00:26,765:INFO:Initializing Dummy Classifier
2025-04-22 20:00:26,765:INFO:Total runtime is 0.3751071453094483 minutes
2025-04-22 20:00:26,768:INFO:SubProcess create_model() called ==================================
2025-04-22 20:00:26,768:INFO:Initializing create_model()
2025-04-22 20:00:26,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E4D8A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:26,769:INFO:Checking exceptions
2025-04-22 20:00:26,769:INFO:Importing libraries
2025-04-22 20:00:26,769:INFO:Copying training dataset
2025-04-22 20:00:26,787:INFO:Defining folds
2025-04-22 20:00:26,787:INFO:Declaring metric variables
2025-04-22 20:00:26,789:INFO:Importing untrained model
2025-04-22 20:00:26,793:INFO:Dummy Classifier Imported successfully
2025-04-22 20:00:26,797:INFO:Starting cross validation
2025-04-22 20:00:26,799:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:00:26,968:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:00:26,969:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:00:26,982:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:00:26,989:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:00:26,990:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:00:27,004:INFO:Calculating mean and std
2025-04-22 20:00:27,005:INFO:Creating metrics dataframe
2025-04-22 20:00:27,006:INFO:Uploading results into container
2025-04-22 20:00:27,007:INFO:Uploading model into container now
2025-04-22 20:00:27,007:INFO:_master_model_container: 14
2025-04-22 20:00:27,007:INFO:_display_container: 2
2025-04-22 20:00:27,007:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 20:00:27,007:INFO:create_model() successfully completed......................................
2025-04-22 20:00:27,164:INFO:SubProcess create_model() end ==================================
2025-04-22 20:00:27,164:INFO:Creating metrics dataframe
2025-04-22 20:00:27,172:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 20:00:27,179:INFO:Initializing create_model()
2025-04-22 20:00:27,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D220D6DA10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:00:27,179:INFO:Checking exceptions
2025-04-22 20:00:27,180:INFO:Importing libraries
2025-04-22 20:00:27,180:INFO:Copying training dataset
2025-04-22 20:00:27,197:INFO:Defining folds
2025-04-22 20:00:27,198:INFO:Declaring metric variables
2025-04-22 20:00:27,198:INFO:Importing untrained model
2025-04-22 20:00:27,198:INFO:Declaring custom model
2025-04-22 20:00:27,198:INFO:Naive Bayes Imported successfully
2025-04-22 20:00:27,199:INFO:Cross validation set to False
2025-04-22 20:00:27,199:INFO:Fitting Model
2025-04-22 20:00:27,291:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:00:27,291:INFO:create_model() successfully completed......................................
2025-04-22 20:00:27,456:INFO:_master_model_container: 14
2025-04-22 20:00:27,456:INFO:_display_container: 2
2025-04-22 20:00:27,456:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:00:27,458:INFO:compare_models() successfully completed......................................
2025-04-22 20:01:13,368:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,369:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:13,449:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,452:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:13,529:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,530:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:13,611:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,612:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:13,694:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,694:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:13,778:WARNING:<ipython-input-81-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:13,779:WARNING:<ipython-input-81-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-22 20:01:15,360:WARNING:<ipython-input-85-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-22 20:01:15,893:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:15,894:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:16,448:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:16,449:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:16,634:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:16,636:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:16,823:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:16,824:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:17,006:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:17,007:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:17,182:WARNING:<ipython-input-86-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-22 20:01:17,183:WARNING:<ipython-input-86-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-22 20:01:18,626:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-22 20:01:19,085:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-22 20:01:19,086:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-22 20:01:29,292:INFO:PyCaret ClassificationExperiment
2025-04-22 20:01:29,292:INFO:Logging name: baseline
2025-04-22 20:01:29,292:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 20:01:29,292:INFO:version 3.3.2
2025-04-22 20:01:29,292:INFO:Initializing setup()
2025-04-22 20:01:29,292:INFO:self.USI: 5bdd
2025-04-22 20:01:29,292:INFO:self._variable_keys: {'fold_generator', 'y', 'target_param', '_ml_usecase', '_available_plots', 'X_test', 'idx', 'exp_name_log', 'X_train', 'USI', 'logging_param', 'seed', 'html_param', 'gpu_param', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'exp_id', 'y_test', 'y_train', 'X', 'memory', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'is_multiclass'}
2025-04-22 20:01:29,292:INFO:Checking environment
2025-04-22 20:01:29,292:INFO:python_version: 3.11.4
2025-04-22 20:01:29,292:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 20:01:29,292:INFO:machine: AMD64
2025-04-22 20:01:29,292:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 20:01:29,300:INFO:Memory: svmem(total=16498810880, available=2685837312, percent=83.7, used=13812973568, free=2685837312)
2025-04-22 20:01:29,301:INFO:Physical Core: 8
2025-04-22 20:01:29,301:INFO:Logical Core: 16
2025-04-22 20:01:29,301:INFO:Checking libraries
2025-04-22 20:01:29,301:INFO:System:
2025-04-22 20:01:29,301:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 20:01:29,301:INFO:executable: c:\Python311\python.exe
2025-04-22 20:01:29,301:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 20:01:29,301:INFO:PyCaret required dependencies:
2025-04-22 20:01:29,301:INFO:                 pip: 23.1.2
2025-04-22 20:01:29,301:INFO:          setuptools: 65.5.0
2025-04-22 20:01:29,301:INFO:             pycaret: 3.3.2
2025-04-22 20:01:29,301:INFO:             IPython: 8.20.0
2025-04-22 20:01:29,301:INFO:          ipywidgets: 8.1.6
2025-04-22 20:01:29,301:INFO:                tqdm: 4.66.2
2025-04-22 20:01:29,301:INFO:               numpy: 1.26.2
2025-04-22 20:01:29,301:INFO:              pandas: 2.1.4
2025-04-22 20:01:29,301:INFO:              jinja2: 3.1.2
2025-04-22 20:01:29,301:INFO:               scipy: 1.11.4
2025-04-22 20:01:29,301:INFO:              joblib: 1.3.2
2025-04-22 20:01:29,301:INFO:             sklearn: 1.4.2
2025-04-22 20:01:29,301:INFO:                pyod: 2.0.4
2025-04-22 20:01:29,301:INFO:            imblearn: 0.12.0
2025-04-22 20:01:29,301:INFO:   category_encoders: 2.7.0
2025-04-22 20:01:29,301:INFO:            lightgbm: 4.6.0
2025-04-22 20:01:29,301:INFO:               numba: 0.61.2
2025-04-22 20:01:29,301:INFO:            requests: 2.31.0
2025-04-22 20:01:29,301:INFO:          matplotlib: 3.7.5
2025-04-22 20:01:29,302:INFO:          scikitplot: 0.3.7
2025-04-22 20:01:29,302:INFO:         yellowbrick: 1.5
2025-04-22 20:01:29,302:INFO:              plotly: 5.24.1
2025-04-22 20:01:29,302:INFO:    plotly-resampler: Not installed
2025-04-22 20:01:29,302:INFO:             kaleido: 0.2.1
2025-04-22 20:01:29,302:INFO:           schemdraw: 0.15
2025-04-22 20:01:29,302:INFO:         statsmodels: 0.14.4
2025-04-22 20:01:29,302:INFO:              sktime: 0.26.0
2025-04-22 20:01:29,302:INFO:               tbats: 1.1.3
2025-04-22 20:01:29,302:INFO:            pmdarima: 2.0.4
2025-04-22 20:01:29,302:INFO:              psutil: 5.9.8
2025-04-22 20:01:29,302:INFO:          markupsafe: 2.1.3
2025-04-22 20:01:29,302:INFO:             pickle5: Not installed
2025-04-22 20:01:29,302:INFO:         cloudpickle: 3.1.1
2025-04-22 20:01:29,302:INFO:         deprecation: 2.1.0
2025-04-22 20:01:29,302:INFO:              xxhash: 3.5.0
2025-04-22 20:01:29,302:INFO:           wurlitzer: Not installed
2025-04-22 20:01:29,302:INFO:PyCaret optional dependencies:
2025-04-22 20:01:29,302:INFO:                shap: Not installed
2025-04-22 20:01:29,302:INFO:           interpret: Not installed
2025-04-22 20:01:29,302:INFO:                umap: Not installed
2025-04-22 20:01:29,302:INFO:     ydata_profiling: Not installed
2025-04-22 20:01:29,302:INFO:  explainerdashboard: Not installed
2025-04-22 20:01:29,302:INFO:             autoviz: Not installed
2025-04-22 20:01:29,302:INFO:           fairlearn: Not installed
2025-04-22 20:01:29,302:INFO:          deepchecks: Not installed
2025-04-22 20:01:29,302:INFO:             xgboost: Not installed
2025-04-22 20:01:29,302:INFO:            catboost: Not installed
2025-04-22 20:01:29,302:INFO:              kmodes: Not installed
2025-04-22 20:01:29,302:INFO:             mlxtend: 0.23.4
2025-04-22 20:01:29,302:INFO:       statsforecast: Not installed
2025-04-22 20:01:29,302:INFO:        tune_sklearn: Not installed
2025-04-22 20:01:29,302:INFO:                 ray: Not installed
2025-04-22 20:01:29,302:INFO:            hyperopt: Not installed
2025-04-22 20:01:29,302:INFO:              optuna: Not installed
2025-04-22 20:01:29,302:INFO:               skopt: Not installed
2025-04-22 20:01:29,302:INFO:              mlflow: Not installed
2025-04-22 20:01:29,303:INFO:              gradio: Not installed
2025-04-22 20:01:29,303:INFO:             fastapi: Not installed
2025-04-22 20:01:29,303:INFO:             uvicorn: Not installed
2025-04-22 20:01:29,303:INFO:              m2cgen: Not installed
2025-04-22 20:01:29,303:INFO:           evidently: Not installed
2025-04-22 20:01:29,303:INFO:               fugue: Not installed
2025-04-22 20:01:29,303:INFO:           streamlit: Not installed
2025-04-22 20:01:29,303:INFO:             prophet: Not installed
2025-04-22 20:01:29,303:INFO:None
2025-04-22 20:01:29,303:INFO:Set up data.
2025-04-22 20:01:29,314:INFO:Set up folding strategy.
2025-04-22 20:01:29,314:INFO:Set up train/test split.
2025-04-22 20:01:29,330:INFO:Set up index.
2025-04-22 20:01:29,332:INFO:Assigning column types.
2025-04-22 20:01:29,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 20:01:29,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,464:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 20:01:29,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,561:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:01:29,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,583:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 20:01:29,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:29,704:INFO:Preparing preprocessing pipeline...
2025-04-22 20:01:29,706:INFO:Set up simple imputation.
2025-04-22 20:01:29,713:INFO:Set up encoding of ordinal features.
2025-04-22 20:01:29,720:INFO:Set up encoding of categorical features.
2025-04-22 20:01:29,826:INFO:Finished creating preprocessing pipeline.
2025-04-22 20:01:29,851:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-22 20:01:29,851:INFO:Creating final display dataframe.
2025-04-22 20:01:30,112:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        5bdd
2025-04-22 20:01:30,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:30,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:30,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:30,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:01:30,236:INFO:setup() successfully completed in 0.96s...............
2025-04-22 20:01:30,248:INFO:Initializing compare_models()
2025-04-22 20:01:30,248:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 20:01:30,248:INFO:Checking exceptions
2025-04-22 20:01:30,259:INFO:Preparing display monitor
2025-04-22 20:01:30,274:INFO:Initializing Logistic Regression
2025-04-22 20:01:30,274:INFO:Total runtime is 0.0 minutes
2025-04-22 20:01:30,276:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:30,277:INFO:Initializing create_model()
2025-04-22 20:01:30,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:30,278:INFO:Checking exceptions
2025-04-22 20:01:30,278:INFO:Importing libraries
2025-04-22 20:01:30,278:INFO:Copying training dataset
2025-04-22 20:01:30,301:INFO:Defining folds
2025-04-22 20:01:30,301:INFO:Declaring metric variables
2025-04-22 20:01:30,304:INFO:Importing untrained model
2025-04-22 20:01:30,307:INFO:Logistic Regression Imported successfully
2025-04-22 20:01:30,314:INFO:Starting cross validation
2025-04-22 20:01:30,315:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:31,611:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:01:31,694:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:01:31,707:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:01:31,717:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:01:31,751:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-22 20:01:31,796:INFO:Calculating mean and std
2025-04-22 20:01:31,797:INFO:Creating metrics dataframe
2025-04-22 20:01:31,798:INFO:Uploading results into container
2025-04-22 20:01:31,799:INFO:Uploading model into container now
2025-04-22 20:01:31,799:INFO:_master_model_container: 1
2025-04-22 20:01:31,799:INFO:_display_container: 2
2025-04-22 20:01:31,800:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:01:31,800:INFO:create_model() successfully completed......................................
2025-04-22 20:01:31,991:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:31,992:INFO:Creating metrics dataframe
2025-04-22 20:01:31,997:INFO:Initializing K Neighbors Classifier
2025-04-22 20:01:31,997:INFO:Total runtime is 0.028715320428212485 minutes
2025-04-22 20:01:32,000:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:32,000:INFO:Initializing create_model()
2025-04-22 20:01:32,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:32,000:INFO:Checking exceptions
2025-04-22 20:01:32,000:INFO:Importing libraries
2025-04-22 20:01:32,000:INFO:Copying training dataset
2025-04-22 20:01:32,017:INFO:Defining folds
2025-04-22 20:01:32,017:INFO:Declaring metric variables
2025-04-22 20:01:32,020:INFO:Importing untrained model
2025-04-22 20:01:32,023:INFO:K Neighbors Classifier Imported successfully
2025-04-22 20:01:32,028:INFO:Starting cross validation
2025-04-22 20:01:32,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:32,984:INFO:Calculating mean and std
2025-04-22 20:01:32,985:INFO:Creating metrics dataframe
2025-04-22 20:01:32,986:INFO:Uploading results into container
2025-04-22 20:01:32,987:INFO:Uploading model into container now
2025-04-22 20:01:32,987:INFO:_master_model_container: 2
2025-04-22 20:01:32,987:INFO:_display_container: 2
2025-04-22 20:01:32,988:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 20:01:32,988:INFO:create_model() successfully completed......................................
2025-04-22 20:01:33,156:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:33,156:INFO:Creating metrics dataframe
2025-04-22 20:01:33,161:INFO:Initializing Naive Bayes
2025-04-22 20:01:33,161:INFO:Total runtime is 0.048122934500376385 minutes
2025-04-22 20:01:33,163:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:33,163:INFO:Initializing create_model()
2025-04-22 20:01:33,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:33,164:INFO:Checking exceptions
2025-04-22 20:01:33,164:INFO:Importing libraries
2025-04-22 20:01:33,164:INFO:Copying training dataset
2025-04-22 20:01:33,179:INFO:Defining folds
2025-04-22 20:01:33,179:INFO:Declaring metric variables
2025-04-22 20:01:33,182:INFO:Importing untrained model
2025-04-22 20:01:33,185:INFO:Naive Bayes Imported successfully
2025-04-22 20:01:33,189:INFO:Starting cross validation
2025-04-22 20:01:33,191:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:33,370:INFO:Calculating mean and std
2025-04-22 20:01:33,371:INFO:Creating metrics dataframe
2025-04-22 20:01:33,372:INFO:Uploading results into container
2025-04-22 20:01:33,372:INFO:Uploading model into container now
2025-04-22 20:01:33,373:INFO:_master_model_container: 3
2025-04-22 20:01:33,373:INFO:_display_container: 2
2025-04-22 20:01:33,373:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:01:33,373:INFO:create_model() successfully completed......................................
2025-04-22 20:01:33,520:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:33,520:INFO:Creating metrics dataframe
2025-04-22 20:01:33,527:INFO:Initializing Decision Tree Classifier
2025-04-22 20:01:33,527:INFO:Total runtime is 0.054218260447184245 minutes
2025-04-22 20:01:33,529:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:33,529:INFO:Initializing create_model()
2025-04-22 20:01:33,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:33,529:INFO:Checking exceptions
2025-04-22 20:01:33,529:INFO:Importing libraries
2025-04-22 20:01:33,529:INFO:Copying training dataset
2025-04-22 20:01:33,544:INFO:Defining folds
2025-04-22 20:01:33,544:INFO:Declaring metric variables
2025-04-22 20:01:33,547:INFO:Importing untrained model
2025-04-22 20:01:33,550:INFO:Decision Tree Classifier Imported successfully
2025-04-22 20:01:33,555:INFO:Starting cross validation
2025-04-22 20:01:33,556:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:34,087:INFO:Calculating mean and std
2025-04-22 20:01:34,088:INFO:Creating metrics dataframe
2025-04-22 20:01:34,089:INFO:Uploading results into container
2025-04-22 20:01:34,090:INFO:Uploading model into container now
2025-04-22 20:01:34,090:INFO:_master_model_container: 4
2025-04-22 20:01:34,090:INFO:_display_container: 2
2025-04-22 20:01:34,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 20:01:34,091:INFO:create_model() successfully completed......................................
2025-04-22 20:01:34,237:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:34,237:INFO:Creating metrics dataframe
2025-04-22 20:01:34,242:INFO:Initializing SVM - Linear Kernel
2025-04-22 20:01:34,243:INFO:Total runtime is 0.06615994771321615 minutes
2025-04-22 20:01:34,245:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:34,245:INFO:Initializing create_model()
2025-04-22 20:01:34,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:34,245:INFO:Checking exceptions
2025-04-22 20:01:34,245:INFO:Importing libraries
2025-04-22 20:01:34,245:INFO:Copying training dataset
2025-04-22 20:01:34,263:INFO:Defining folds
2025-04-22 20:01:34,263:INFO:Declaring metric variables
2025-04-22 20:01:34,266:INFO:Importing untrained model
2025-04-22 20:01:34,268:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 20:01:34,272:INFO:Starting cross validation
2025-04-22 20:01:34,274:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:34,784:INFO:Calculating mean and std
2025-04-22 20:01:34,784:INFO:Creating metrics dataframe
2025-04-22 20:01:34,786:INFO:Uploading results into container
2025-04-22 20:01:34,787:INFO:Uploading model into container now
2025-04-22 20:01:34,787:INFO:_master_model_container: 5
2025-04-22 20:01:34,787:INFO:_display_container: 2
2025-04-22 20:01:34,787:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 20:01:34,787:INFO:create_model() successfully completed......................................
2025-04-22 20:01:34,934:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:34,934:INFO:Creating metrics dataframe
2025-04-22 20:01:34,941:INFO:Initializing Ridge Classifier
2025-04-22 20:01:34,941:INFO:Total runtime is 0.07778344154357911 minutes
2025-04-22 20:01:34,944:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:34,944:INFO:Initializing create_model()
2025-04-22 20:01:34,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:34,944:INFO:Checking exceptions
2025-04-22 20:01:34,944:INFO:Importing libraries
2025-04-22 20:01:34,944:INFO:Copying training dataset
2025-04-22 20:01:34,961:INFO:Defining folds
2025-04-22 20:01:34,961:INFO:Declaring metric variables
2025-04-22 20:01:34,964:INFO:Importing untrained model
2025-04-22 20:01:34,967:INFO:Ridge Classifier Imported successfully
2025-04-22 20:01:34,972:INFO:Starting cross validation
2025-04-22 20:01:34,973:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:35,162:INFO:Calculating mean and std
2025-04-22 20:01:35,163:INFO:Creating metrics dataframe
2025-04-22 20:01:35,164:INFO:Uploading results into container
2025-04-22 20:01:35,166:INFO:Uploading model into container now
2025-04-22 20:01:35,166:INFO:_master_model_container: 6
2025-04-22 20:01:35,166:INFO:_display_container: 2
2025-04-22 20:01:35,166:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 20:01:35,166:INFO:create_model() successfully completed......................................
2025-04-22 20:01:35,320:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:35,320:INFO:Creating metrics dataframe
2025-04-22 20:01:35,326:INFO:Initializing Random Forest Classifier
2025-04-22 20:01:35,326:INFO:Total runtime is 0.08419833183288575 minutes
2025-04-22 20:01:35,328:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:35,328:INFO:Initializing create_model()
2025-04-22 20:01:35,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:35,328:INFO:Checking exceptions
2025-04-22 20:01:35,328:INFO:Importing libraries
2025-04-22 20:01:35,328:INFO:Copying training dataset
2025-04-22 20:01:35,343:INFO:Defining folds
2025-04-22 20:01:35,343:INFO:Declaring metric variables
2025-04-22 20:01:35,347:INFO:Importing untrained model
2025-04-22 20:01:35,350:INFO:Random Forest Classifier Imported successfully
2025-04-22 20:01:35,354:INFO:Starting cross validation
2025-04-22 20:01:35,354:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:38,029:INFO:Calculating mean and std
2025-04-22 20:01:38,030:INFO:Creating metrics dataframe
2025-04-22 20:01:38,031:INFO:Uploading results into container
2025-04-22 20:01:38,033:INFO:Uploading model into container now
2025-04-22 20:01:38,033:INFO:_master_model_container: 7
2025-04-22 20:01:38,033:INFO:_display_container: 2
2025-04-22 20:01:38,033:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 20:01:38,034:INFO:create_model() successfully completed......................................
2025-04-22 20:01:38,184:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:38,184:INFO:Creating metrics dataframe
2025-04-22 20:01:38,191:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 20:01:38,191:INFO:Total runtime is 0.1319468418757121 minutes
2025-04-22 20:01:38,194:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:38,194:INFO:Initializing create_model()
2025-04-22 20:01:38,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:38,195:INFO:Checking exceptions
2025-04-22 20:01:38,195:INFO:Importing libraries
2025-04-22 20:01:38,195:INFO:Copying training dataset
2025-04-22 20:01:38,212:INFO:Defining folds
2025-04-22 20:01:38,212:INFO:Declaring metric variables
2025-04-22 20:01:38,214:INFO:Importing untrained model
2025-04-22 20:01:38,218:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 20:01:38,223:INFO:Starting cross validation
2025-04-22 20:01:38,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:38,358:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:01:38,361:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:01:38,370:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:01:38,386:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:01:38,386:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-22 20:01:38,436:INFO:Calculating mean and std
2025-04-22 20:01:38,438:INFO:Creating metrics dataframe
2025-04-22 20:01:38,439:INFO:Uploading results into container
2025-04-22 20:01:38,440:INFO:Uploading model into container now
2025-04-22 20:01:38,440:INFO:_master_model_container: 8
2025-04-22 20:01:38,440:INFO:_display_container: 2
2025-04-22 20:01:38,440:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 20:01:38,440:INFO:create_model() successfully completed......................................
2025-04-22 20:01:38,597:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:38,597:INFO:Creating metrics dataframe
2025-04-22 20:01:38,603:INFO:Initializing Ada Boost Classifier
2025-04-22 20:01:38,603:INFO:Total runtime is 0.13881770372390748 minutes
2025-04-22 20:01:38,606:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:38,606:INFO:Initializing create_model()
2025-04-22 20:01:38,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:38,606:INFO:Checking exceptions
2025-04-22 20:01:38,606:INFO:Importing libraries
2025-04-22 20:01:38,606:INFO:Copying training dataset
2025-04-22 20:01:38,622:INFO:Defining folds
2025-04-22 20:01:38,622:INFO:Declaring metric variables
2025-04-22 20:01:38,624:INFO:Importing untrained model
2025-04-22 20:01:38,626:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:01:38,631:INFO:Starting cross validation
2025-04-22 20:01:38,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:38,755:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:01:38,763:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:01:38,770:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:01:38,770:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:01:38,782:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:01:40,279:INFO:Calculating mean and std
2025-04-22 20:01:40,280:INFO:Creating metrics dataframe
2025-04-22 20:01:40,282:INFO:Uploading results into container
2025-04-22 20:01:40,282:INFO:Uploading model into container now
2025-04-22 20:01:40,282:INFO:_master_model_container: 9
2025-04-22 20:01:40,284:INFO:_display_container: 2
2025-04-22 20:01:40,284:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 20:01:40,284:INFO:create_model() successfully completed......................................
2025-04-22 20:01:40,434:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:40,434:INFO:Creating metrics dataframe
2025-04-22 20:01:40,440:INFO:Initializing Gradient Boosting Classifier
2025-04-22 20:01:40,440:INFO:Total runtime is 0.1694408893585205 minutes
2025-04-22 20:01:40,444:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:40,444:INFO:Initializing create_model()
2025-04-22 20:01:40,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:40,444:INFO:Checking exceptions
2025-04-22 20:01:40,444:INFO:Importing libraries
2025-04-22 20:01:40,444:INFO:Copying training dataset
2025-04-22 20:01:40,462:INFO:Defining folds
2025-04-22 20:01:40,462:INFO:Declaring metric variables
2025-04-22 20:01:40,464:INFO:Importing untrained model
2025-04-22 20:01:40,466:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:01:40,471:INFO:Starting cross validation
2025-04-22 20:01:40,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:47,404:INFO:Calculating mean and std
2025-04-22 20:01:47,404:INFO:Creating metrics dataframe
2025-04-22 20:01:47,407:INFO:Uploading results into container
2025-04-22 20:01:47,407:INFO:Uploading model into container now
2025-04-22 20:01:47,408:INFO:_master_model_container: 10
2025-04-22 20:01:47,408:INFO:_display_container: 2
2025-04-22 20:01:47,408:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:01:47,408:INFO:create_model() successfully completed......................................
2025-04-22 20:01:47,565:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:47,567:INFO:Creating metrics dataframe
2025-04-22 20:01:47,574:INFO:Initializing Linear Discriminant Analysis
2025-04-22 20:01:47,574:INFO:Total runtime is 0.2883321285247803 minutes
2025-04-22 20:01:47,576:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:47,576:INFO:Initializing create_model()
2025-04-22 20:01:47,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:47,576:INFO:Checking exceptions
2025-04-22 20:01:47,576:INFO:Importing libraries
2025-04-22 20:01:47,576:INFO:Copying training dataset
2025-04-22 20:01:47,593:INFO:Defining folds
2025-04-22 20:01:47,593:INFO:Declaring metric variables
2025-04-22 20:01:47,596:INFO:Importing untrained model
2025-04-22 20:01:47,598:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 20:01:47,605:INFO:Starting cross validation
2025-04-22 20:01:47,605:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:47,867:INFO:Calculating mean and std
2025-04-22 20:01:47,868:INFO:Creating metrics dataframe
2025-04-22 20:01:47,870:INFO:Uploading results into container
2025-04-22 20:01:47,870:INFO:Uploading model into container now
2025-04-22 20:01:47,871:INFO:_master_model_container: 11
2025-04-22 20:01:47,871:INFO:_display_container: 2
2025-04-22 20:01:47,871:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 20:01:47,871:INFO:create_model() successfully completed......................................
2025-04-22 20:01:48,045:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:48,045:INFO:Creating metrics dataframe
2025-04-22 20:01:48,052:INFO:Initializing Extra Trees Classifier
2025-04-22 20:01:48,052:INFO:Total runtime is 0.2963078260421753 minutes
2025-04-22 20:01:48,054:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:48,056:INFO:Initializing create_model()
2025-04-22 20:01:48,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:48,056:INFO:Checking exceptions
2025-04-22 20:01:48,056:INFO:Importing libraries
2025-04-22 20:01:48,056:INFO:Copying training dataset
2025-04-22 20:01:48,072:INFO:Defining folds
2025-04-22 20:01:48,072:INFO:Declaring metric variables
2025-04-22 20:01:48,075:INFO:Importing untrained model
2025-04-22 20:01:48,077:INFO:Extra Trees Classifier Imported successfully
2025-04-22 20:01:48,082:INFO:Starting cross validation
2025-04-22 20:01:48,084:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:49,526:INFO:Calculating mean and std
2025-04-22 20:01:49,527:INFO:Creating metrics dataframe
2025-04-22 20:01:49,529:INFO:Uploading results into container
2025-04-22 20:01:49,529:INFO:Uploading model into container now
2025-04-22 20:01:49,530:INFO:_master_model_container: 12
2025-04-22 20:01:49,530:INFO:_display_container: 2
2025-04-22 20:01:49,530:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 20:01:49,530:INFO:create_model() successfully completed......................................
2025-04-22 20:01:49,687:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:49,687:INFO:Creating metrics dataframe
2025-04-22 20:01:49,694:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 20:01:49,694:INFO:Total runtime is 0.3236677447954814 minutes
2025-04-22 20:01:49,697:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:49,697:INFO:Initializing create_model()
2025-04-22 20:01:49,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:49,697:INFO:Checking exceptions
2025-04-22 20:01:49,697:INFO:Importing libraries
2025-04-22 20:01:49,697:INFO:Copying training dataset
2025-04-22 20:01:49,714:INFO:Defining folds
2025-04-22 20:01:49,714:INFO:Declaring metric variables
2025-04-22 20:01:49,718:INFO:Importing untrained model
2025-04-22 20:01:49,721:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:01:49,728:INFO:Starting cross validation
2025-04-22 20:01:49,729:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:50,564:INFO:Calculating mean and std
2025-04-22 20:01:50,566:INFO:Creating metrics dataframe
2025-04-22 20:01:50,568:INFO:Uploading results into container
2025-04-22 20:01:50,569:INFO:Uploading model into container now
2025-04-22 20:01:50,569:INFO:_master_model_container: 13
2025-04-22 20:01:50,569:INFO:_display_container: 2
2025-04-22 20:01:50,570:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:01:50,570:INFO:create_model() successfully completed......................................
2025-04-22 20:01:50,741:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:50,741:INFO:Creating metrics dataframe
2025-04-22 20:01:50,750:INFO:Initializing Dummy Classifier
2025-04-22 20:01:50,750:INFO:Total runtime is 0.3412658015886943 minutes
2025-04-22 20:01:50,753:INFO:SubProcess create_model() called ==================================
2025-04-22 20:01:50,753:INFO:Initializing create_model()
2025-04-22 20:01:50,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FE56A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:50,753:INFO:Checking exceptions
2025-04-22 20:01:50,753:INFO:Importing libraries
2025-04-22 20:01:50,753:INFO:Copying training dataset
2025-04-22 20:01:50,770:INFO:Defining folds
2025-04-22 20:01:50,771:INFO:Declaring metric variables
2025-04-22 20:01:50,774:INFO:Importing untrained model
2025-04-22 20:01:50,777:INFO:Dummy Classifier Imported successfully
2025-04-22 20:01:50,781:INFO:Starting cross validation
2025-04-22 20:01:50,782:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:01:50,926:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:01:50,932:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:01:50,939:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:01:50,939:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:01:50,951:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:01:50,960:INFO:Calculating mean and std
2025-04-22 20:01:50,962:INFO:Creating metrics dataframe
2025-04-22 20:01:50,964:INFO:Uploading results into container
2025-04-22 20:01:50,964:INFO:Uploading model into container now
2025-04-22 20:01:50,964:INFO:_master_model_container: 14
2025-04-22 20:01:50,964:INFO:_display_container: 2
2025-04-22 20:01:50,965:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 20:01:50,965:INFO:create_model() successfully completed......................................
2025-04-22 20:01:51,118:INFO:SubProcess create_model() end ==================================
2025-04-22 20:01:51,118:INFO:Creating metrics dataframe
2025-04-22 20:01:51,126:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 20:01:51,133:INFO:Initializing create_model()
2025-04-22 20:01:51,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21F90A510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:01:51,133:INFO:Checking exceptions
2025-04-22 20:01:51,135:INFO:Importing libraries
2025-04-22 20:01:51,135:INFO:Copying training dataset
2025-04-22 20:01:51,150:INFO:Defining folds
2025-04-22 20:01:51,150:INFO:Declaring metric variables
2025-04-22 20:01:51,150:INFO:Importing untrained model
2025-04-22 20:01:51,150:INFO:Declaring custom model
2025-04-22 20:01:51,151:INFO:Naive Bayes Imported successfully
2025-04-22 20:01:51,152:INFO:Cross validation set to False
2025-04-22 20:01:51,152:INFO:Fitting Model
2025-04-22 20:01:51,247:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:01:51,247:INFO:create_model() successfully completed......................................
2025-04-22 20:01:51,417:INFO:_master_model_container: 14
2025-04-22 20:01:51,417:INFO:_display_container: 2
2025-04-22 20:01:51,417:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:01:51,418:INFO:compare_models() successfully completed......................................
2025-04-22 20:02:23,740:INFO:PyCaret ClassificationExperiment
2025-04-22 20:02:23,740:INFO:Logging name: baseline_after_selection
2025-04-22 20:02:23,741:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-22 20:02:23,741:INFO:version 3.3.2
2025-04-22 20:02:23,741:INFO:Initializing setup()
2025-04-22 20:02:23,741:INFO:self.USI: 8e50
2025-04-22 20:02:23,741:INFO:self._variable_keys: {'fold_generator', 'y', 'target_param', '_ml_usecase', '_available_plots', 'X_test', 'idx', 'exp_name_log', 'X_train', 'USI', 'logging_param', 'seed', 'html_param', 'gpu_param', 'log_plots_param', 'gpu_n_jobs_param', 'data', 'exp_id', 'y_test', 'y_train', 'X', 'memory', 'n_jobs_param', 'fix_imbalance', 'fold_groups_param', 'pipeline', 'fold_shuffle_param', 'is_multiclass'}
2025-04-22 20:02:23,741:INFO:Checking environment
2025-04-22 20:02:23,741:INFO:python_version: 3.11.4
2025-04-22 20:02:23,741:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-22 20:02:23,741:INFO:machine: AMD64
2025-04-22 20:02:23,741:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-22 20:02:23,752:INFO:Memory: svmem(total=16498810880, available=2707333120, percent=83.6, used=13791477760, free=2707333120)
2025-04-22 20:02:23,752:INFO:Physical Core: 8
2025-04-22 20:02:23,752:INFO:Logical Core: 16
2025-04-22 20:02:23,752:INFO:Checking libraries
2025-04-22 20:02:23,752:INFO:System:
2025-04-22 20:02:23,752:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-22 20:02:23,753:INFO:executable: c:\Python311\python.exe
2025-04-22 20:02:23,753:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-22 20:02:23,753:INFO:PyCaret required dependencies:
2025-04-22 20:02:23,753:INFO:                 pip: 23.1.2
2025-04-22 20:02:23,753:INFO:          setuptools: 65.5.0
2025-04-22 20:02:23,753:INFO:             pycaret: 3.3.2
2025-04-22 20:02:23,753:INFO:             IPython: 8.20.0
2025-04-22 20:02:23,753:INFO:          ipywidgets: 8.1.6
2025-04-22 20:02:23,753:INFO:                tqdm: 4.66.2
2025-04-22 20:02:23,753:INFO:               numpy: 1.26.2
2025-04-22 20:02:23,753:INFO:              pandas: 2.1.4
2025-04-22 20:02:23,753:INFO:              jinja2: 3.1.2
2025-04-22 20:02:23,753:INFO:               scipy: 1.11.4
2025-04-22 20:02:23,753:INFO:              joblib: 1.3.2
2025-04-22 20:02:23,753:INFO:             sklearn: 1.4.2
2025-04-22 20:02:23,753:INFO:                pyod: 2.0.4
2025-04-22 20:02:23,753:INFO:            imblearn: 0.12.0
2025-04-22 20:02:23,753:INFO:   category_encoders: 2.7.0
2025-04-22 20:02:23,753:INFO:            lightgbm: 4.6.0
2025-04-22 20:02:23,753:INFO:               numba: 0.61.2
2025-04-22 20:02:23,753:INFO:            requests: 2.31.0
2025-04-22 20:02:23,753:INFO:          matplotlib: 3.7.5
2025-04-22 20:02:23,753:INFO:          scikitplot: 0.3.7
2025-04-22 20:02:23,753:INFO:         yellowbrick: 1.5
2025-04-22 20:02:23,753:INFO:              plotly: 5.24.1
2025-04-22 20:02:23,753:INFO:    plotly-resampler: Not installed
2025-04-22 20:02:23,753:INFO:             kaleido: 0.2.1
2025-04-22 20:02:23,753:INFO:           schemdraw: 0.15
2025-04-22 20:02:23,753:INFO:         statsmodels: 0.14.4
2025-04-22 20:02:23,753:INFO:              sktime: 0.26.0
2025-04-22 20:02:23,754:INFO:               tbats: 1.1.3
2025-04-22 20:02:23,754:INFO:            pmdarima: 2.0.4
2025-04-22 20:02:23,754:INFO:              psutil: 5.9.8
2025-04-22 20:02:23,754:INFO:          markupsafe: 2.1.3
2025-04-22 20:02:23,754:INFO:             pickle5: Not installed
2025-04-22 20:02:23,754:INFO:         cloudpickle: 3.1.1
2025-04-22 20:02:23,754:INFO:         deprecation: 2.1.0
2025-04-22 20:02:23,754:INFO:              xxhash: 3.5.0
2025-04-22 20:02:23,754:INFO:           wurlitzer: Not installed
2025-04-22 20:02:23,754:INFO:PyCaret optional dependencies:
2025-04-22 20:02:23,754:INFO:                shap: Not installed
2025-04-22 20:02:23,754:INFO:           interpret: Not installed
2025-04-22 20:02:23,754:INFO:                umap: Not installed
2025-04-22 20:02:23,754:INFO:     ydata_profiling: Not installed
2025-04-22 20:02:23,754:INFO:  explainerdashboard: Not installed
2025-04-22 20:02:23,754:INFO:             autoviz: Not installed
2025-04-22 20:02:23,754:INFO:           fairlearn: Not installed
2025-04-22 20:02:23,754:INFO:          deepchecks: Not installed
2025-04-22 20:02:23,754:INFO:             xgboost: Not installed
2025-04-22 20:02:23,754:INFO:            catboost: Not installed
2025-04-22 20:02:23,754:INFO:              kmodes: Not installed
2025-04-22 20:02:23,754:INFO:             mlxtend: 0.23.4
2025-04-22 20:02:23,754:INFO:       statsforecast: Not installed
2025-04-22 20:02:23,754:INFO:        tune_sklearn: Not installed
2025-04-22 20:02:23,754:INFO:                 ray: Not installed
2025-04-22 20:02:23,754:INFO:            hyperopt: Not installed
2025-04-22 20:02:23,754:INFO:              optuna: Not installed
2025-04-22 20:02:23,754:INFO:               skopt: Not installed
2025-04-22 20:02:23,754:INFO:              mlflow: Not installed
2025-04-22 20:02:23,754:INFO:              gradio: Not installed
2025-04-22 20:02:23,754:INFO:             fastapi: Not installed
2025-04-22 20:02:23,754:INFO:             uvicorn: Not installed
2025-04-22 20:02:23,754:INFO:              m2cgen: Not installed
2025-04-22 20:02:23,754:INFO:           evidently: Not installed
2025-04-22 20:02:23,754:INFO:               fugue: Not installed
2025-04-22 20:02:23,754:INFO:           streamlit: Not installed
2025-04-22 20:02:23,754:INFO:             prophet: Not installed
2025-04-22 20:02:23,755:INFO:None
2025-04-22 20:02:23,755:INFO:Set up data.
2025-04-22 20:02:23,759:INFO:Set up folding strategy.
2025-04-22 20:02:23,759:INFO:Set up train/test split.
2025-04-22 20:02:23,769:INFO:Set up index.
2025-04-22 20:02:23,770:INFO:Assigning column types.
2025-04-22 20:02:23,773:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 20:02:23,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:02:23,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:02:23,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:23,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:23,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 20:02:23,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:02:23,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:23,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:23,903:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 20:02:23,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:02:23,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:23,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,001:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-22 20:02:24,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,024:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-22 20:02:24,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,146:INFO:Preparing preprocessing pipeline...
2025-04-22 20:02:24,147:INFO:Set up simple imputation.
2025-04-22 20:02:24,147:INFO:Set up imbalanced handling.
2025-04-22 20:02:24,147:INFO:Set up feature normalization.
2025-04-22 20:02:24,187:INFO:Finished creating preprocessing pipeline.
2025-04-22 20:02:24,192:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sept_Pay_status',
                                             'May_Pay_status',
                                             'momentum_stability_flag',
                                             'low_repayment_months_log'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_value...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTETomek(n_jobs=None,
                                                                                   random_state=42,
                                                                                   sampling_strategy='auto',
                                                                                   smote=None,
                                                                                   tomek=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2025-04-22 20:02:24,192:INFO:Creating final display dataframe.
2025-04-22 20:02:24,267:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                  (29163, 5)
4        Transformed data shape                  (40455, 5)
5   Transformed train set shape                  (31706, 5)
6    Transformed test set shape                   (8749, 5)
7              Numeric features                           4
8                    Preprocess                        True
9               Imputation type                      simple
10           Numeric imputation                        mean
11       Categorical imputation                        mode
12                Fix imbalance                        True
13         Fix imbalance method                  smotetomek
14                    Normalize                        True
15             Normalize method                      robust
16               Fold Generator             StratifiedKFold
17                  Fold Number                           5
18                     CPU Jobs                          -1
19                      Use GPU                       False
20               Log Experiment                       False
21              Experiment Name    baseline_after_selection
22                          USI                        8e50
2025-04-22 20:02:24,333:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 20:02:24,394:INFO:setup() successfully completed in 0.67s...............
2025-04-22 20:02:24,411:INFO:Initializing compare_models()
2025-04-22 20:02:24,411:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-22 20:02:24,411:INFO:Checking exceptions
2025-04-22 20:02:24,415:INFO:Preparing display monitor
2025-04-22 20:02:24,431:INFO:Initializing Logistic Regression
2025-04-22 20:02:24,431:INFO:Total runtime is 0.0 minutes
2025-04-22 20:02:24,434:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:24,434:INFO:Initializing create_model()
2025-04-22 20:02:24,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:24,434:INFO:Checking exceptions
2025-04-22 20:02:24,434:INFO:Importing libraries
2025-04-22 20:02:24,434:INFO:Copying training dataset
2025-04-22 20:02:24,441:INFO:Defining folds
2025-04-22 20:02:24,441:INFO:Declaring metric variables
2025-04-22 20:02:24,445:INFO:Importing untrained model
2025-04-22 20:02:24,447:INFO:Logistic Regression Imported successfully
2025-04-22 20:02:24,454:INFO:Starting cross validation
2025-04-22 20:02:24,455:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:25,556:INFO:Calculating mean and std
2025-04-22 20:02:25,557:INFO:Creating metrics dataframe
2025-04-22 20:02:25,559:INFO:Uploading results into container
2025-04-22 20:02:25,562:INFO:Uploading model into container now
2025-04-22 20:02:25,562:INFO:_master_model_container: 1
2025-04-22 20:02:25,562:INFO:_display_container: 2
2025-04-22 20:02:25,563:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:02:25,563:INFO:create_model() successfully completed......................................
2025-04-22 20:02:25,831:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:25,831:INFO:Creating metrics dataframe
2025-04-22 20:02:25,836:INFO:Initializing K Neighbors Classifier
2025-04-22 20:02:25,836:INFO:Total runtime is 0.02341616153717041 minutes
2025-04-22 20:02:25,839:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:25,839:INFO:Initializing create_model()
2025-04-22 20:02:25,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:25,840:INFO:Checking exceptions
2025-04-22 20:02:25,840:INFO:Importing libraries
2025-04-22 20:02:25,840:INFO:Copying training dataset
2025-04-22 20:02:25,846:INFO:Defining folds
2025-04-22 20:02:25,846:INFO:Declaring metric variables
2025-04-22 20:02:25,849:INFO:Importing untrained model
2025-04-22 20:02:25,852:INFO:K Neighbors Classifier Imported successfully
2025-04-22 20:02:25,859:INFO:Starting cross validation
2025-04-22 20:02:25,859:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:27,749:INFO:Calculating mean and std
2025-04-22 20:02:27,750:INFO:Creating metrics dataframe
2025-04-22 20:02:27,751:INFO:Uploading results into container
2025-04-22 20:02:27,752:INFO:Uploading model into container now
2025-04-22 20:02:27,752:INFO:_master_model_container: 2
2025-04-22 20:02:27,752:INFO:_display_container: 2
2025-04-22 20:02:27,752:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-22 20:02:27,752:INFO:create_model() successfully completed......................................
2025-04-22 20:02:27,904:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:27,904:INFO:Creating metrics dataframe
2025-04-22 20:02:27,909:INFO:Initializing Naive Bayes
2025-04-22 20:02:27,909:INFO:Total runtime is 0.05795530080795288 minutes
2025-04-22 20:02:27,911:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:27,911:INFO:Initializing create_model()
2025-04-22 20:02:27,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:27,912:INFO:Checking exceptions
2025-04-22 20:02:27,912:INFO:Importing libraries
2025-04-22 20:02:27,912:INFO:Copying training dataset
2025-04-22 20:02:27,919:INFO:Defining folds
2025-04-22 20:02:27,919:INFO:Declaring metric variables
2025-04-22 20:02:27,922:INFO:Importing untrained model
2025-04-22 20:02:27,925:INFO:Naive Bayes Imported successfully
2025-04-22 20:02:27,931:INFO:Starting cross validation
2025-04-22 20:02:27,932:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:29,012:INFO:Calculating mean and std
2025-04-22 20:02:29,013:INFO:Creating metrics dataframe
2025-04-22 20:02:29,015:INFO:Uploading results into container
2025-04-22 20:02:29,015:INFO:Uploading model into container now
2025-04-22 20:02:29,015:INFO:_master_model_container: 3
2025-04-22 20:02:29,016:INFO:_display_container: 2
2025-04-22 20:02:29,016:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-22 20:02:29,017:INFO:create_model() successfully completed......................................
2025-04-22 20:02:29,200:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:29,200:INFO:Creating metrics dataframe
2025-04-22 20:02:29,207:INFO:Initializing Decision Tree Classifier
2025-04-22 20:02:29,207:INFO:Total runtime is 0.07959637641906739 minutes
2025-04-22 20:02:29,209:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:29,210:INFO:Initializing create_model()
2025-04-22 20:02:29,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:29,210:INFO:Checking exceptions
2025-04-22 20:02:29,210:INFO:Importing libraries
2025-04-22 20:02:29,210:INFO:Copying training dataset
2025-04-22 20:02:29,217:INFO:Defining folds
2025-04-22 20:02:29,217:INFO:Declaring metric variables
2025-04-22 20:02:29,219:INFO:Importing untrained model
2025-04-22 20:02:29,223:INFO:Decision Tree Classifier Imported successfully
2025-04-22 20:02:29,228:INFO:Starting cross validation
2025-04-22 20:02:29,229:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:30,404:INFO:Calculating mean and std
2025-04-22 20:02:30,406:INFO:Creating metrics dataframe
2025-04-22 20:02:30,407:INFO:Uploading results into container
2025-04-22 20:02:30,407:INFO:Uploading model into container now
2025-04-22 20:02:30,408:INFO:_master_model_container: 4
2025-04-22 20:02:30,408:INFO:_display_container: 2
2025-04-22 20:02:30,408:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-22 20:02:30,408:INFO:create_model() successfully completed......................................
2025-04-22 20:02:30,561:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:30,561:INFO:Creating metrics dataframe
2025-04-22 20:02:30,567:INFO:Initializing SVM - Linear Kernel
2025-04-22 20:02:30,567:INFO:Total runtime is 0.10225496689478557 minutes
2025-04-22 20:02:30,569:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:30,570:INFO:Initializing create_model()
2025-04-22 20:02:30,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:30,570:INFO:Checking exceptions
2025-04-22 20:02:30,570:INFO:Importing libraries
2025-04-22 20:02:30,570:INFO:Copying training dataset
2025-04-22 20:02:30,576:INFO:Defining folds
2025-04-22 20:02:30,576:INFO:Declaring metric variables
2025-04-22 20:02:30,578:INFO:Importing untrained model
2025-04-22 20:02:30,583:INFO:SVM - Linear Kernel Imported successfully
2025-04-22 20:02:30,591:INFO:Starting cross validation
2025-04-22 20:02:30,591:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:31,765:INFO:Calculating mean and std
2025-04-22 20:02:31,766:INFO:Creating metrics dataframe
2025-04-22 20:02:31,769:INFO:Uploading results into container
2025-04-22 20:02:31,769:INFO:Uploading model into container now
2025-04-22 20:02:31,770:INFO:_master_model_container: 5
2025-04-22 20:02:31,770:INFO:_display_container: 2
2025-04-22 20:02:31,770:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-22 20:02:31,770:INFO:create_model() successfully completed......................................
2025-04-22 20:02:31,940:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:31,940:INFO:Creating metrics dataframe
2025-04-22 20:02:31,946:INFO:Initializing Ridge Classifier
2025-04-22 20:02:31,946:INFO:Total runtime is 0.1252495805422465 minutes
2025-04-22 20:02:31,950:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:31,950:INFO:Initializing create_model()
2025-04-22 20:02:31,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:31,950:INFO:Checking exceptions
2025-04-22 20:02:31,950:INFO:Importing libraries
2025-04-22 20:02:31,951:INFO:Copying training dataset
2025-04-22 20:02:31,960:INFO:Defining folds
2025-04-22 20:02:31,960:INFO:Declaring metric variables
2025-04-22 20:02:31,964:INFO:Importing untrained model
2025-04-22 20:02:31,972:INFO:Ridge Classifier Imported successfully
2025-04-22 20:02:31,981:INFO:Starting cross validation
2025-04-22 20:02:31,983:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:33,668:INFO:Calculating mean and std
2025-04-22 20:02:33,669:INFO:Creating metrics dataframe
2025-04-22 20:02:33,671:INFO:Uploading results into container
2025-04-22 20:02:33,672:INFO:Uploading model into container now
2025-04-22 20:02:33,672:INFO:_master_model_container: 6
2025-04-22 20:02:33,672:INFO:_display_container: 2
2025-04-22 20:02:33,673:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-22 20:02:33,673:INFO:create_model() successfully completed......................................
2025-04-22 20:02:33,841:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:33,841:INFO:Creating metrics dataframe
2025-04-22 20:02:33,848:INFO:Initializing Random Forest Classifier
2025-04-22 20:02:33,848:INFO:Total runtime is 0.15694886843363443 minutes
2025-04-22 20:02:33,850:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:33,850:INFO:Initializing create_model()
2025-04-22 20:02:33,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:33,850:INFO:Checking exceptions
2025-04-22 20:02:33,850:INFO:Importing libraries
2025-04-22 20:02:33,851:INFO:Copying training dataset
2025-04-22 20:02:33,857:INFO:Defining folds
2025-04-22 20:02:33,858:INFO:Declaring metric variables
2025-04-22 20:02:33,861:INFO:Importing untrained model
2025-04-22 20:02:33,865:INFO:Random Forest Classifier Imported successfully
2025-04-22 20:02:33,871:INFO:Starting cross validation
2025-04-22 20:02:33,872:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:35,689:INFO:Calculating mean and std
2025-04-22 20:02:35,690:INFO:Creating metrics dataframe
2025-04-22 20:02:35,691:INFO:Uploading results into container
2025-04-22 20:02:35,692:INFO:Uploading model into container now
2025-04-22 20:02:35,693:INFO:_master_model_container: 7
2025-04-22 20:02:35,693:INFO:_display_container: 2
2025-04-22 20:02:35,693:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-22 20:02:35,693:INFO:create_model() successfully completed......................................
2025-04-22 20:02:35,859:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:35,859:INFO:Creating metrics dataframe
2025-04-22 20:02:35,866:INFO:Initializing Quadratic Discriminant Analysis
2025-04-22 20:02:35,866:INFO:Total runtime is 0.19058071772257484 minutes
2025-04-22 20:02:35,869:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:35,870:INFO:Initializing create_model()
2025-04-22 20:02:35,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:35,870:INFO:Checking exceptions
2025-04-22 20:02:35,870:INFO:Importing libraries
2025-04-22 20:02:35,870:INFO:Copying training dataset
2025-04-22 20:02:35,880:INFO:Defining folds
2025-04-22 20:02:35,880:INFO:Declaring metric variables
2025-04-22 20:02:35,884:INFO:Importing untrained model
2025-04-22 20:02:35,887:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-22 20:02:35,896:INFO:Starting cross validation
2025-04-22 20:02:35,897:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:37,433:INFO:Calculating mean and std
2025-04-22 20:02:37,434:INFO:Creating metrics dataframe
2025-04-22 20:02:37,436:INFO:Uploading results into container
2025-04-22 20:02:37,437:INFO:Uploading model into container now
2025-04-22 20:02:37,437:INFO:_master_model_container: 8
2025-04-22 20:02:37,437:INFO:_display_container: 2
2025-04-22 20:02:37,438:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-22 20:02:37,438:INFO:create_model() successfully completed......................................
2025-04-22 20:02:37,623:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:37,623:INFO:Creating metrics dataframe
2025-04-22 20:02:37,631:INFO:Initializing Ada Boost Classifier
2025-04-22 20:02:37,631:INFO:Total runtime is 0.2199977397918701 minutes
2025-04-22 20:02:37,635:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:37,635:INFO:Initializing create_model()
2025-04-22 20:02:37,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:37,636:INFO:Checking exceptions
2025-04-22 20:02:37,636:INFO:Importing libraries
2025-04-22 20:02:37,636:INFO:Copying training dataset
2025-04-22 20:02:37,646:INFO:Defining folds
2025-04-22 20:02:37,646:INFO:Declaring metric variables
2025-04-22 20:02:37,651:INFO:Importing untrained model
2025-04-22 20:02:37,655:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:02:37,664:INFO:Starting cross validation
2025-04-22 20:02:37,665:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:39,112:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:02:39,127:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:02:39,128:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:02:39,153:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:02:39,193:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:02:39,744:INFO:Calculating mean and std
2025-04-22 20:02:39,746:INFO:Creating metrics dataframe
2025-04-22 20:02:39,748:INFO:Uploading results into container
2025-04-22 20:02:39,749:INFO:Uploading model into container now
2025-04-22 20:02:39,750:INFO:_master_model_container: 9
2025-04-22 20:02:39,750:INFO:_display_container: 2
2025-04-22 20:02:39,751:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 20:02:39,751:INFO:create_model() successfully completed......................................
2025-04-22 20:02:39,927:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:39,927:INFO:Creating metrics dataframe
2025-04-22 20:02:39,933:INFO:Initializing Gradient Boosting Classifier
2025-04-22 20:02:39,933:INFO:Total runtime is 0.2583610693613688 minutes
2025-04-22 20:02:39,938:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:39,938:INFO:Initializing create_model()
2025-04-22 20:02:39,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:39,938:INFO:Checking exceptions
2025-04-22 20:02:39,938:INFO:Importing libraries
2025-04-22 20:02:39,938:INFO:Copying training dataset
2025-04-22 20:02:39,949:INFO:Defining folds
2025-04-22 20:02:39,949:INFO:Declaring metric variables
2025-04-22 20:02:39,954:INFO:Importing untrained model
2025-04-22 20:02:39,957:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:02:39,964:INFO:Starting cross validation
2025-04-22 20:02:39,965:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:42,280:INFO:Calculating mean and std
2025-04-22 20:02:42,280:INFO:Creating metrics dataframe
2025-04-22 20:02:42,283:INFO:Uploading results into container
2025-04-22 20:02:42,283:INFO:Uploading model into container now
2025-04-22 20:02:42,284:INFO:_master_model_container: 10
2025-04-22 20:02:42,284:INFO:_display_container: 2
2025-04-22 20:02:42,284:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:02:42,284:INFO:create_model() successfully completed......................................
2025-04-22 20:02:42,447:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:42,447:INFO:Creating metrics dataframe
2025-04-22 20:02:42,456:INFO:Initializing Linear Discriminant Analysis
2025-04-22 20:02:42,456:INFO:Total runtime is 0.3004064321517944 minutes
2025-04-22 20:02:42,460:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:42,460:INFO:Initializing create_model()
2025-04-22 20:02:42,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:42,460:INFO:Checking exceptions
2025-04-22 20:02:42,460:INFO:Importing libraries
2025-04-22 20:02:42,460:INFO:Copying training dataset
2025-04-22 20:02:42,472:INFO:Defining folds
2025-04-22 20:02:42,472:INFO:Declaring metric variables
2025-04-22 20:02:42,476:INFO:Importing untrained model
2025-04-22 20:02:42,483:INFO:Linear Discriminant Analysis Imported successfully
2025-04-22 20:02:42,492:INFO:Starting cross validation
2025-04-22 20:02:42,493:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:43,985:INFO:Calculating mean and std
2025-04-22 20:02:43,986:INFO:Creating metrics dataframe
2025-04-22 20:02:43,988:INFO:Uploading results into container
2025-04-22 20:02:43,989:INFO:Uploading model into container now
2025-04-22 20:02:43,989:INFO:_master_model_container: 11
2025-04-22 20:02:43,989:INFO:_display_container: 2
2025-04-22 20:02:43,990:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-22 20:02:43,990:INFO:create_model() successfully completed......................................
2025-04-22 20:02:44,146:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:44,147:INFO:Creating metrics dataframe
2025-04-22 20:02:44,153:INFO:Initializing Extra Trees Classifier
2025-04-22 20:02:44,153:INFO:Total runtime is 0.3286951502164205 minutes
2025-04-22 20:02:44,156:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:44,156:INFO:Initializing create_model()
2025-04-22 20:02:44,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:44,156:INFO:Checking exceptions
2025-04-22 20:02:44,156:INFO:Importing libraries
2025-04-22 20:02:44,156:INFO:Copying training dataset
2025-04-22 20:02:44,162:INFO:Defining folds
2025-04-22 20:02:44,164:INFO:Declaring metric variables
2025-04-22 20:02:44,166:INFO:Importing untrained model
2025-04-22 20:02:44,171:INFO:Extra Trees Classifier Imported successfully
2025-04-22 20:02:44,177:INFO:Starting cross validation
2025-04-22 20:02:44,179:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:46,034:INFO:Calculating mean and std
2025-04-22 20:02:46,035:INFO:Creating metrics dataframe
2025-04-22 20:02:46,038:INFO:Uploading results into container
2025-04-22 20:02:46,038:INFO:Uploading model into container now
2025-04-22 20:02:46,039:INFO:_master_model_container: 12
2025-04-22 20:02:46,039:INFO:_display_container: 2
2025-04-22 20:02:46,040:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-22 20:02:46,040:INFO:create_model() successfully completed......................................
2025-04-22 20:02:46,233:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:46,233:INFO:Creating metrics dataframe
2025-04-22 20:02:46,241:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 20:02:46,241:INFO:Total runtime is 0.3634922941525777 minutes
2025-04-22 20:02:46,244:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:46,244:INFO:Initializing create_model()
2025-04-22 20:02:46,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:46,244:INFO:Checking exceptions
2025-04-22 20:02:46,244:INFO:Importing libraries
2025-04-22 20:02:46,244:INFO:Copying training dataset
2025-04-22 20:02:46,252:INFO:Defining folds
2025-04-22 20:02:46,252:INFO:Declaring metric variables
2025-04-22 20:02:46,256:INFO:Importing untrained model
2025-04-22 20:02:46,259:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:02:46,264:INFO:Starting cross validation
2025-04-22 20:02:46,265:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:48,106:INFO:Calculating mean and std
2025-04-22 20:02:48,107:INFO:Creating metrics dataframe
2025-04-22 20:02:48,109:INFO:Uploading results into container
2025-04-22 20:02:48,109:INFO:Uploading model into container now
2025-04-22 20:02:48,110:INFO:_master_model_container: 13
2025-04-22 20:02:48,110:INFO:_display_container: 2
2025-04-22 20:02:48,111:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:02:48,111:INFO:create_model() successfully completed......................................
2025-04-22 20:02:48,281:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:48,281:INFO:Creating metrics dataframe
2025-04-22 20:02:48,289:INFO:Initializing Dummy Classifier
2025-04-22 20:02:48,289:INFO:Total runtime is 0.3976256847381592 minutes
2025-04-22 20:02:48,292:INFO:SubProcess create_model() called ==================================
2025-04-22 20:02:48,292:INFO:Initializing create_model()
2025-04-22 20:02:48,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CD4FA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:48,292:INFO:Checking exceptions
2025-04-22 20:02:48,292:INFO:Importing libraries
2025-04-22 20:02:48,292:INFO:Copying training dataset
2025-04-22 20:02:48,299:INFO:Defining folds
2025-04-22 20:02:48,299:INFO:Declaring metric variables
2025-04-22 20:02:48,303:INFO:Importing untrained model
2025-04-22 20:02:48,306:INFO:Dummy Classifier Imported successfully
2025-04-22 20:02:48,312:INFO:Starting cross validation
2025-04-22 20:02:48,313:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:02:49,331:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:02:49,367:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:02:49,396:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:02:49,398:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:02:49,407:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:02:49,423:INFO:Calculating mean and std
2025-04-22 20:02:49,425:INFO:Creating metrics dataframe
2025-04-22 20:02:49,426:INFO:Uploading results into container
2025-04-22 20:02:49,426:INFO:Uploading model into container now
2025-04-22 20:02:49,427:INFO:_master_model_container: 14
2025-04-22 20:02:49,427:INFO:_display_container: 2
2025-04-22 20:02:49,427:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-22 20:02:49,427:INFO:create_model() successfully completed......................................
2025-04-22 20:02:49,598:INFO:SubProcess create_model() end ==================================
2025-04-22 20:02:49,598:INFO:Creating metrics dataframe
2025-04-22 20:02:49,606:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 20:02:49,613:INFO:Initializing create_model()
2025-04-22 20:02:49,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:02:49,614:INFO:Checking exceptions
2025-04-22 20:02:49,615:INFO:Importing libraries
2025-04-22 20:02:49,615:INFO:Copying training dataset
2025-04-22 20:02:49,620:INFO:Defining folds
2025-04-22 20:02:49,620:INFO:Declaring metric variables
2025-04-22 20:02:49,620:INFO:Importing untrained model
2025-04-22 20:02:49,620:INFO:Declaring custom model
2025-04-22 20:02:49,622:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:02:49,622:INFO:Cross validation set to False
2025-04-22 20:02:49,622:INFO:Fitting Model
2025-04-22 20:02:51,494:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:02:51,495:INFO:create_model() successfully completed......................................
2025-04-22 20:02:51,719:INFO:_master_model_container: 14
2025-04-22 20:02:51,719:INFO:_display_container: 2
2025-04-22 20:02:51,720:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:02:51,720:INFO:compare_models() successfully completed......................................
2025-04-22 20:05:17,709:INFO:Initializing create_model()
2025-04-22 20:05:17,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:05:17,709:INFO:Checking exceptions
2025-04-22 20:05:17,723:INFO:Importing libraries
2025-04-22 20:05:17,723:INFO:Copying training dataset
2025-04-22 20:05:17,734:INFO:Defining folds
2025-04-22 20:05:17,734:INFO:Declaring metric variables
2025-04-22 20:05:17,738:INFO:Importing untrained model
2025-04-22 20:05:17,741:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:05:17,748:INFO:Starting cross validation
2025-04-22 20:05:17,749:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:05:19,560:INFO:Calculating mean and std
2025-04-22 20:05:19,561:INFO:Creating metrics dataframe
2025-04-22 20:05:19,565:INFO:Finalizing model
2025-04-22 20:05:21,478:INFO:Uploading results into container
2025-04-22 20:05:21,479:INFO:Uploading model into container now
2025-04-22 20:05:21,484:INFO:_master_model_container: 15
2025-04-22 20:05:21,484:INFO:_display_container: 3
2025-04-22 20:05:21,486:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:05:21,486:INFO:create_model() successfully completed......................................
2025-04-22 20:05:21,652:INFO:Initializing predict_model()
2025-04-22 20:05:21,652:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D220DF8360>)
2025-04-22 20:05:21,652:INFO:Checking exceptions
2025-04-22 20:05:21,652:INFO:Preloading libraries
2025-04-22 20:05:56,058:INFO:Initializing tune_model()
2025-04-22 20:05:56,058:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 20:05:56,058:INFO:Checking exceptions
2025-04-22 20:05:56,073:INFO:Copying training dataset
2025-04-22 20:05:56,080:INFO:Checking base model
2025-04-22 20:05:56,080:INFO:Base model : Gradient Boosting Classifier
2025-04-22 20:05:56,083:INFO:Declaring metric variables
2025-04-22 20:05:56,086:INFO:Defining Hyperparameters
2025-04-22 20:05:56,250:INFO:Tuning with n_jobs=-1
2025-04-22 20:05:56,250:INFO:Initializing RandomizedSearchCV
2025-04-22 20:07:09,141:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.4}
2025-04-22 20:07:09,142:INFO:Hyperparameter search completed
2025-04-22 20:07:09,142:INFO:SubProcess create_model() called ==================================
2025-04-22 20:07:09,143:INFO:Initializing create_model()
2025-04-22 20:07:09,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D221E5FE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 130, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 1, 'learning_rate': 0.4})
2025-04-22 20:07:09,143:INFO:Checking exceptions
2025-04-22 20:07:09,143:INFO:Importing libraries
2025-04-22 20:07:09,143:INFO:Copying training dataset
2025-04-22 20:07:09,151:INFO:Defining folds
2025-04-22 20:07:09,151:INFO:Declaring metric variables
2025-04-22 20:07:09,154:INFO:Importing untrained model
2025-04-22 20:07:09,154:INFO:Declaring custom model
2025-04-22 20:07:09,157:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:07:09,161:INFO:Starting cross validation
2025-04-22 20:07:09,162:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:07:10,972:INFO:Calculating mean and std
2025-04-22 20:07:10,973:INFO:Creating metrics dataframe
2025-04-22 20:07:10,978:INFO:Finalizing model
2025-04-22 20:07:12,866:INFO:Uploading results into container
2025-04-22 20:07:12,867:INFO:Uploading model into container now
2025-04-22 20:07:12,867:INFO:_master_model_container: 16
2025-04-22 20:07:12,867:INFO:_display_container: 5
2025-04-22 20:07:12,868:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:07:12,868:INFO:create_model() successfully completed......................................
2025-04-22 20:07:13,026:INFO:SubProcess create_model() end ==================================
2025-04-22 20:07:13,026:INFO:choose_better activated
2025-04-22 20:07:13,028:INFO:SubProcess create_model() called ==================================
2025-04-22 20:07:13,029:INFO:Initializing create_model()
2025-04-22 20:07:13,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:07:13,029:INFO:Checking exceptions
2025-04-22 20:07:13,030:INFO:Importing libraries
2025-04-22 20:07:13,031:INFO:Copying training dataset
2025-04-22 20:07:13,036:INFO:Defining folds
2025-04-22 20:07:13,036:INFO:Declaring metric variables
2025-04-22 20:07:13,036:INFO:Importing untrained model
2025-04-22 20:07:13,036:INFO:Declaring custom model
2025-04-22 20:07:13,037:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:07:13,037:INFO:Starting cross validation
2025-04-22 20:07:13,037:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:07:14,819:INFO:Calculating mean and std
2025-04-22 20:07:14,821:INFO:Creating metrics dataframe
2025-04-22 20:07:14,822:INFO:Finalizing model
2025-04-22 20:07:16,720:INFO:Uploading results into container
2025-04-22 20:07:16,721:INFO:Uploading model into container now
2025-04-22 20:07:16,721:INFO:_master_model_container: 17
2025-04-22 20:07:16,721:INFO:_display_container: 6
2025-04-22 20:07:16,721:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:07:16,721:INFO:create_model() successfully completed......................................
2025-04-22 20:07:16,874:INFO:SubProcess create_model() end ==================================
2025-04-22 20:07:16,874:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5358
2025-04-22 20:07:16,875:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 20:07:16,875:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-04-22 20:07:16,875:INFO:choose_better completed
2025-04-22 20:07:16,882:INFO:_master_model_container: 17
2025-04-22 20:07:16,882:INFO:_display_container: 5
2025-04-22 20:07:16,883:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:07:16,883:INFO:tune_model() successfully completed......................................
2025-04-22 20:08:03,050:INFO:Initializing create_model()
2025-04-22 20:08:03,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.4, 'loss': 'log_loss', 'max_depth': 1, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 130, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.6, 'tol': 0.0001, 'validation_fraction': 0.1, 'warm_start': False})
2025-04-22 20:08:03,051:INFO:Checking exceptions
2025-04-22 20:08:03,064:INFO:Importing libraries
2025-04-22 20:08:03,064:INFO:Copying training dataset
2025-04-22 20:08:03,071:INFO:Defining folds
2025-04-22 20:08:03,071:INFO:Declaring metric variables
2025-04-22 20:08:03,075:INFO:Importing untrained model
2025-04-22 20:08:03,077:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 20:08:03,083:INFO:Starting cross validation
2025-04-22 20:08:03,083:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:08:04,851:INFO:Calculating mean and std
2025-04-22 20:08:04,852:INFO:Creating metrics dataframe
2025-04-22 20:08:04,857:INFO:Finalizing model
2025-04-22 20:08:06,712:INFO:Uploading results into container
2025-04-22 20:08:06,713:INFO:Uploading model into container now
2025-04-22 20:08:06,720:INFO:_master_model_container: 18
2025-04-22 20:08:06,720:INFO:_display_container: 6
2025-04-22 20:08:06,722:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 20:08:06,722:INFO:create_model() successfully completed......................................
2025-04-22 20:08:06,890:INFO:Initializing predict_model()
2025-04-22 20:08:06,890:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D220DF94E0>)
2025-04-22 20:08:06,890:INFO:Checking exceptions
2025-04-22 20:08:06,890:INFO:Preloading libraries
2025-04-22 20:12:25,364:INFO:Initializing plot_model()
2025-04-22 20:12:25,364:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:25,364:INFO:Checking exceptions
2025-04-22 20:12:25,371:INFO:Preloading libraries
2025-04-22 20:12:25,379:INFO:Copying training dataset
2025-04-22 20:12:25,379:INFO:Plot type: auc
2025-04-22 20:12:25,453:INFO:Fitting Model
2025-04-22 20:12:25,467:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 20:12:25,467:INFO:Scoring test/hold-out set
2025-04-22 20:12:25,628:INFO:Visual Rendered Successfully
2025-04-22 20:12:25,789:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:25,790:INFO:Initializing plot_model()
2025-04-22 20:12:25,790:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:25,790:INFO:Checking exceptions
2025-04-22 20:12:25,795:INFO:Preloading libraries
2025-04-22 20:12:25,801:INFO:Copying training dataset
2025-04-22 20:12:25,801:INFO:Plot type: confusion_matrix
2025-04-22 20:12:25,876:INFO:Fitting Model
2025-04-22 20:12:25,876:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 20:12:25,876:INFO:Scoring test/hold-out set
2025-04-22 20:12:25,968:INFO:Visual Rendered Successfully
2025-04-22 20:12:26,131:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:26,131:INFO:Initializing plot_model()
2025-04-22 20:12:26,131:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:26,131:INFO:Checking exceptions
2025-04-22 20:12:26,136:INFO:Preloading libraries
2025-04-22 20:12:26,143:INFO:Copying training dataset
2025-04-22 20:12:26,143:INFO:Plot type: pr
2025-04-22 20:12:26,220:INFO:Fitting Model
2025-04-22 20:12:26,221:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 20:12:26,221:INFO:Scoring test/hold-out set
2025-04-22 20:12:26,360:INFO:Visual Rendered Successfully
2025-04-22 20:12:26,518:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:26,519:INFO:Initializing plot_model()
2025-04-22 20:12:26,519:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:26,519:INFO:Checking exceptions
2025-04-22 20:12:26,523:INFO:Preloading libraries
2025-04-22 20:12:26,530:INFO:Copying training dataset
2025-04-22 20:12:26,530:INFO:Plot type: class_report
2025-04-22 20:12:26,602:INFO:Fitting Model
2025-04-22 20:12:26,602:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-04-22 20:12:26,603:INFO:Scoring test/hold-out set
2025-04-22 20:12:26,761:INFO:Visual Rendered Successfully
2025-04-22 20:12:26,920:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:26,920:INFO:Initializing plot_model()
2025-04-22 20:12:26,920:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:26,920:INFO:Checking exceptions
2025-04-22 20:12:26,925:INFO:Preloading libraries
2025-04-22 20:12:26,932:INFO:Copying training dataset
2025-04-22 20:12:26,932:INFO:Plot type: lift
2025-04-22 20:12:26,932:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:12:27,106:INFO:Visual Rendered Successfully
2025-04-22 20:12:27,258:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:27,259:INFO:Initializing plot_model()
2025-04-22 20:12:27,259:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:27,259:INFO:Checking exceptions
2025-04-22 20:12:27,264:INFO:Preloading libraries
2025-04-22 20:12:27,271:INFO:Copying training dataset
2025-04-22 20:12:27,271:INFO:Plot type: gain
2025-04-22 20:12:27,271:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:12:27,440:INFO:Visual Rendered Successfully
2025-04-22 20:12:27,597:INFO:plot_model() successfully completed......................................
2025-04-22 20:12:27,597:INFO:Initializing plot_model()
2025-04-22 20:12:27,597:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:12:27,597:INFO:Checking exceptions
2025-04-22 20:12:27,601:INFO:Preloading libraries
2025-04-22 20:12:27,608:INFO:Copying training dataset
2025-04-22 20:12:27,608:INFO:Plot type: feature
2025-04-22 20:12:27,609:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 20:12:27,717:INFO:Visual Rendered Successfully
2025-04-22 20:12:27,873:INFO:plot_model() successfully completed......................................
2025-04-22 20:13:16,408:INFO:Initializing create_model()
2025-04-22 20:13:16,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:13:16,408:INFO:Checking exceptions
2025-04-22 20:13:16,420:INFO:Importing libraries
2025-04-22 20:13:16,421:INFO:Copying training dataset
2025-04-22 20:13:16,428:INFO:Defining folds
2025-04-22 20:13:16,428:INFO:Declaring metric variables
2025-04-22 20:13:16,431:INFO:Importing untrained model
2025-04-22 20:13:16,434:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:13:16,440:INFO:Starting cross validation
2025-04-22 20:13:16,441:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:13:21,299:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:21,309:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:21,315:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:21,318:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:21,325:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:21,844:INFO:Calculating mean and std
2025-04-22 20:13:21,847:INFO:Creating metrics dataframe
2025-04-22 20:13:21,852:INFO:Finalizing model
2025-04-22 20:13:23,184:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:13:23,636:INFO:Uploading results into container
2025-04-22 20:13:23,637:INFO:Uploading model into container now
2025-04-22 20:13:23,644:INFO:_master_model_container: 19
2025-04-22 20:13:23,644:INFO:_display_container: 8
2025-04-22 20:13:23,645:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 20:13:23,645:INFO:create_model() successfully completed......................................
2025-04-22 20:13:23,805:INFO:Initializing predict_model()
2025-04-22 20:13:23,805:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21F9FA0C0>)
2025-04-22 20:13:23,805:INFO:Checking exceptions
2025-04-22 20:13:23,805:INFO:Preloading libraries
2025-04-22 20:13:29,296:INFO:Initializing tune_model()
2025-04-22 20:13:29,296:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 20:13:29,296:INFO:Checking exceptions
2025-04-22 20:13:29,309:INFO:Copying training dataset
2025-04-22 20:13:29,313:INFO:Checking base model
2025-04-22 20:13:29,315:INFO:Base model : Ada Boost Classifier
2025-04-22 20:13:29,318:INFO:Declaring metric variables
2025-04-22 20:13:29,321:INFO:Defining Hyperparameters
2025-04-22 20:13:29,487:INFO:Tuning with n_jobs=-1
2025-04-22 20:13:29,487:INFO:Initializing RandomizedSearchCV
2025-04-22 20:14:40,556:INFO:best_params: {'actual_estimator__n_estimators': 180, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__algorithm': 'SAMME'}
2025-04-22 20:14:40,557:INFO:Hyperparameter search completed
2025-04-22 20:14:40,557:INFO:SubProcess create_model() called ==================================
2025-04-22 20:14:40,558:INFO:Initializing create_model()
2025-04-22 20:14:40,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D221E5CB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 180, 'learning_rate': 0.1, 'algorithm': 'SAMME'})
2025-04-22 20:14:40,558:INFO:Checking exceptions
2025-04-22 20:14:40,558:INFO:Importing libraries
2025-04-22 20:14:40,558:INFO:Copying training dataset
2025-04-22 20:14:40,565:INFO:Defining folds
2025-04-22 20:14:40,566:INFO:Declaring metric variables
2025-04-22 20:14:40,568:INFO:Importing untrained model
2025-04-22 20:14:40,568:INFO:Declaring custom model
2025-04-22 20:14:40,571:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:14:40,576:INFO:Starting cross validation
2025-04-22 20:14:40,577:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:14:43,006:INFO:Calculating mean and std
2025-04-22 20:14:43,007:INFO:Creating metrics dataframe
2025-04-22 20:14:43,011:INFO:Finalizing model
2025-04-22 20:14:45,368:INFO:Uploading results into container
2025-04-22 20:14:45,369:INFO:Uploading model into container now
2025-04-22 20:14:45,370:INFO:_master_model_container: 20
2025-04-22 20:14:45,370:INFO:_display_container: 10
2025-04-22 20:14:45,370:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 20:14:45,370:INFO:create_model() successfully completed......................................
2025-04-22 20:14:45,540:INFO:SubProcess create_model() end ==================================
2025-04-22 20:14:45,540:INFO:choose_better activated
2025-04-22 20:14:45,544:INFO:SubProcess create_model() called ==================================
2025-04-22 20:14:45,544:INFO:Initializing create_model()
2025-04-22 20:14:45,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:14:45,544:INFO:Checking exceptions
2025-04-22 20:14:45,546:INFO:Importing libraries
2025-04-22 20:14:45,546:INFO:Copying training dataset
2025-04-22 20:14:45,553:INFO:Defining folds
2025-04-22 20:14:45,553:INFO:Declaring metric variables
2025-04-22 20:14:45,553:INFO:Importing untrained model
2025-04-22 20:14:45,553:INFO:Declaring custom model
2025-04-22 20:14:45,553:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:14:45,554:INFO:Starting cross validation
2025-04-22 20:14:45,554:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:14:46,705:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:46,729:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:46,729:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:46,756:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:46,775:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:47,278:INFO:Calculating mean and std
2025-04-22 20:14:47,278:INFO:Creating metrics dataframe
2025-04-22 20:14:47,280:INFO:Finalizing model
2025-04-22 20:14:48,627:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 20:14:49,075:INFO:Uploading results into container
2025-04-22 20:14:49,076:INFO:Uploading model into container now
2025-04-22 20:14:49,076:INFO:_master_model_container: 21
2025-04-22 20:14:49,076:INFO:_display_container: 11
2025-04-22 20:14:49,076:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-22 20:14:49,076:INFO:create_model() successfully completed......................................
2025-04-22 20:14:49,235:INFO:SubProcess create_model() end ==================================
2025-04-22 20:14:49,236:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42) result for F1 is 0.5352
2025-04-22 20:14:49,236:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 20:14:49,236:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) is best model
2025-04-22 20:14:49,236:INFO:choose_better completed
2025-04-22 20:14:49,243:INFO:_master_model_container: 21
2025-04-22 20:14:49,243:INFO:_display_container: 10
2025-04-22 20:14:49,243:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 20:14:49,244:INFO:tune_model() successfully completed......................................
2025-04-22 20:20:10,858:INFO:Initializing create_model()
2025-04-22 20:20:10,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'algorithm': 'SAMME', 'learning_rate': 0.2, 'n_estimators': 70, 'random_state': 42})
2025-04-22 20:20:10,858:INFO:Checking exceptions
2025-04-22 20:20:10,870:INFO:Importing libraries
2025-04-22 20:20:10,870:INFO:Copying training dataset
2025-04-22 20:20:10,880:INFO:Defining folds
2025-04-22 20:20:10,880:INFO:Declaring metric variables
2025-04-22 20:20:10,884:INFO:Importing untrained model
2025-04-22 20:20:10,888:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:20:10,895:INFO:Starting cross validation
2025-04-22 20:20:10,895:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:20:15,736:INFO:Calculating mean and std
2025-04-22 20:20:15,737:INFO:Creating metrics dataframe
2025-04-22 20:20:15,743:INFO:Finalizing model
2025-04-22 20:20:17,371:INFO:Uploading results into container
2025-04-22 20:20:17,371:INFO:Uploading model into container now
2025-04-22 20:20:17,378:INFO:_master_model_container: 22
2025-04-22 20:20:17,378:INFO:_display_container: 11
2025-04-22 20:20:17,378:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42)
2025-04-22 20:20:17,379:INFO:create_model() successfully completed......................................
2025-04-22 20:20:17,538:INFO:Initializing predict_model()
2025-04-22 20:20:17,538:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=70, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D220E17060>)
2025-04-22 20:20:17,538:INFO:Checking exceptions
2025-04-22 20:20:17,538:INFO:Preloading libraries
2025-04-22 20:20:43,092:INFO:Initializing create_model()
2025-04-22 20:20:43,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 180, 'random_state': 42})
2025-04-22 20:20:43,092:INFO:Checking exceptions
2025-04-22 20:20:43,105:INFO:Importing libraries
2025-04-22 20:20:43,105:INFO:Copying training dataset
2025-04-22 20:20:43,112:INFO:Defining folds
2025-04-22 20:20:43,112:INFO:Declaring metric variables
2025-04-22 20:20:43,115:INFO:Importing untrained model
2025-04-22 20:20:43,118:INFO:Ada Boost Classifier Imported successfully
2025-04-22 20:20:43,124:INFO:Starting cross validation
2025-04-22 20:20:43,125:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:20:47,714:INFO:Calculating mean and std
2025-04-22 20:20:47,716:INFO:Creating metrics dataframe
2025-04-22 20:20:47,721:INFO:Finalizing model
2025-04-22 20:20:49,839:INFO:Uploading results into container
2025-04-22 20:20:49,840:INFO:Uploading model into container now
2025-04-22 20:20:49,847:INFO:_master_model_container: 23
2025-04-22 20:20:49,847:INFO:_display_container: 13
2025-04-22 20:20:49,847:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 20:20:49,847:INFO:create_model() successfully completed......................................
2025-04-22 20:20:50,010:INFO:Initializing predict_model()
2025-04-22 20:20:50,010:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21F9FB4C0>)
2025-04-22 20:20:50,010:INFO:Checking exceptions
2025-04-22 20:20:50,010:INFO:Preloading libraries
2025-04-22 20:24:36,741:INFO:Initializing create_model()
2025-04-22 20:24:36,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:24:36,742:INFO:Checking exceptions
2025-04-22 20:24:36,753:INFO:Importing libraries
2025-04-22 20:24:36,754:INFO:Copying training dataset
2025-04-22 20:24:36,762:INFO:Defining folds
2025-04-22 20:24:36,762:INFO:Declaring metric variables
2025-04-22 20:24:36,764:INFO:Importing untrained model
2025-04-22 20:24:36,767:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:24:36,776:INFO:Starting cross validation
2025-04-22 20:24:36,776:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:24:40,805:INFO:Calculating mean and std
2025-04-22 20:24:40,807:INFO:Creating metrics dataframe
2025-04-22 20:24:40,813:INFO:Finalizing model
2025-04-22 20:24:42,139:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 20:24:42,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.
2025-04-22 20:24:42,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 20:24:42,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 20:24:42,141:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 20:24:42,141:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 20:24:42,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 20:24:42,213:INFO:Uploading results into container
2025-04-22 20:24:42,213:INFO:Uploading model into container now
2025-04-22 20:24:42,221:INFO:_master_model_container: 24
2025-04-22 20:24:42,221:INFO:_display_container: 15
2025-04-22 20:24:42,222:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:24:42,222:INFO:create_model() successfully completed......................................
2025-04-22 20:24:42,400:INFO:Initializing predict_model()
2025-04-22 20:24:42,401:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21F9F8AE0>)
2025-04-22 20:24:42,401:INFO:Checking exceptions
2025-04-22 20:24:42,401:INFO:Preloading libraries
2025-04-22 20:26:11,824:INFO:Initializing tune_model()
2025-04-22 20:26:11,824:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 20:26:11,824:INFO:Checking exceptions
2025-04-22 20:26:11,840:INFO:Copying training dataset
2025-04-22 20:26:11,847:INFO:Checking base model
2025-04-22 20:26:11,847:INFO:Base model : Light Gradient Boosting Machine
2025-04-22 20:26:11,851:INFO:Declaring metric variables
2025-04-22 20:26:11,853:INFO:Defining Hyperparameters
2025-04-22 20:26:12,037:INFO:Tuning with n_jobs=-1
2025-04-22 20:26:12,037:INFO:Initializing RandomizedSearchCV
2025-04-22 20:28:41,979:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 86, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2025-04-22 20:28:41,981:INFO:Hyperparameter search completed
2025-04-22 20:28:41,981:INFO:SubProcess create_model() called ==================================
2025-04-22 20:28:41,982:INFO:Initializing create_model()
2025-04-22 20:28:41,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21DC32390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.001, 'reg_alpha': 2, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.9, 'min_child_samples': 86, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2025-04-22 20:28:41,983:INFO:Checking exceptions
2025-04-22 20:28:41,983:INFO:Importing libraries
2025-04-22 20:28:41,983:INFO:Copying training dataset
2025-04-22 20:28:41,992:INFO:Defining folds
2025-04-22 20:28:41,993:INFO:Declaring metric variables
2025-04-22 20:28:41,998:INFO:Importing untrained model
2025-04-22 20:28:41,998:INFO:Declaring custom model
2025-04-22 20:28:42,003:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:28:42,010:INFO:Starting cross validation
2025-04-22 20:28:42,012:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:28:43,937:INFO:Calculating mean and std
2025-04-22 20:28:43,939:INFO:Creating metrics dataframe
2025-04-22 20:28:43,946:INFO:Finalizing model
2025-04-22 20:28:45,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:28:45,360:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:28:45,360:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:28:45,365:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:28:45,365:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:28:45,365:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:28:45,366:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 20:28:45,367:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.
2025-04-22 20:28:45,367:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 20:28:45,367:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 20:28:45,367:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 20:28:45,367:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 20:28:45,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 20:28:45,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,422:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 20:28:45,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:28:45,434:INFO:Uploading results into container
2025-04-22 20:28:45,435:INFO:Uploading model into container now
2025-04-22 20:28:45,435:INFO:_master_model_container: 25
2025-04-22 20:28:45,435:INFO:_display_container: 17
2025-04-22 20:28:45,436:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:28:45,437:INFO:create_model() successfully completed......................................
2025-04-22 20:28:45,626:INFO:SubProcess create_model() end ==================================
2025-04-22 20:28:45,626:INFO:choose_better activated
2025-04-22 20:28:45,629:INFO:SubProcess create_model() called ==================================
2025-04-22 20:28:45,630:INFO:Initializing create_model()
2025-04-22 20:28:45,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:28:45,630:INFO:Checking exceptions
2025-04-22 20:28:45,632:INFO:Importing libraries
2025-04-22 20:28:45,632:INFO:Copying training dataset
2025-04-22 20:28:45,637:INFO:Defining folds
2025-04-22 20:28:45,637:INFO:Declaring metric variables
2025-04-22 20:28:45,637:INFO:Importing untrained model
2025-04-22 20:28:45,637:INFO:Declaring custom model
2025-04-22 20:28:45,638:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:28:45,638:INFO:Starting cross validation
2025-04-22 20:28:45,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:28:47,430:INFO:Calculating mean and std
2025-04-22 20:28:47,431:INFO:Creating metrics dataframe
2025-04-22 20:28:47,433:INFO:Finalizing model
2025-04-22 20:28:48,817:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 20:28:48,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.
2025-04-22 20:28:48,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 20:28:48,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 20:28:48,819:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 20:28:48,819:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 20:28:48,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 20:28:48,887:INFO:Uploading results into container
2025-04-22 20:28:48,888:INFO:Uploading model into container now
2025-04-22 20:28:48,888:INFO:_master_model_container: 26
2025-04-22 20:28:48,888:INFO:_display_container: 18
2025-04-22 20:28:48,889:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:28:48,889:INFO:create_model() successfully completed......................................
2025-04-22 20:28:49,071:INFO:SubProcess create_model() end ==================================
2025-04-22 20:28:49,072:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5324
2025-04-22 20:28:49,073:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 20:28:49,073:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 20:28:49,073:INFO:choose_better completed
2025-04-22 20:28:49,079:INFO:_master_model_container: 26
2025-04-22 20:28:49,079:INFO:_display_container: 17
2025-04-22 20:28:49,080:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:28:49,080:INFO:tune_model() successfully completed......................................
2025-04-22 20:33:37,912:INFO:Initializing create_model()
2025-04-22 20:33:37,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.6, 'bagging_freq': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'feature_fraction': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 86, 'min_child_weight': 0.001, 'min_split_gain': 0.9, 'n_estimators': 130, 'n_jobs': -1, 'num_leaves': 40, 'objective': None, 'random_state': 42, 'reg_alpha': 2, 'reg_lambda': 0.001, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0})
2025-04-22 20:33:37,913:INFO:Checking exceptions
2025-04-22 20:33:37,924:INFO:Importing libraries
2025-04-22 20:33:37,924:INFO:Copying training dataset
2025-04-22 20:33:37,932:INFO:Defining folds
2025-04-22 20:33:37,932:INFO:Declaring metric variables
2025-04-22 20:33:37,937:INFO:Importing untrained model
2025-04-22 20:33:37,942:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 20:33:37,948:INFO:Starting cross validation
2025-04-22 20:33:37,949:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:33:39,348:INFO:Calculating mean and std
2025-04-22 20:33:39,350:INFO:Creating metrics dataframe
2025-04-22 20:33:39,354:INFO:Finalizing model
2025-04-22 20:33:40,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:33:40,652:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:33:40,652:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:33:40,656:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:33:40,656:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:33:40,656:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:33:40,656:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 20:33:40,658:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.
2025-04-22 20:33:40,658:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 20:33:40,658:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 20:33:40,658:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 20:33:40,658:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 20:33:40,658:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 20:33:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 20:33:40,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 20:33:40,743:INFO:Uploading results into container
2025-04-22 20:33:40,744:INFO:Uploading model into container now
2025-04-22 20:33:40,753:INFO:_master_model_container: 27
2025-04-22 20:33:40,753:INFO:_display_container: 18
2025-04-22 20:33:40,754:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 20:33:40,754:INFO:create_model() successfully completed......................................
2025-04-22 20:33:40,953:INFO:Initializing predict_model()
2025-04-22 20:33:40,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21F9FB060>)
2025-04-22 20:33:40,953:INFO:Checking exceptions
2025-04-22 20:33:40,953:INFO:Preloading libraries
2025-04-22 20:36:19,167:INFO:Initializing plot_model()
2025-04-22 20:36:19,167:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:19,167:INFO:Checking exceptions
2025-04-22 20:36:19,172:INFO:Preloading libraries
2025-04-22 20:36:19,176:INFO:Copying training dataset
2025-04-22 20:36:19,177:INFO:Plot type: auc
2025-04-22 20:36:19,287:INFO:Fitting Model
2025-04-22 20:36:19,288:INFO:Scoring test/hold-out set
2025-04-22 20:36:19,288:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:19,289:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:19,289:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:19,294:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:19,294:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:19,294:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:19,489:INFO:Visual Rendered Successfully
2025-04-22 20:36:19,670:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:19,671:INFO:Initializing plot_model()
2025-04-22 20:36:19,671:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:19,671:INFO:Checking exceptions
2025-04-22 20:36:19,675:INFO:Preloading libraries
2025-04-22 20:36:19,679:INFO:Copying training dataset
2025-04-22 20:36:19,679:INFO:Plot type: confusion_matrix
2025-04-22 20:36:19,791:INFO:Fitting Model
2025-04-22 20:36:19,793:INFO:Scoring test/hold-out set
2025-04-22 20:36:19,794:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:19,794:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:19,794:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:19,801:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:19,801:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:19,801:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:19,919:INFO:Visual Rendered Successfully
2025-04-22 20:36:20,096:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:20,097:INFO:Initializing plot_model()
2025-04-22 20:36:20,097:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:20,097:INFO:Checking exceptions
2025-04-22 20:36:20,102:INFO:Preloading libraries
2025-04-22 20:36:20,105:INFO:Copying training dataset
2025-04-22 20:36:20,105:INFO:Plot type: pr
2025-04-22 20:36:20,219:INFO:Fitting Model
2025-04-22 20:36:20,221:INFO:Scoring test/hold-out set
2025-04-22 20:36:20,222:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:20,222:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:20,222:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:20,229:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:20,229:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:20,229:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:20,403:INFO:Visual Rendered Successfully
2025-04-22 20:36:20,574:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:20,575:INFO:Initializing plot_model()
2025-04-22 20:36:20,575:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:20,575:INFO:Checking exceptions
2025-04-22 20:36:20,581:INFO:Preloading libraries
2025-04-22 20:36:20,585:INFO:Copying training dataset
2025-04-22 20:36:20,585:INFO:Plot type: class_report
2025-04-22 20:36:20,696:INFO:Fitting Model
2025-04-22 20:36:20,698:INFO:Scoring test/hold-out set
2025-04-22 20:36:20,699:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:20,699:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:20,699:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:20,705:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:20,705:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:20,705:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:20,903:INFO:Visual Rendered Successfully
2025-04-22 20:36:21,083:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:21,085:INFO:Initializing plot_model()
2025-04-22 20:36:21,085:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:21,085:INFO:Checking exceptions
2025-04-22 20:36:21,090:INFO:Preloading libraries
2025-04-22 20:36:21,093:INFO:Copying training dataset
2025-04-22 20:36:21,093:INFO:Plot type: lift
2025-04-22 20:36:21,093:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:36:21,140:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:21,140:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:21,140:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:21,288:INFO:Visual Rendered Successfully
2025-04-22 20:36:21,449:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:21,450:INFO:Initializing plot_model()
2025-04-22 20:36:21,450:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:21,450:INFO:Checking exceptions
2025-04-22 20:36:21,454:INFO:Preloading libraries
2025-04-22 20:36:21,458:INFO:Copying training dataset
2025-04-22 20:36:21,458:INFO:Plot type: gain
2025-04-22 20:36:21,458:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:36:21,504:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 20:36:21,504:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 20:36:21,504:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 20:36:21,658:INFO:Visual Rendered Successfully
2025-04-22 20:36:21,814:INFO:plot_model() successfully completed......................................
2025-04-22 20:36:21,814:INFO:Initializing plot_model()
2025-04-22 20:36:21,814:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:36:21,815:INFO:Checking exceptions
2025-04-22 20:36:21,818:INFO:Preloading libraries
2025-04-22 20:36:21,822:INFO:Copying training dataset
2025-04-22 20:36:21,822:INFO:Plot type: feature
2025-04-22 20:36:21,822:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 20:36:21,983:INFO:Visual Rendered Successfully
2025-04-22 20:36:22,139:INFO:plot_model() successfully completed......................................
2025-04-22 20:38:08,828:INFO:Initializing create_model()
2025-04-22 20:38:08,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:38:08,828:INFO:Checking exceptions
2025-04-22 20:38:08,841:INFO:Importing libraries
2025-04-22 20:38:08,842:INFO:Copying training dataset
2025-04-22 20:38:08,849:INFO:Defining folds
2025-04-22 20:38:08,849:INFO:Declaring metric variables
2025-04-22 20:38:08,852:INFO:Importing untrained model
2025-04-22 20:38:08,856:INFO:Logistic Regression Imported successfully
2025-04-22 20:38:08,862:INFO:Starting cross validation
2025-04-22 20:38:08,862:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:38:10,575:INFO:Calculating mean and std
2025-04-22 20:38:10,576:INFO:Creating metrics dataframe
2025-04-22 20:38:10,581:INFO:Finalizing model
2025-04-22 20:38:11,897:INFO:Uploading results into container
2025-04-22 20:38:11,897:INFO:Uploading model into container now
2025-04-22 20:38:11,906:INFO:_master_model_container: 28
2025-04-22 20:38:11,906:INFO:_display_container: 20
2025-04-22 20:38:11,907:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:38:11,907:INFO:create_model() successfully completed......................................
2025-04-22 20:38:12,085:INFO:Initializing predict_model()
2025-04-22 20:38:12,085:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21FA0F6A0>)
2025-04-22 20:38:12,085:INFO:Checking exceptions
2025-04-22 20:38:12,085:INFO:Preloading libraries
2025-04-22 20:38:20,427:INFO:Initializing create_model()
2025-04-22 20:38:20,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:38:20,428:INFO:Checking exceptions
2025-04-22 20:38:20,438:INFO:Importing libraries
2025-04-22 20:38:20,439:INFO:Copying training dataset
2025-04-22 20:38:20,450:INFO:Defining folds
2025-04-22 20:38:20,450:INFO:Declaring metric variables
2025-04-22 20:38:20,453:INFO:Importing untrained model
2025-04-22 20:38:20,456:INFO:Logistic Regression Imported successfully
2025-04-22 20:38:20,462:INFO:Starting cross validation
2025-04-22 20:38:20,463:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:38:24,209:INFO:Calculating mean and std
2025-04-22 20:38:24,211:INFO:Creating metrics dataframe
2025-04-22 20:38:24,215:INFO:Finalizing model
2025-04-22 20:38:25,573:INFO:Uploading results into container
2025-04-22 20:38:25,574:INFO:Uploading model into container now
2025-04-22 20:38:25,582:INFO:_master_model_container: 29
2025-04-22 20:38:25,582:INFO:_display_container: 22
2025-04-22 20:38:25,582:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:38:25,582:INFO:create_model() successfully completed......................................
2025-04-22 20:38:25,750:INFO:Initializing predict_model()
2025-04-22 20:38:25,750:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21FA0F6A0>)
2025-04-22 20:38:25,750:INFO:Checking exceptions
2025-04-22 20:38:25,750:INFO:Preloading libraries
2025-04-22 20:39:00,452:INFO:Initializing tune_model()
2025-04-22 20:39:00,452:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=50, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-04-22 20:39:00,452:INFO:Checking exceptions
2025-04-22 20:39:00,470:INFO:Copying training dataset
2025-04-22 20:39:00,475:INFO:Checking base model
2025-04-22 20:39:00,475:INFO:Base model : Logistic Regression
2025-04-22 20:39:00,479:INFO:Declaring metric variables
2025-04-22 20:39:00,483:INFO:Defining Hyperparameters
2025-04-22 20:39:00,683:INFO:Tuning with n_jobs=-1
2025-04-22 20:39:00,684:INFO:Initializing RandomizedSearchCV
2025-04-22 20:39:50,766:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.385}
2025-04-22 20:39:50,767:INFO:Hyperparameter search completed
2025-04-22 20:39:50,767:INFO:SubProcess create_model() called ==================================
2025-04-22 20:39:50,768:INFO:Initializing create_model()
2025-04-22 20:39:50,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21E5D41D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 0.385})
2025-04-22 20:39:50,768:INFO:Checking exceptions
2025-04-22 20:39:50,768:INFO:Importing libraries
2025-04-22 20:39:50,769:INFO:Copying training dataset
2025-04-22 20:39:50,779:INFO:Defining folds
2025-04-22 20:39:50,779:INFO:Declaring metric variables
2025-04-22 20:39:50,782:INFO:Importing untrained model
2025-04-22 20:39:50,782:INFO:Declaring custom model
2025-04-22 20:39:50,786:INFO:Logistic Regression Imported successfully
2025-04-22 20:39:50,794:INFO:Starting cross validation
2025-04-22 20:39:50,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:39:52,573:INFO:Calculating mean and std
2025-04-22 20:39:52,576:INFO:Creating metrics dataframe
2025-04-22 20:39:52,582:INFO:Finalizing model
2025-04-22 20:39:54,473:INFO:Uploading results into container
2025-04-22 20:39:54,474:INFO:Uploading model into container now
2025-04-22 20:39:54,476:INFO:_master_model_container: 30
2025-04-22 20:39:54,476:INFO:_display_container: 24
2025-04-22 20:39:54,476:INFO:LogisticRegression(C=0.385, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:39:54,476:INFO:create_model() successfully completed......................................
2025-04-22 20:39:54,690:INFO:SubProcess create_model() end ==================================
2025-04-22 20:39:54,690:INFO:choose_better activated
2025-04-22 20:39:54,694:INFO:SubProcess create_model() called ==================================
2025-04-22 20:39:54,695:INFO:Initializing create_model()
2025-04-22 20:39:54,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:39:54,696:INFO:Checking exceptions
2025-04-22 20:39:54,697:INFO:Importing libraries
2025-04-22 20:39:54,697:INFO:Copying training dataset
2025-04-22 20:39:54,706:INFO:Defining folds
2025-04-22 20:39:54,706:INFO:Declaring metric variables
2025-04-22 20:39:54,706:INFO:Importing untrained model
2025-04-22 20:39:54,706:INFO:Declaring custom model
2025-04-22 20:39:54,707:INFO:Logistic Regression Imported successfully
2025-04-22 20:39:54,707:INFO:Starting cross validation
2025-04-22 20:39:54,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:39:56,558:INFO:Calculating mean and std
2025-04-22 20:39:56,559:INFO:Creating metrics dataframe
2025-04-22 20:39:56,561:INFO:Finalizing model
2025-04-22 20:39:58,454:INFO:Uploading results into container
2025-04-22 20:39:58,455:INFO:Uploading model into container now
2025-04-22 20:39:58,455:INFO:_master_model_container: 31
2025-04-22 20:39:58,455:INFO:_display_container: 25
2025-04-22 20:39:58,455:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:39:58,455:INFO:create_model() successfully completed......................................
2025-04-22 20:39:58,660:INFO:SubProcess create_model() end ==================================
2025-04-22 20:39:58,661:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 20:39:58,661:INFO:LogisticRegression(C=0.385, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 20:39:58,662:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-04-22 20:39:58,662:INFO:choose_better completed
2025-04-22 20:39:58,662:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-22 20:39:58,671:INFO:_master_model_container: 31
2025-04-22 20:39:58,671:INFO:_display_container: 24
2025-04-22 20:39:58,671:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 20:39:58,671:INFO:tune_model() successfully completed......................................
2025-04-22 20:40:44,275:INFO:Initializing plot_model()
2025-04-22 20:40:44,275:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:44,275:INFO:Checking exceptions
2025-04-22 20:40:44,281:INFO:Preloading libraries
2025-04-22 20:40:44,281:INFO:Copying training dataset
2025-04-22 20:40:44,281:INFO:Plot type: auc
2025-04-22 20:40:44,368:INFO:Fitting Model
2025-04-22 20:40:44,369:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-04-22 20:40:44,369:INFO:Scoring test/hold-out set
2025-04-22 20:40:44,534:INFO:Visual Rendered Successfully
2025-04-22 20:40:44,721:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:44,721:INFO:Initializing plot_model()
2025-04-22 20:40:44,721:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:44,721:INFO:Checking exceptions
2025-04-22 20:40:44,726:INFO:Preloading libraries
2025-04-22 20:40:44,726:INFO:Copying training dataset
2025-04-22 20:40:44,726:INFO:Plot type: confusion_matrix
2025-04-22 20:40:44,816:INFO:Fitting Model
2025-04-22 20:40:44,816:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-04-22 20:40:44,816:INFO:Scoring test/hold-out set
2025-04-22 20:40:44,906:INFO:Visual Rendered Successfully
2025-04-22 20:40:45,062:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:45,062:INFO:Initializing plot_model()
2025-04-22 20:40:45,063:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:45,063:INFO:Checking exceptions
2025-04-22 20:40:45,068:INFO:Preloading libraries
2025-04-22 20:40:45,068:INFO:Copying training dataset
2025-04-22 20:40:45,068:INFO:Plot type: pr
2025-04-22 20:40:45,159:INFO:Fitting Model
2025-04-22 20:40:45,161:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-04-22 20:40:45,161:INFO:Scoring test/hold-out set
2025-04-22 20:40:45,294:INFO:Visual Rendered Successfully
2025-04-22 20:40:45,453:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:45,454:INFO:Initializing plot_model()
2025-04-22 20:40:45,454:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:45,454:INFO:Checking exceptions
2025-04-22 20:40:45,457:INFO:Preloading libraries
2025-04-22 20:40:45,458:INFO:Copying training dataset
2025-04-22 20:40:45,458:INFO:Plot type: class_report
2025-04-22 20:40:45,532:INFO:Fitting Model
2025-04-22 20:40:45,532:WARNING:c:\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-04-22 20:40:45,532:INFO:Scoring test/hold-out set
2025-04-22 20:40:45,691:INFO:Visual Rendered Successfully
2025-04-22 20:40:45,854:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:45,854:INFO:Initializing plot_model()
2025-04-22 20:40:45,854:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:45,855:INFO:Checking exceptions
2025-04-22 20:40:45,859:INFO:Preloading libraries
2025-04-22 20:40:45,859:INFO:Copying training dataset
2025-04-22 20:40:45,859:INFO:Plot type: lift
2025-04-22 20:40:45,859:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:40:46,027:INFO:Visual Rendered Successfully
2025-04-22 20:40:46,190:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:46,190:INFO:Initializing plot_model()
2025-04-22 20:40:46,190:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:46,190:INFO:Checking exceptions
2025-04-22 20:40:46,194:INFO:Preloading libraries
2025-04-22 20:40:46,195:INFO:Copying training dataset
2025-04-22 20:40:46,195:INFO:Plot type: gain
2025-04-22 20:40:46,195:INFO:Generating predictions / predict_proba on X_test
2025-04-22 20:40:46,354:INFO:Visual Rendered Successfully
2025-04-22 20:40:46,517:INFO:plot_model() successfully completed......................................
2025-04-22 20:40:46,517:INFO:Initializing plot_model()
2025-04-22 20:40:46,517:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:40:46,518:INFO:Checking exceptions
2025-04-22 20:40:46,522:INFO:Preloading libraries
2025-04-22 20:40:46,522:INFO:Copying training dataset
2025-04-22 20:40:46,522:INFO:Plot type: feature
2025-04-22 20:40:46,658:INFO:Visual Rendered Successfully
2025-04-22 20:40:46,821:INFO:plot_model() successfully completed......................................
2025-04-22 20:44:57,953:INFO:Initializing predict_model()
2025-04-22 20:44:57,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D21FA0F6A0>)
2025-04-22 20:44:57,953:INFO:Checking exceptions
2025-04-22 20:44:57,953:INFO:Preloading libraries
2025-04-22 20:47:34,741:INFO:Initializing plot_model()
2025-04-22 20:47:34,742:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibrate, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:47:34,742:INFO:Checking exceptions
2025-04-22 20:48:33,982:INFO:Initializing plot_model()
2025-04-22 20:48:33,982:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:48:33,982:INFO:Checking exceptions
2025-04-22 20:48:33,987:INFO:Preloading libraries
2025-04-22 20:48:33,987:INFO:Copying training dataset
2025-04-22 20:48:33,987:INFO:Plot type: calibration
2025-04-22 20:48:33,998:INFO:Scoring test/hold-out set
2025-04-22 20:48:34,149:INFO:Visual Rendered Successfully
2025-04-22 20:48:34,332:INFO:plot_model() successfully completed......................................
2025-04-22 20:49:10,025:INFO:Initializing predict_model()
2025-04-22 20:49:10,025:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D220BCF880>)
2025-04-22 20:49:10,025:INFO:Checking exceptions
2025-04-22 20:49:10,026:INFO:Preloading libraries
2025-04-22 20:50:07,597:INFO:Initializing plot_model()
2025-04-22 20:50:07,597:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:50:07,597:INFO:Checking exceptions
2025-04-22 20:50:07,603:INFO:Preloading libraries
2025-04-22 20:50:07,603:INFO:Copying training dataset
2025-04-22 20:50:07,603:INFO:Plot type: calibration
2025-04-22 20:50:07,613:INFO:Scoring test/hold-out set
2025-04-22 20:50:07,764:INFO:Visual Rendered Successfully
2025-04-22 20:50:07,947:INFO:plot_model() successfully completed......................................
2025-04-22 20:50:07,948:INFO:Initializing calibrate_model()
2025-04-22 20:50:07,948:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-04-22 20:50:07,948:INFO:Checking exceptions
2025-04-22 20:50:07,951:INFO:Preloading libraries
2025-04-22 20:50:07,951:INFO:Preparing display monitor
2025-04-22 20:50:07,962:INFO:Getting model name
2025-04-22 20:50:07,962:INFO:Base model : Logistic Regression
2025-04-22 20:50:07,968:INFO:Importing untrained CalibratedClassifierCV
2025-04-22 20:50:07,968:INFO:SubProcess create_model() called ==================================
2025-04-22 20:50:07,969:INFO:Initializing create_model()
2025-04-22 20:50:07,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='sigmoid', n_jobs=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21F74F450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:50:07,969:INFO:Checking exceptions
2025-04-22 20:50:07,969:INFO:Importing libraries
2025-04-22 20:50:07,969:INFO:Copying training dataset
2025-04-22 20:50:07,975:INFO:Defining folds
2025-04-22 20:50:07,975:INFO:Declaring metric variables
2025-04-22 20:50:07,976:INFO:Importing untrained model
2025-04-22 20:50:07,976:INFO:Declaring custom model
2025-04-22 20:50:07,982:INFO:Logistic Regression Imported successfully
2025-04-22 20:50:07,987:INFO:Starting cross validation
2025-04-22 20:50:07,988:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:50:12,471:INFO:Calculating mean and std
2025-04-22 20:50:12,473:INFO:Creating metrics dataframe
2025-04-22 20:50:12,478:INFO:Finalizing model
2025-04-22 20:50:27,332:INFO:Initializing plot_model()
2025-04-22 20:50:27,332:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:50:27,333:INFO:Checking exceptions
2025-04-22 20:50:27,337:INFO:Preloading libraries
2025-04-22 20:50:27,338:INFO:Copying training dataset
2025-04-22 20:50:27,338:INFO:Plot type: calibration
2025-04-22 20:50:27,350:INFO:Scoring test/hold-out set
2025-04-22 20:50:27,498:INFO:Visual Rendered Successfully
2025-04-22 20:50:27,736:INFO:plot_model() successfully completed......................................
2025-04-22 20:50:27,736:INFO:Initializing calibrate_model()
2025-04-22 20:50:27,736:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-04-22 20:50:27,736:INFO:Checking exceptions
2025-04-22 20:50:27,739:INFO:Preloading libraries
2025-04-22 20:50:27,739:INFO:Preparing display monitor
2025-04-22 20:50:27,749:INFO:Getting model name
2025-04-22 20:50:27,750:INFO:Base model : Logistic Regression
2025-04-22 20:50:27,755:INFO:Importing untrained CalibratedClassifierCV
2025-04-22 20:50:27,755:INFO:SubProcess create_model() called ==================================
2025-04-22 20:50:27,755:INFO:Initializing create_model()
2025-04-22 20:50:27,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='sigmoid', n_jobs=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FB0AFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:50:27,755:INFO:Checking exceptions
2025-04-22 20:50:27,755:INFO:Importing libraries
2025-04-22 20:50:27,756:INFO:Copying training dataset
2025-04-22 20:50:27,761:INFO:Defining folds
2025-04-22 20:50:27,761:INFO:Declaring metric variables
2025-04-22 20:50:27,765:INFO:Importing untrained model
2025-04-22 20:50:27,765:INFO:Declaring custom model
2025-04-22 20:50:27,768:INFO:Logistic Regression Imported successfully
2025-04-22 20:50:27,774:INFO:Starting cross validation
2025-04-22 20:50:27,775:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:50:31,391:INFO:Calculating mean and std
2025-04-22 20:50:31,393:INFO:Creating metrics dataframe
2025-04-22 20:50:31,399:INFO:Finalizing model
2025-04-22 20:50:32,783:INFO:Uploading results into container
2025-04-22 20:50:32,784:INFO:Uploading model into container now
2025-04-22 20:50:32,784:INFO:_master_model_container: 32
2025-04-22 20:50:32,784:INFO:_display_container: 27
2025-04-22 20:50:32,785:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='sigmoid', n_jobs=None)
2025-04-22 20:50:32,785:INFO:create_model() successfully completed......................................
2025-04-22 20:50:32,994:INFO:SubProcess create_model() end ==================================
2025-04-22 20:50:33,004:INFO:_master_model_container: 32
2025-04-22 20:50:33,004:INFO:_display_container: 27
2025-04-22 20:50:33,004:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='sigmoid', n_jobs=None)
2025-04-22 20:50:33,005:INFO:calibrate_model() successfully completed......................................
2025-04-22 20:50:33,216:INFO:Initializing plot_model()
2025-04-22 20:50:33,216:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='sigmoid', n_jobs=None), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:50:33,216:INFO:Checking exceptions
2025-04-22 20:50:33,220:INFO:Preloading libraries
2025-04-22 20:50:33,220:INFO:Copying training dataset
2025-04-22 20:50:33,220:INFO:Plot type: calibration
2025-04-22 20:50:33,230:INFO:Scoring test/hold-out set
2025-04-22 20:50:33,381:INFO:Visual Rendered Successfully
2025-04-22 20:50:33,591:INFO:plot_model() successfully completed......................................
2025-04-22 20:51:12,533:INFO:Initializing plot_model()
2025-04-22 20:51:12,533:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:51:12,533:INFO:Checking exceptions
2025-04-22 20:51:12,539:INFO:Preloading libraries
2025-04-22 20:51:12,540:INFO:Copying training dataset
2025-04-22 20:51:12,540:INFO:Plot type: calibration
2025-04-22 20:51:12,551:INFO:Scoring test/hold-out set
2025-04-22 20:51:12,700:INFO:Visual Rendered Successfully
2025-04-22 20:51:12,915:INFO:plot_model() successfully completed......................................
2025-04-22 20:51:12,916:INFO:Initializing calibrate_model()
2025-04-22 20:51:12,916:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=isotonic, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2025-04-22 20:51:12,916:INFO:Checking exceptions
2025-04-22 20:51:12,918:INFO:Preloading libraries
2025-04-22 20:51:12,918:INFO:Preparing display monitor
2025-04-22 20:51:12,929:INFO:Getting model name
2025-04-22 20:51:12,929:INFO:Base model : Logistic Regression
2025-04-22 20:51:12,935:INFO:Importing untrained CalibratedClassifierCV
2025-04-22 20:51:12,935:INFO:SubProcess create_model() called ==================================
2025-04-22 20:51:12,935:INFO:Initializing create_model()
2025-04-22 20:51:12,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='isotonic', n_jobs=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21FEC2790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:51:12,935:INFO:Checking exceptions
2025-04-22 20:51:12,935:INFO:Importing libraries
2025-04-22 20:51:12,937:INFO:Copying training dataset
2025-04-22 20:51:12,942:INFO:Defining folds
2025-04-22 20:51:12,942:INFO:Declaring metric variables
2025-04-22 20:51:12,946:INFO:Importing untrained model
2025-04-22 20:51:12,946:INFO:Declaring custom model
2025-04-22 20:51:12,949:INFO:Logistic Regression Imported successfully
2025-04-22 20:51:12,955:INFO:Starting cross validation
2025-04-22 20:51:12,956:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:51:16,628:INFO:Calculating mean and std
2025-04-22 20:51:16,630:INFO:Creating metrics dataframe
2025-04-22 20:51:16,634:INFO:Finalizing model
2025-04-22 20:51:18,062:INFO:Uploading results into container
2025-04-22 20:51:18,062:INFO:Uploading model into container now
2025-04-22 20:51:18,063:INFO:_master_model_container: 33
2025-04-22 20:51:18,063:INFO:_display_container: 28
2025-04-22 20:51:18,064:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='isotonic', n_jobs=None)
2025-04-22 20:51:18,064:INFO:create_model() successfully completed......................................
2025-04-22 20:51:18,272:INFO:SubProcess create_model() end ==================================
2025-04-22 20:51:18,282:INFO:_master_model_container: 33
2025-04-22 20:51:18,282:INFO:_display_container: 28
2025-04-22 20:51:18,283:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='isotonic', n_jobs=None)
2025-04-22 20:51:18,283:INFO:calibrate_model() successfully completed......................................
2025-04-22 20:51:18,495:INFO:Initializing plot_model()
2025-04-22 20:51:18,495:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=LogisticRegression(C=1.0, class_weight=None,
                                                    dual=False,
                                                    fit_intercept=True,
                                                    intercept_scaling=1,
                                                    l1_ratio=None,
                                                    max_iter=1000,
                                                    multi_class='auto',
                                                    n_jobs=None, penalty='l2',
                                                    random_state=42,
                                                    solver='lbfgs', tol=0.0001,
                                                    verbose=0,
                                                    warm_start=False),
                       method='isotonic', n_jobs=None), plot=calibration, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 20:51:18,495:INFO:Checking exceptions
2025-04-22 20:51:18,499:INFO:Preloading libraries
2025-04-22 20:51:18,500:INFO:Copying training dataset
2025-04-22 20:51:18,500:INFO:Plot type: calibration
2025-04-22 20:51:18,509:INFO:Scoring test/hold-out set
2025-04-22 20:51:18,662:INFO:Visual Rendered Successfully
2025-04-22 20:51:18,875:INFO:plot_model() successfully completed......................................
2025-04-22 20:53:14,466:INFO:Initializing optimize_threshold()
2025-04-22 20:53:14,467:INFO:optimize_threshold(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), optimize=f1, return_data=True, plot_kwargs=None, verbose=True, shgo_kwargs={})
2025-04-22 20:53:14,467:INFO:Importing libraries
2025-04-22 20:53:14,467:INFO:Checking exceptions
2025-04-22 20:53:14,467:INFO:defining variables
2025-04-22 20:53:14,467:INFO:starting optimization
2025-04-22 20:53:14,499:INFO:Initializing create_model()
2025-04-22 20:53:14,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:14,499:INFO:Checking exceptions
2025-04-22 20:53:14,501:INFO:Importing libraries
2025-04-22 20:53:14,501:INFO:Copying training dataset
2025-04-22 20:53:14,506:INFO:Defining folds
2025-04-22 20:53:14,506:INFO:Declaring metric variables
2025-04-22 20:53:14,508:INFO:Importing untrained model
2025-04-22 20:53:14,508:INFO:Declaring custom model
2025-04-22 20:53:14,508:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:14,508:INFO:Starting cross validation
2025-04-22 20:53:14,508:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:17,742:INFO:Calculating mean and std
2025-04-22 20:53:17,742:INFO:Creating metrics dataframe
2025-04-22 20:53:17,744:INFO:Finalizing model
2025-04-22 20:53:19,044:INFO:Uploading results into container
2025-04-22 20:53:19,045:INFO:Uploading model into container now
2025-04-22 20:53:19,045:INFO:_master_model_container: 34
2025-04-22 20:53:19,045:INFO:_display_container: 29
2025-04-22 20:53:19,047:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:19,047:INFO:create_model() successfully completed......................................
2025-04-22 20:53:19,257:INFO:Threshold: 0.375. F1: 0.4958
2025-04-22 20:53:19,257:INFO:Initializing create_model()
2025-04-22 20:53:19,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:19,258:INFO:Checking exceptions
2025-04-22 20:53:19,259:INFO:Importing libraries
2025-04-22 20:53:19,259:INFO:Copying training dataset
2025-04-22 20:53:19,264:INFO:Defining folds
2025-04-22 20:53:19,264:INFO:Declaring metric variables
2025-04-22 20:53:19,264:INFO:Importing untrained model
2025-04-22 20:53:19,264:INFO:Declaring custom model
2025-04-22 20:53:19,264:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:19,265:INFO:Starting cross validation
2025-04-22 20:53:19,265:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:20,371:INFO:Calculating mean and std
2025-04-22 20:53:20,372:INFO:Creating metrics dataframe
2025-04-22 20:53:20,373:INFO:Finalizing model
2025-04-22 20:53:21,707:INFO:Uploading results into container
2025-04-22 20:53:21,707:INFO:Uploading model into container now
2025-04-22 20:53:21,708:INFO:_master_model_container: 35
2025-04-22 20:53:21,708:INFO:_display_container: 29
2025-04-22 20:53:21,709:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:21,709:INFO:create_model() successfully completed......................................
2025-04-22 20:53:21,919:INFO:Threshold: 0.125. F1: 0.3652
2025-04-22 20:53:21,920:INFO:Initializing create_model()
2025-04-22 20:53:21,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:21,920:INFO:Checking exceptions
2025-04-22 20:53:21,921:INFO:Importing libraries
2025-04-22 20:53:21,921:INFO:Copying training dataset
2025-04-22 20:53:21,927:INFO:Defining folds
2025-04-22 20:53:21,927:INFO:Declaring metric variables
2025-04-22 20:53:21,927:INFO:Importing untrained model
2025-04-22 20:53:21,928:INFO:Declaring custom model
2025-04-22 20:53:21,928:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:21,928:INFO:Starting cross validation
2025-04-22 20:53:21,929:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:23,029:INFO:Calculating mean and std
2025-04-22 20:53:23,029:INFO:Creating metrics dataframe
2025-04-22 20:53:23,030:INFO:Finalizing model
2025-04-22 20:53:24,363:INFO:Uploading results into container
2025-04-22 20:53:24,363:INFO:Uploading model into container now
2025-04-22 20:53:24,364:INFO:_master_model_container: 36
2025-04-22 20:53:24,364:INFO:_display_container: 29
2025-04-22 20:53:24,364:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5, random_state=42,
                                     solver='lbfgs', tol=0.0001, verbose=0,
                                     warm_start=False)
2025-04-22 20:53:24,365:INFO:create_model() successfully completed......................................
2025-04-22 20:53:24,578:INFO:Threshold: 0.5. F1: 0.5328
2025-04-22 20:53:24,578:INFO:Initializing create_model()
2025-04-22 20:53:24,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.25, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:24,578:INFO:Checking exceptions
2025-04-22 20:53:24,579:INFO:Importing libraries
2025-04-22 20:53:24,579:INFO:Copying training dataset
2025-04-22 20:53:24,584:INFO:Defining folds
2025-04-22 20:53:24,584:INFO:Declaring metric variables
2025-04-22 20:53:24,584:INFO:Importing untrained model
2025-04-22 20:53:24,584:INFO:Declaring custom model
2025-04-22 20:53:24,585:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:24,585:INFO:Starting cross validation
2025-04-22 20:53:24,585:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:25,701:INFO:Calculating mean and std
2025-04-22 20:53:25,701:INFO:Creating metrics dataframe
2025-04-22 20:53:25,702:INFO:Finalizing model
2025-04-22 20:53:27,026:INFO:Uploading results into container
2025-04-22 20:53:27,029:INFO:Uploading model into container now
2025-04-22 20:53:27,029:INFO:_master_model_container: 37
2025-04-22 20:53:27,029:INFO:_display_container: 29
2025-04-22 20:53:27,030:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.25,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:27,030:INFO:create_model() successfully completed......................................
2025-04-22 20:53:27,240:INFO:Threshold: 0.25. F1: 0.3666
2025-04-22 20:53:27,240:INFO:Initializing create_model()
2025-04-22 20:53:27,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:27,240:INFO:Checking exceptions
2025-04-22 20:53:27,241:INFO:Importing libraries
2025-04-22 20:53:27,241:INFO:Copying training dataset
2025-04-22 20:53:27,246:INFO:Defining folds
2025-04-22 20:53:27,246:INFO:Declaring metric variables
2025-04-22 20:53:27,246:INFO:Importing untrained model
2025-04-22 20:53:27,246:INFO:Declaring custom model
2025-04-22 20:53:27,247:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:27,247:INFO:Starting cross validation
2025-04-22 20:53:27,249:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:28,374:INFO:Calculating mean and std
2025-04-22 20:53:28,374:INFO:Creating metrics dataframe
2025-04-22 20:53:28,375:INFO:Finalizing model
2025-04-22 20:53:29,699:INFO:Uploading results into container
2025-04-22 20:53:29,699:INFO:Uploading model into container now
2025-04-22 20:53:29,699:INFO:_master_model_container: 38
2025-04-22 20:53:29,700:INFO:_display_container: 29
2025-04-22 20:53:29,700:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:29,700:INFO:create_model() successfully completed......................................
2025-04-22 20:53:29,910:INFO:Threshold: 0.625. F1: 0.5307
2025-04-22 20:53:29,910:INFO:Initializing create_model()
2025-04-22 20:53:29,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.75, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:29,910:INFO:Checking exceptions
2025-04-22 20:53:29,911:INFO:Importing libraries
2025-04-22 20:53:29,911:INFO:Copying training dataset
2025-04-22 20:53:29,916:INFO:Defining folds
2025-04-22 20:53:29,916:INFO:Declaring metric variables
2025-04-22 20:53:29,916:INFO:Importing untrained model
2025-04-22 20:53:29,916:INFO:Declaring custom model
2025-04-22 20:53:29,916:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:29,916:INFO:Starting cross validation
2025-04-22 20:53:29,917:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:31,082:INFO:Calculating mean and std
2025-04-22 20:53:31,082:INFO:Creating metrics dataframe
2025-04-22 20:53:31,084:INFO:Finalizing model
2025-04-22 20:53:32,430:INFO:Uploading results into container
2025-04-22 20:53:32,430:INFO:Uploading model into container now
2025-04-22 20:53:32,430:INFO:_master_model_container: 39
2025-04-22 20:53:32,431:INFO:_display_container: 29
2025-04-22 20:53:32,431:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.75,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:32,431:INFO:create_model() successfully completed......................................
2025-04-22 20:53:32,643:INFO:Threshold: 0.75. F1: 0.4613
2025-04-22 20:53:32,643:INFO:Initializing create_model()
2025-04-22 20:53:32,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:32,643:INFO:Checking exceptions
2025-04-22 20:53:32,644:INFO:Importing libraries
2025-04-22 20:53:32,644:INFO:Copying training dataset
2025-04-22 20:53:32,651:INFO:Defining folds
2025-04-22 20:53:32,651:INFO:Declaring metric variables
2025-04-22 20:53:32,651:INFO:Importing untrained model
2025-04-22 20:53:32,651:INFO:Declaring custom model
2025-04-22 20:53:32,652:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:32,652:INFO:Starting cross validation
2025-04-22 20:53:32,653:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:33,757:INFO:Calculating mean and std
2025-04-22 20:53:33,757:INFO:Creating metrics dataframe
2025-04-22 20:53:33,759:INFO:Finalizing model
2025-04-22 20:53:35,092:INFO:Uploading results into container
2025-04-22 20:53:35,093:INFO:Uploading model into container now
2025-04-22 20:53:35,093:INFO:_master_model_container: 40
2025-04-22 20:53:35,093:INFO:_display_container: 29
2025-04-22 20:53:35,095:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:35,095:INFO:create_model() successfully completed......................................
2025-04-22 20:53:35,342:INFO:Threshold: 0.875. F1: 0.2908
2025-04-22 20:53:35,342:INFO:Initializing create_model()
2025-04-22 20:53:35,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:35,342:INFO:Checking exceptions
2025-04-22 20:53:35,343:INFO:Importing libraries
2025-04-22 20:53:35,343:INFO:Copying training dataset
2025-04-22 20:53:35,350:INFO:Defining folds
2025-04-22 20:53:35,350:INFO:Declaring metric variables
2025-04-22 20:53:35,350:INFO:Importing untrained model
2025-04-22 20:53:35,350:INFO:Declaring custom model
2025-04-22 20:53:35,350:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:35,351:INFO:Starting cross validation
2025-04-22 20:53:35,351:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:36,624:INFO:Calculating mean and std
2025-04-22 20:53:36,624:INFO:Creating metrics dataframe
2025-04-22 20:53:36,626:INFO:Finalizing model
2025-04-22 20:53:37,975:INFO:Uploading results into container
2025-04-22 20:53:37,975:INFO:Uploading model into container now
2025-04-22 20:53:37,976:INFO:_master_model_container: 41
2025-04-22 20:53:37,976:INFO:_display_container: 29
2025-04-22 20:53:37,976:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.0, random_state=42,
                                     solver='lbfgs', tol=0.0001, verbose=0,
                                     warm_start=False)
2025-04-22 20:53:37,976:INFO:create_model() successfully completed......................................
2025-04-22 20:53:38,190:INFO:Threshold: 0.0. F1: 0.3652
2025-04-22 20:53:38,191:INFO:Initializing create_model()
2025-04-22 20:53:38,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:38,191:INFO:Checking exceptions
2025-04-22 20:53:38,191:INFO:Importing libraries
2025-04-22 20:53:38,191:INFO:Copying training dataset
2025-04-22 20:53:38,196:INFO:Defining folds
2025-04-22 20:53:38,196:INFO:Declaring metric variables
2025-04-22 20:53:38,198:INFO:Importing untrained model
2025-04-22 20:53:38,198:INFO:Declaring custom model
2025-04-22 20:53:38,198:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:38,198:INFO:Starting cross validation
2025-04-22 20:53:38,199:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:39,312:INFO:Calculating mean and std
2025-04-22 20:53:39,314:INFO:Creating metrics dataframe
2025-04-22 20:53:39,314:INFO:Finalizing model
2025-04-22 20:53:40,692:INFO:Uploading results into container
2025-04-22 20:53:40,692:INFO:Uploading model into container now
2025-04-22 20:53:40,692:INFO:_master_model_container: 42
2025-04-22 20:53:40,692:INFO:_display_container: 29
2025-04-22 20:53:40,693:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5, random_state=42,
                                     solver='lbfgs', tol=0.0001, verbose=0,
                                     warm_start=False)
2025-04-22 20:53:40,693:INFO:create_model() successfully completed......................................
2025-04-22 20:53:40,922:INFO:Threshold: 0.5. F1: 0.5328
2025-04-22 20:53:40,922:INFO:Initializing create_model()
2025-04-22 20:53:40,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5000000149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:40,922:INFO:Checking exceptions
2025-04-22 20:53:40,924:INFO:Importing libraries
2025-04-22 20:53:40,924:INFO:Copying training dataset
2025-04-22 20:53:40,929:INFO:Defining folds
2025-04-22 20:53:40,929:INFO:Declaring metric variables
2025-04-22 20:53:40,929:INFO:Importing untrained model
2025-04-22 20:53:40,929:INFO:Declaring custom model
2025-04-22 20:53:40,929:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:40,930:INFO:Starting cross validation
2025-04-22 20:53:40,930:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:42,174:INFO:Calculating mean and std
2025-04-22 20:53:42,174:INFO:Creating metrics dataframe
2025-04-22 20:53:42,176:INFO:Finalizing model
2025-04-22 20:53:43,501:INFO:Uploading results into container
2025-04-22 20:53:43,501:INFO:Uploading model into container now
2025-04-22 20:53:43,501:INFO:_master_model_container: 43
2025-04-22 20:53:43,502:INFO:_display_container: 29
2025-04-22 20:53:43,502:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5000000149011612,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:43,502:INFO:create_model() successfully completed......................................
2025-04-22 20:53:43,712:INFO:Threshold: 0.5000000149011612. F1: 0.5328
2025-04-22 20:53:43,717:INFO:Initializing create_model()
2025-04-22 20:53:43,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.21875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:43,717:INFO:Checking exceptions
2025-04-22 20:53:43,717:INFO:Importing libraries
2025-04-22 20:53:43,717:INFO:Copying training dataset
2025-04-22 20:53:43,724:INFO:Defining folds
2025-04-22 20:53:43,724:INFO:Declaring metric variables
2025-04-22 20:53:43,724:INFO:Importing untrained model
2025-04-22 20:53:43,724:INFO:Declaring custom model
2025-04-22 20:53:43,724:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:43,724:INFO:Starting cross validation
2025-04-22 20:53:43,725:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:44,925:INFO:Calculating mean and std
2025-04-22 20:53:44,925:INFO:Creating metrics dataframe
2025-04-22 20:53:44,926:INFO:Finalizing model
2025-04-22 20:53:46,372:INFO:Uploading results into container
2025-04-22 20:53:46,372:INFO:Uploading model into container now
2025-04-22 20:53:46,373:INFO:_master_model_container: 44
2025-04-22 20:53:46,373:INFO:_display_container: 29
2025-04-22 20:53:46,374:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.21875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:46,374:INFO:create_model() successfully completed......................................
2025-04-22 20:53:46,585:INFO:Threshold: 0.21875. F1: 0.366
2025-04-22 20:53:46,586:INFO:Initializing create_model()
2025-04-22 20:53:46,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.09375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:46,586:INFO:Checking exceptions
2025-04-22 20:53:46,587:INFO:Importing libraries
2025-04-22 20:53:46,587:INFO:Copying training dataset
2025-04-22 20:53:46,593:INFO:Defining folds
2025-04-22 20:53:46,593:INFO:Declaring metric variables
2025-04-22 20:53:46,593:INFO:Importing untrained model
2025-04-22 20:53:46,593:INFO:Declaring custom model
2025-04-22 20:53:46,593:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:46,593:INFO:Starting cross validation
2025-04-22 20:53:46,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:48,044:INFO:Calculating mean and std
2025-04-22 20:53:48,045:INFO:Creating metrics dataframe
2025-04-22 20:53:48,045:INFO:Finalizing model
2025-04-22 20:53:49,471:INFO:Uploading results into container
2025-04-22 20:53:49,471:INFO:Uploading model into container now
2025-04-22 20:53:49,472:INFO:_master_model_container: 45
2025-04-22 20:53:49,472:INFO:_display_container: 29
2025-04-22 20:53:49,473:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.09375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:49,473:INFO:create_model() successfully completed......................................
2025-04-22 20:53:49,686:INFO:Threshold: 0.09375. F1: 0.3652
2025-04-22 20:53:49,687:INFO:Initializing create_model()
2025-04-22 20:53:49,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:49,687:INFO:Checking exceptions
2025-04-22 20:53:49,688:INFO:Importing libraries
2025-04-22 20:53:49,688:INFO:Copying training dataset
2025-04-22 20:53:49,694:INFO:Defining folds
2025-04-22 20:53:49,694:INFO:Declaring metric variables
2025-04-22 20:53:49,694:INFO:Importing untrained model
2025-04-22 20:53:49,694:INFO:Declaring custom model
2025-04-22 20:53:49,695:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:49,695:INFO:Starting cross validation
2025-04-22 20:53:49,696:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:51,140:INFO:Calculating mean and std
2025-04-22 20:53:51,140:INFO:Creating metrics dataframe
2025-04-22 20:53:51,141:INFO:Finalizing model
2025-04-22 20:53:52,598:INFO:Uploading results into container
2025-04-22 20:53:52,598:INFO:Uploading model into container now
2025-04-22 20:53:52,599:INFO:_master_model_container: 46
2025-04-22 20:53:52,599:INFO:_display_container: 29
2025-04-22 20:53:52,599:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.3125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:52,599:INFO:create_model() successfully completed......................................
2025-04-22 20:53:52,812:INFO:Threshold: 0.3125. F1: 0.381
2025-04-22 20:53:52,812:INFO:Initializing create_model()
2025-04-22 20:53:52,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:52,812:INFO:Checking exceptions
2025-04-22 20:53:52,813:INFO:Importing libraries
2025-04-22 20:53:52,813:INFO:Copying training dataset
2025-04-22 20:53:52,821:INFO:Defining folds
2025-04-22 20:53:52,821:INFO:Declaring metric variables
2025-04-22 20:53:52,821:INFO:Importing untrained model
2025-04-22 20:53:52,821:INFO:Declaring custom model
2025-04-22 20:53:52,822:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:52,822:INFO:Starting cross validation
2025-04-22 20:53:52,822:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:54,305:INFO:Calculating mean and std
2025-04-22 20:53:54,305:INFO:Creating metrics dataframe
2025-04-22 20:53:54,307:INFO:Finalizing model
2025-04-22 20:53:55,885:INFO:Uploading results into container
2025-04-22 20:53:55,885:INFO:Uploading model into container now
2025-04-22 20:53:55,885:INFO:_master_model_container: 47
2025-04-22 20:53:55,885:INFO:_display_container: 29
2025-04-22 20:53:55,887:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.1875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:55,887:INFO:create_model() successfully completed......................................
2025-04-22 20:53:56,102:INFO:Threshold: 0.1875. F1: 0.3652
2025-04-22 20:53:56,103:INFO:Initializing create_model()
2025-04-22 20:53:56,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.34375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:56,103:INFO:Checking exceptions
2025-04-22 20:53:56,104:INFO:Importing libraries
2025-04-22 20:53:56,104:INFO:Copying training dataset
2025-04-22 20:53:56,110:INFO:Defining folds
2025-04-22 20:53:56,110:INFO:Declaring metric variables
2025-04-22 20:53:56,110:INFO:Importing untrained model
2025-04-22 20:53:56,110:INFO:Declaring custom model
2025-04-22 20:53:56,111:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:56,111:INFO:Starting cross validation
2025-04-22 20:53:56,111:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:53:57,550:INFO:Calculating mean and std
2025-04-22 20:53:57,550:INFO:Creating metrics dataframe
2025-04-22 20:53:57,552:INFO:Finalizing model
2025-04-22 20:53:58,921:INFO:Uploading results into container
2025-04-22 20:53:58,922:INFO:Uploading model into container now
2025-04-22 20:53:58,922:INFO:_master_model_container: 48
2025-04-22 20:53:58,922:INFO:_display_container: 29
2025-04-22 20:53:58,923:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.34375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:53:58,923:INFO:create_model() successfully completed......................................
2025-04-22 20:53:59,129:INFO:Threshold: 0.34375. F1: 0.4934
2025-04-22 20:53:59,129:INFO:Initializing create_model()
2025-04-22 20:53:59,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:53:59,130:INFO:Checking exceptions
2025-04-22 20:53:59,131:INFO:Importing libraries
2025-04-22 20:53:59,131:INFO:Copying training dataset
2025-04-22 20:53:59,136:INFO:Defining folds
2025-04-22 20:53:59,136:INFO:Declaring metric variables
2025-04-22 20:53:59,136:INFO:Importing untrained model
2025-04-22 20:53:59,136:INFO:Declaring custom model
2025-04-22 20:53:59,136:INFO:Logistic Regression Imported successfully
2025-04-22 20:53:59,136:INFO:Starting cross validation
2025-04-22 20:53:59,138:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:00,251:INFO:Calculating mean and std
2025-04-22 20:54:00,251:INFO:Creating metrics dataframe
2025-04-22 20:54:00,253:INFO:Finalizing model
2025-04-22 20:54:01,610:INFO:Uploading results into container
2025-04-22 20:54:01,610:INFO:Uploading model into container now
2025-04-22 20:54:01,610:INFO:_master_model_container: 49
2025-04-22 20:54:01,611:INFO:_display_container: 29
2025-04-22 20:54:01,611:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.4375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:01,611:INFO:create_model() successfully completed......................................
2025-04-22 20:54:01,841:INFO:Threshold: 0.4375. F1: 0.5171
2025-04-22 20:54:01,842:INFO:Initializing create_model()
2025-04-22 20:54:01,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.46875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:01,842:INFO:Checking exceptions
2025-04-22 20:54:01,843:INFO:Importing libraries
2025-04-22 20:54:01,843:INFO:Copying training dataset
2025-04-22 20:54:01,849:INFO:Defining folds
2025-04-22 20:54:01,849:INFO:Declaring metric variables
2025-04-22 20:54:01,849:INFO:Importing untrained model
2025-04-22 20:54:01,849:INFO:Declaring custom model
2025-04-22 20:54:01,849:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:01,849:INFO:Starting cross validation
2025-04-22 20:54:01,850:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:03,137:INFO:Calculating mean and std
2025-04-22 20:54:03,137:INFO:Creating metrics dataframe
2025-04-22 20:54:03,139:INFO:Finalizing model
2025-04-22 20:54:04,489:INFO:Uploading results into container
2025-04-22 20:54:04,490:INFO:Uploading model into container now
2025-04-22 20:54:04,490:INFO:_master_model_container: 50
2025-04-22 20:54:04,490:INFO:_display_container: 29
2025-04-22 20:54:04,491:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.46875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:04,492:INFO:create_model() successfully completed......................................
2025-04-22 20:54:04,721:INFO:Threshold: 0.46875. F1: 0.5295
2025-04-22 20:54:04,721:INFO:Initializing create_model()
2025-04-22 20:54:04,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:04,721:INFO:Checking exceptions
2025-04-22 20:54:04,723:INFO:Importing libraries
2025-04-22 20:54:04,723:INFO:Copying training dataset
2025-04-22 20:54:04,729:INFO:Defining folds
2025-04-22 20:54:04,730:INFO:Declaring metric variables
2025-04-22 20:54:04,730:INFO:Importing untrained model
2025-04-22 20:54:04,730:INFO:Declaring custom model
2025-04-22 20:54:04,730:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:04,730:INFO:Starting cross validation
2025-04-22 20:54:04,731:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:06,200:INFO:Calculating mean and std
2025-04-22 20:54:06,200:INFO:Creating metrics dataframe
2025-04-22 20:54:06,202:INFO:Finalizing model
2025-04-22 20:54:07,703:INFO:Uploading results into container
2025-04-22 20:54:07,703:INFO:Uploading model into container now
2025-04-22 20:54:07,705:INFO:_master_model_container: 51
2025-04-22 20:54:07,705:INFO:_display_container: 29
2025-04-22 20:54:07,705:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:07,706:INFO:create_model() successfully completed......................................
2025-04-22 20:54:07,925:INFO:Threshold: 0.5625. F1: 0.5236
2025-04-22 20:54:07,925:INFO:Initializing create_model()
2025-04-22 20:54:07,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.59375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:07,925:INFO:Checking exceptions
2025-04-22 20:54:07,926:INFO:Importing libraries
2025-04-22 20:54:07,926:INFO:Copying training dataset
2025-04-22 20:54:07,932:INFO:Defining folds
2025-04-22 20:54:07,932:INFO:Declaring metric variables
2025-04-22 20:54:07,932:INFO:Importing untrained model
2025-04-22 20:54:07,932:INFO:Declaring custom model
2025-04-22 20:54:07,932:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:07,932:INFO:Starting cross validation
2025-04-22 20:54:07,933:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:09,551:INFO:Calculating mean and std
2025-04-22 20:54:09,551:INFO:Creating metrics dataframe
2025-04-22 20:54:09,552:INFO:Finalizing model
2025-04-22 20:54:11,011:INFO:Uploading results into container
2025-04-22 20:54:11,012:INFO:Uploading model into container now
2025-04-22 20:54:11,012:INFO:_master_model_container: 52
2025-04-22 20:54:11,012:INFO:_display_container: 29
2025-04-22 20:54:11,013:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.59375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:11,013:INFO:create_model() successfully completed......................................
2025-04-22 20:54:11,232:INFO:Threshold: 0.59375. F1: 0.5296
2025-04-22 20:54:11,233:INFO:Initializing create_model()
2025-04-22 20:54:11,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:11,233:INFO:Checking exceptions
2025-04-22 20:54:11,234:INFO:Importing libraries
2025-04-22 20:54:11,234:INFO:Copying training dataset
2025-04-22 20:54:11,242:INFO:Defining folds
2025-04-22 20:54:11,242:INFO:Declaring metric variables
2025-04-22 20:54:11,242:INFO:Importing untrained model
2025-04-22 20:54:11,242:INFO:Declaring custom model
2025-04-22 20:54:11,242:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:11,242:INFO:Starting cross validation
2025-04-22 20:54:11,244:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:12,771:INFO:Calculating mean and std
2025-04-22 20:54:12,772:INFO:Creating metrics dataframe
2025-04-22 20:54:12,773:INFO:Finalizing model
2025-04-22 20:54:14,131:INFO:Uploading results into container
2025-04-22 20:54:14,131:INFO:Uploading model into container now
2025-04-22 20:54:14,132:INFO:_master_model_container: 53
2025-04-22 20:54:14,132:INFO:_display_container: 29
2025-04-22 20:54:14,134:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.6875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:14,134:INFO:create_model() successfully completed......................................
2025-04-22 20:54:14,355:INFO:Threshold: 0.6875. F1: 0.5189
2025-04-22 20:54:14,356:INFO:Initializing create_model()
2025-04-22 20:54:14,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.71875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:14,356:INFO:Checking exceptions
2025-04-22 20:54:14,357:INFO:Importing libraries
2025-04-22 20:54:14,357:INFO:Copying training dataset
2025-04-22 20:54:14,362:INFO:Defining folds
2025-04-22 20:54:14,362:INFO:Declaring metric variables
2025-04-22 20:54:14,362:INFO:Importing untrained model
2025-04-22 20:54:14,362:INFO:Declaring custom model
2025-04-22 20:54:14,364:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:14,364:INFO:Starting cross validation
2025-04-22 20:54:14,365:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:15,816:INFO:Calculating mean and std
2025-04-22 20:54:15,816:INFO:Creating metrics dataframe
2025-04-22 20:54:15,817:INFO:Finalizing model
2025-04-22 20:54:17,391:INFO:Uploading results into container
2025-04-22 20:54:17,391:INFO:Uploading model into container now
2025-04-22 20:54:17,392:INFO:_master_model_container: 54
2025-04-22 20:54:17,392:INFO:_display_container: 29
2025-04-22 20:54:17,393:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.71875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:17,393:INFO:create_model() successfully completed......................................
2025-04-22 20:54:17,613:INFO:Threshold: 0.71875. F1: 0.4685
2025-04-22 20:54:17,614:INFO:Initializing create_model()
2025-04-22 20:54:17,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:17,614:INFO:Checking exceptions
2025-04-22 20:54:17,616:INFO:Importing libraries
2025-04-22 20:54:17,616:INFO:Copying training dataset
2025-04-22 20:54:17,622:INFO:Defining folds
2025-04-22 20:54:17,622:INFO:Declaring metric variables
2025-04-22 20:54:17,622:INFO:Importing untrained model
2025-04-22 20:54:17,622:INFO:Declaring custom model
2025-04-22 20:54:17,622:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:17,623:INFO:Starting cross validation
2025-04-22 20:54:17,623:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:19,085:INFO:Calculating mean and std
2025-04-22 20:54:19,085:INFO:Creating metrics dataframe
2025-04-22 20:54:19,087:INFO:Finalizing model
2025-04-22 20:54:20,482:INFO:Uploading results into container
2025-04-22 20:54:20,483:INFO:Uploading model into container now
2025-04-22 20:54:20,483:INFO:_master_model_container: 55
2025-04-22 20:54:20,483:INFO:_display_container: 29
2025-04-22 20:54:20,484:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.8125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:20,484:INFO:create_model() successfully completed......................................
2025-04-22 20:54:20,706:INFO:Threshold: 0.8125. F1: 0.3976
2025-04-22 20:54:20,707:INFO:Initializing create_model()
2025-04-22 20:54:20,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.84375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:20,707:INFO:Checking exceptions
2025-04-22 20:54:20,708:INFO:Importing libraries
2025-04-22 20:54:20,708:INFO:Copying training dataset
2025-04-22 20:54:20,714:INFO:Defining folds
2025-04-22 20:54:20,714:INFO:Declaring metric variables
2025-04-22 20:54:20,714:INFO:Importing untrained model
2025-04-22 20:54:20,715:INFO:Declaring custom model
2025-04-22 20:54:20,715:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:20,715:INFO:Starting cross validation
2025-04-22 20:54:20,716:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:22,184:INFO:Calculating mean and std
2025-04-22 20:54:22,185:INFO:Creating metrics dataframe
2025-04-22 20:54:22,186:INFO:Finalizing model
2025-04-22 20:54:23,561:INFO:Uploading results into container
2025-04-22 20:54:23,561:INFO:Uploading model into container now
2025-04-22 20:54:23,562:INFO:_master_model_container: 56
2025-04-22 20:54:23,562:INFO:_display_container: 29
2025-04-22 20:54:23,562:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.84375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:23,562:INFO:create_model() successfully completed......................................
2025-04-22 20:54:23,769:INFO:Threshold: 0.84375. F1: 0.3614
2025-04-22 20:54:23,769:INFO:Initializing create_model()
2025-04-22 20:54:23,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.9375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:23,769:INFO:Checking exceptions
2025-04-22 20:54:23,771:INFO:Importing libraries
2025-04-22 20:54:23,771:INFO:Copying training dataset
2025-04-22 20:54:23,776:INFO:Defining folds
2025-04-22 20:54:23,777:INFO:Declaring metric variables
2025-04-22 20:54:23,777:INFO:Importing untrained model
2025-04-22 20:54:23,777:INFO:Declaring custom model
2025-04-22 20:54:23,777:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:23,777:INFO:Starting cross validation
2025-04-22 20:54:23,778:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:25,230:INFO:Calculating mean and std
2025-04-22 20:54:25,231:INFO:Creating metrics dataframe
2025-04-22 20:54:25,232:INFO:Finalizing model
2025-04-22 20:54:26,620:INFO:Uploading results into container
2025-04-22 20:54:26,620:INFO:Uploading model into container now
2025-04-22 20:54:26,620:INFO:_master_model_container: 57
2025-04-22 20:54:26,620:INFO:_display_container: 29
2025-04-22 20:54:26,621:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.9375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:26,621:INFO:create_model() successfully completed......................................
2025-04-22 20:54:26,840:INFO:Threshold: 0.9375. F1: 0.0211
2025-04-22 20:54:26,841:INFO:Initializing create_model()
2025-04-22 20:54:26,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:26,841:INFO:Checking exceptions
2025-04-22 20:54:26,842:INFO:Importing libraries
2025-04-22 20:54:26,842:INFO:Copying training dataset
2025-04-22 20:54:26,847:INFO:Defining folds
2025-04-22 20:54:26,847:INFO:Declaring metric variables
2025-04-22 20:54:26,847:INFO:Importing untrained model
2025-04-22 20:54:26,847:INFO:Declaring custom model
2025-04-22 20:54:26,848:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:26,848:INFO:Starting cross validation
2025-04-22 20:54:26,848:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:28,322:INFO:Calculating mean and std
2025-04-22 20:54:28,322:INFO:Creating metrics dataframe
2025-04-22 20:54:28,323:INFO:Finalizing model
2025-04-22 20:54:29,710:INFO:Uploading results into container
2025-04-22 20:54:29,711:INFO:Uploading model into container now
2025-04-22 20:54:29,711:INFO:_master_model_container: 58
2025-04-22 20:54:29,711:INFO:_display_container: 29
2025-04-22 20:54:29,712:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.0625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:29,712:INFO:create_model() successfully completed......................................
2025-04-22 20:54:29,921:INFO:Threshold: 0.0625. F1: 0.3652
2025-04-22 20:54:29,921:INFO:Initializing create_model()
2025-04-22 20:54:29,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.96875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:29,921:INFO:Checking exceptions
2025-04-22 20:54:29,922:INFO:Importing libraries
2025-04-22 20:54:29,922:INFO:Copying training dataset
2025-04-22 20:54:29,929:INFO:Defining folds
2025-04-22 20:54:29,929:INFO:Declaring metric variables
2025-04-22 20:54:29,929:INFO:Importing untrained model
2025-04-22 20:54:29,929:INFO:Declaring custom model
2025-04-22 20:54:29,930:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:29,930:INFO:Starting cross validation
2025-04-22 20:54:29,930:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:31,346:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:54:31,358:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:54:31,389:INFO:Calculating mean and std
2025-04-22 20:54:31,390:INFO:Creating metrics dataframe
2025-04-22 20:54:31,392:INFO:Finalizing model
2025-04-22 20:54:32,863:INFO:Uploading results into container
2025-04-22 20:54:32,863:INFO:Uploading model into container now
2025-04-22 20:54:32,864:INFO:_master_model_container: 59
2025-04-22 20:54:32,864:INFO:_display_container: 29
2025-04-22 20:54:32,864:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.96875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:32,866:INFO:create_model() successfully completed......................................
2025-04-22 20:54:33,075:INFO:Threshold: 0.96875. F1: 0.0031
2025-04-22 20:54:33,075:INFO:Initializing create_model()
2025-04-22 20:54:33,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.59375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:33,076:INFO:Checking exceptions
2025-04-22 20:54:33,077:INFO:Importing libraries
2025-04-22 20:54:33,077:INFO:Copying training dataset
2025-04-22 20:54:33,082:INFO:Defining folds
2025-04-22 20:54:33,082:INFO:Declaring metric variables
2025-04-22 20:54:33,082:INFO:Importing untrained model
2025-04-22 20:54:33,082:INFO:Declaring custom model
2025-04-22 20:54:33,082:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:33,083:INFO:Starting cross validation
2025-04-22 20:54:33,083:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:34,527:INFO:Calculating mean and std
2025-04-22 20:54:34,527:INFO:Creating metrics dataframe
2025-04-22 20:54:34,529:INFO:Finalizing model
2025-04-22 20:54:35,946:INFO:Uploading results into container
2025-04-22 20:54:35,946:INFO:Uploading model into container now
2025-04-22 20:54:35,947:INFO:_master_model_container: 60
2025-04-22 20:54:35,947:INFO:_display_container: 29
2025-04-22 20:54:35,948:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.59375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:35,948:INFO:create_model() successfully completed......................................
2025-04-22 20:54:36,157:INFO:Threshold: 0.59375. F1: 0.5296
2025-04-22 20:54:36,158:INFO:Initializing create_model()
2025-04-22 20:54:36,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5937500149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:36,158:INFO:Checking exceptions
2025-04-22 20:54:36,159:INFO:Importing libraries
2025-04-22 20:54:36,159:INFO:Copying training dataset
2025-04-22 20:54:36,164:INFO:Defining folds
2025-04-22 20:54:36,164:INFO:Declaring metric variables
2025-04-22 20:54:36,164:INFO:Importing untrained model
2025-04-22 20:54:36,164:INFO:Declaring custom model
2025-04-22 20:54:36,164:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:36,166:INFO:Starting cross validation
2025-04-22 20:54:36,166:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:37,631:INFO:Calculating mean and std
2025-04-22 20:54:37,632:INFO:Creating metrics dataframe
2025-04-22 20:54:37,633:INFO:Finalizing model
2025-04-22 20:54:39,029:INFO:Uploading results into container
2025-04-22 20:54:39,030:INFO:Uploading model into container now
2025-04-22 20:54:39,030:INFO:_master_model_container: 61
2025-04-22 20:54:39,030:INFO:_display_container: 29
2025-04-22 20:54:39,031:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5937500149011612,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:39,031:INFO:create_model() successfully completed......................................
2025-04-22 20:54:39,239:INFO:Threshold: 0.5937500149011612. F1: 0.5296
2025-04-22 20:54:39,240:INFO:Initializing create_model()
2025-04-22 20:54:39,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:39,240:INFO:Checking exceptions
2025-04-22 20:54:39,241:INFO:Importing libraries
2025-04-22 20:54:39,241:INFO:Copying training dataset
2025-04-22 20:54:39,247:INFO:Defining folds
2025-04-22 20:54:39,248:INFO:Declaring metric variables
2025-04-22 20:54:39,248:INFO:Importing untrained model
2025-04-22 20:54:39,248:INFO:Declaring custom model
2025-04-22 20:54:39,248:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:39,248:INFO:Starting cross validation
2025-04-22 20:54:39,249:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:40,700:INFO:Calculating mean and std
2025-04-22 20:54:40,700:INFO:Creating metrics dataframe
2025-04-22 20:54:40,702:INFO:Finalizing model
2025-04-22 20:54:42,146:INFO:Uploading results into container
2025-04-22 20:54:42,146:INFO:Uploading model into container now
2025-04-22 20:54:42,147:INFO:_master_model_container: 62
2025-04-22 20:54:42,147:INFO:_display_container: 29
2025-04-22 20:54:42,147:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.484375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:42,147:INFO:create_model() successfully completed......................................
2025-04-22 20:54:42,356:INFO:Threshold: 0.484375. F1: 0.5327
2025-04-22 20:54:42,357:INFO:Initializing create_model()
2025-04-22 20:54:42,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.53125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:42,357:INFO:Checking exceptions
2025-04-22 20:54:42,359:INFO:Importing libraries
2025-04-22 20:54:42,362:INFO:Copying training dataset
2025-04-22 20:54:42,367:INFO:Defining folds
2025-04-22 20:54:42,367:INFO:Declaring metric variables
2025-04-22 20:54:42,367:INFO:Importing untrained model
2025-04-22 20:54:42,367:INFO:Declaring custom model
2025-04-22 20:54:42,368:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:42,368:INFO:Starting cross validation
2025-04-22 20:54:42,368:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:43,809:INFO:Calculating mean and std
2025-04-22 20:54:43,809:INFO:Creating metrics dataframe
2025-04-22 20:54:43,810:INFO:Finalizing model
2025-04-22 20:54:45,207:INFO:Uploading results into container
2025-04-22 20:54:45,208:INFO:Uploading model into container now
2025-04-22 20:54:45,208:INFO:_master_model_container: 63
2025-04-22 20:54:45,208:INFO:_display_container: 29
2025-04-22 20:54:45,209:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.53125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:45,210:INFO:create_model() successfully completed......................................
2025-04-22 20:54:45,421:INFO:Threshold: 0.53125. F1: 0.5254
2025-04-22 20:54:45,421:INFO:Initializing create_model()
2025-04-22 20:54:45,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.546875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:45,421:INFO:Checking exceptions
2025-04-22 20:54:45,422:INFO:Importing libraries
2025-04-22 20:54:45,422:INFO:Copying training dataset
2025-04-22 20:54:45,428:INFO:Defining folds
2025-04-22 20:54:45,428:INFO:Declaring metric variables
2025-04-22 20:54:45,428:INFO:Importing untrained model
2025-04-22 20:54:45,428:INFO:Declaring custom model
2025-04-22 20:54:45,429:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:45,429:INFO:Starting cross validation
2025-04-22 20:54:45,429:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:46,985:INFO:Calculating mean and std
2025-04-22 20:54:46,986:INFO:Creating metrics dataframe
2025-04-22 20:54:46,988:INFO:Finalizing model
2025-04-22 20:54:48,378:INFO:Uploading results into container
2025-04-22 20:54:48,379:INFO:Uploading model into container now
2025-04-22 20:54:48,379:INFO:_master_model_container: 64
2025-04-22 20:54:48,379:INFO:_display_container: 29
2025-04-22 20:54:48,380:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.546875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:48,380:INFO:create_model() successfully completed......................................
2025-04-22 20:54:48,602:INFO:Threshold: 0.546875. F1: 0.5229
2025-04-22 20:54:48,602:INFO:Initializing create_model()
2025-04-22 20:54:48,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:48,602:INFO:Checking exceptions
2025-04-22 20:54:48,603:INFO:Importing libraries
2025-04-22 20:54:48,603:INFO:Copying training dataset
2025-04-22 20:54:48,609:INFO:Defining folds
2025-04-22 20:54:48,609:INFO:Declaring metric variables
2025-04-22 20:54:48,609:INFO:Importing untrained model
2025-04-22 20:54:48,609:INFO:Declaring custom model
2025-04-22 20:54:48,610:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:48,610:INFO:Starting cross validation
2025-04-22 20:54:48,610:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:50,075:INFO:Calculating mean and std
2025-04-22 20:54:50,076:INFO:Creating metrics dataframe
2025-04-22 20:54:50,078:INFO:Finalizing model
2025-04-22 20:54:51,495:INFO:Uploading results into container
2025-04-22 20:54:51,496:INFO:Uploading model into container now
2025-04-22 20:54:51,496:INFO:_master_model_container: 65
2025-04-22 20:54:51,496:INFO:_display_container: 29
2025-04-22 20:54:51,497:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.609375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:51,497:INFO:create_model() successfully completed......................................
2025-04-22 20:54:51,706:INFO:Threshold: 0.609375. F1: 0.5313
2025-04-22 20:54:51,706:INFO:Initializing create_model()
2025-04-22 20:54:51,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.671875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:51,706:INFO:Checking exceptions
2025-04-22 20:54:51,707:INFO:Importing libraries
2025-04-22 20:54:51,707:INFO:Copying training dataset
2025-04-22 20:54:51,713:INFO:Defining folds
2025-04-22 20:54:51,713:INFO:Declaring metric variables
2025-04-22 20:54:51,713:INFO:Importing untrained model
2025-04-22 20:54:51,713:INFO:Declaring custom model
2025-04-22 20:54:51,714:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:51,714:INFO:Starting cross validation
2025-04-22 20:54:51,715:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:53,238:INFO:Calculating mean and std
2025-04-22 20:54:53,238:INFO:Creating metrics dataframe
2025-04-22 20:54:53,241:INFO:Finalizing model
2025-04-22 20:54:54,669:INFO:Uploading results into container
2025-04-22 20:54:54,669:INFO:Uploading model into container now
2025-04-22 20:54:54,669:INFO:_master_model_container: 66
2025-04-22 20:54:54,669:INFO:_display_container: 29
2025-04-22 20:54:54,670:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.671875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:54,670:INFO:create_model() successfully completed......................................
2025-04-22 20:54:54,883:INFO:Threshold: 0.671875. F1: 0.5189
2025-04-22 20:54:54,883:INFO:Initializing create_model()
2025-04-22 20:54:54,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.78125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:54,883:INFO:Checking exceptions
2025-04-22 20:54:54,884:INFO:Importing libraries
2025-04-22 20:54:54,884:INFO:Copying training dataset
2025-04-22 20:54:54,890:INFO:Defining folds
2025-04-22 20:54:54,890:INFO:Declaring metric variables
2025-04-22 20:54:54,890:INFO:Importing untrained model
2025-04-22 20:54:54,890:INFO:Declaring custom model
2025-04-22 20:54:54,891:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:54,891:INFO:Starting cross validation
2025-04-22 20:54:54,891:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:56,353:INFO:Calculating mean and std
2025-04-22 20:54:56,354:INFO:Creating metrics dataframe
2025-04-22 20:54:56,355:INFO:Finalizing model
2025-04-22 20:54:57,692:INFO:Uploading results into container
2025-04-22 20:54:57,692:INFO:Uploading model into container now
2025-04-22 20:54:57,692:INFO:_master_model_container: 67
2025-04-22 20:54:57,692:INFO:_display_container: 29
2025-04-22 20:54:57,693:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.78125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:54:57,693:INFO:create_model() successfully completed......................................
2025-04-22 20:54:57,901:INFO:Threshold: 0.78125. F1: 0.4288
2025-04-22 20:54:57,901:INFO:Initializing create_model()
2025-04-22 20:54:57,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.03125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:54:57,901:INFO:Checking exceptions
2025-04-22 20:54:57,902:INFO:Importing libraries
2025-04-22 20:54:57,902:INFO:Copying training dataset
2025-04-22 20:54:57,907:INFO:Defining folds
2025-04-22 20:54:57,907:INFO:Declaring metric variables
2025-04-22 20:54:57,908:INFO:Importing untrained model
2025-04-22 20:54:57,908:INFO:Declaring custom model
2025-04-22 20:54:57,908:INFO:Logistic Regression Imported successfully
2025-04-22 20:54:57,908:INFO:Starting cross validation
2025-04-22 20:54:57,909:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:54:59,044:INFO:Calculating mean and std
2025-04-22 20:54:59,044:INFO:Creating metrics dataframe
2025-04-22 20:54:59,046:INFO:Finalizing model
2025-04-22 20:55:00,376:INFO:Uploading results into container
2025-04-22 20:55:00,376:INFO:Uploading model into container now
2025-04-22 20:55:00,377:INFO:_master_model_container: 68
2025-04-22 20:55:00,377:INFO:_display_container: 29
2025-04-22 20:55:00,377:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.03125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:00,378:INFO:create_model() successfully completed......................................
2025-04-22 20:55:00,592:INFO:Threshold: 0.03125. F1: 0.3652
2025-04-22 20:55:00,592:INFO:Initializing create_model()
2025-04-22 20:55:00,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:00,592:INFO:Checking exceptions
2025-04-22 20:55:00,593:INFO:Importing libraries
2025-04-22 20:55:00,593:INFO:Copying training dataset
2025-04-22 20:55:00,599:INFO:Defining folds
2025-04-22 20:55:00,599:INFO:Declaring metric variables
2025-04-22 20:55:00,599:INFO:Importing untrained model
2025-04-22 20:55:00,599:INFO:Declaring custom model
2025-04-22 20:55:00,599:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:00,599:INFO:Starting cross validation
2025-04-22 20:55:00,600:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:01,723:INFO:Calculating mean and std
2025-04-22 20:55:01,723:INFO:Creating metrics dataframe
2025-04-22 20:55:01,725:INFO:Finalizing model
2025-04-22 20:55:03,106:INFO:Uploading results into container
2025-04-22 20:55:03,107:INFO:Uploading model into container now
2025-04-22 20:55:03,107:INFO:_master_model_container: 69
2025-04-22 20:55:03,107:INFO:_display_container: 29
2025-04-22 20:55:03,108:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.734375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:03,108:INFO:create_model() successfully completed......................................
2025-04-22 20:55:03,312:INFO:Threshold: 0.734375. F1: 0.4645
2025-04-22 20:55:03,312:INFO:Initializing create_model()
2025-04-22 20:55:03,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.65625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:03,312:INFO:Checking exceptions
2025-04-22 20:55:03,313:INFO:Importing libraries
2025-04-22 20:55:03,313:INFO:Copying training dataset
2025-04-22 20:55:03,318:INFO:Defining folds
2025-04-22 20:55:03,318:INFO:Declaring metric variables
2025-04-22 20:55:03,318:INFO:Importing untrained model
2025-04-22 20:55:03,318:INFO:Declaring custom model
2025-04-22 20:55:03,319:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:03,319:INFO:Starting cross validation
2025-04-22 20:55:03,320:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:04,434:INFO:Calculating mean and std
2025-04-22 20:55:04,434:INFO:Creating metrics dataframe
2025-04-22 20:55:04,435:INFO:Finalizing model
2025-04-22 20:55:05,762:INFO:Uploading results into container
2025-04-22 20:55:05,762:INFO:Uploading model into container now
2025-04-22 20:55:05,763:INFO:_master_model_container: 70
2025-04-22 20:55:05,763:INFO:_display_container: 29
2025-04-22 20:55:05,763:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.65625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:05,764:INFO:create_model() successfully completed......................................
2025-04-22 20:55:05,976:INFO:Threshold: 0.65625. F1: 0.5208
2025-04-22 20:55:05,976:INFO:Initializing create_model()
2025-04-22 20:55:05,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.796875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:05,977:INFO:Checking exceptions
2025-04-22 20:55:05,978:INFO:Importing libraries
2025-04-22 20:55:05,978:INFO:Copying training dataset
2025-04-22 20:55:05,983:INFO:Defining folds
2025-04-22 20:55:05,983:INFO:Declaring metric variables
2025-04-22 20:55:05,983:INFO:Importing untrained model
2025-04-22 20:55:05,983:INFO:Declaring custom model
2025-04-22 20:55:05,983:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:05,983:INFO:Starting cross validation
2025-04-22 20:55:05,984:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:07,104:INFO:Calculating mean and std
2025-04-22 20:55:07,104:INFO:Creating metrics dataframe
2025-04-22 20:55:07,106:INFO:Finalizing model
2025-04-22 20:55:08,439:INFO:Uploading results into container
2025-04-22 20:55:08,440:INFO:Uploading model into container now
2025-04-22 20:55:08,440:INFO:_master_model_container: 71
2025-04-22 20:55:08,440:INFO:_display_container: 29
2025-04-22 20:55:08,441:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.796875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:08,441:INFO:create_model() successfully completed......................................
2025-04-22 20:55:08,653:INFO:Threshold: 0.796875. F1: 0.4264
2025-04-22 20:55:08,653:INFO:Initializing create_model()
2025-04-22 20:55:08,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:08,653:INFO:Checking exceptions
2025-04-22 20:55:08,654:INFO:Importing libraries
2025-04-22 20:55:08,654:INFO:Copying training dataset
2025-04-22 20:55:08,659:INFO:Defining folds
2025-04-22 20:55:08,659:INFO:Declaring metric variables
2025-04-22 20:55:08,659:INFO:Importing untrained model
2025-04-22 20:55:08,659:INFO:Declaring custom model
2025-04-22 20:55:08,660:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:08,660:INFO:Starting cross validation
2025-04-22 20:55:08,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:09,790:INFO:Calculating mean and std
2025-04-22 20:55:09,790:INFO:Creating metrics dataframe
2025-04-22 20:55:09,791:INFO:Finalizing model
2025-04-22 20:55:11,114:INFO:Uploading results into container
2025-04-22 20:55:11,115:INFO:Uploading model into container now
2025-04-22 20:55:11,115:INFO:_master_model_container: 72
2025-04-22 20:55:11,115:INFO:_display_container: 29
2025-04-22 20:55:11,116:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.859375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:11,116:INFO:create_model() successfully completed......................................
2025-04-22 20:55:11,327:INFO:Threshold: 0.859375. F1: 0.3101
2025-04-22 20:55:11,327:INFO:Initializing create_model()
2025-04-22 20:55:11,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.90625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:11,327:INFO:Checking exceptions
2025-04-22 20:55:11,328:INFO:Importing libraries
2025-04-22 20:55:11,328:INFO:Copying training dataset
2025-04-22 20:55:11,333:INFO:Defining folds
2025-04-22 20:55:11,333:INFO:Declaring metric variables
2025-04-22 20:55:11,333:INFO:Importing untrained model
2025-04-22 20:55:11,333:INFO:Declaring custom model
2025-04-22 20:55:11,334:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:11,334:INFO:Starting cross validation
2025-04-22 20:55:11,334:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:12,448:INFO:Calculating mean and std
2025-04-22 20:55:12,449:INFO:Creating metrics dataframe
2025-04-22 20:55:12,450:INFO:Finalizing model
2025-04-22 20:55:13,789:INFO:Uploading results into container
2025-04-22 20:55:13,790:INFO:Uploading model into container now
2025-04-22 20:55:13,790:INFO:_master_model_container: 73
2025-04-22 20:55:13,790:INFO:_display_container: 29
2025-04-22 20:55:13,791:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.90625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:13,791:INFO:create_model() successfully completed......................................
2025-04-22 20:55:14,002:INFO:Threshold: 0.90625. F1: 0.1042
2025-04-22 20:55:14,003:INFO:Initializing create_model()
2025-04-22 20:55:14,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.921875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:14,003:INFO:Checking exceptions
2025-04-22 20:55:14,004:INFO:Importing libraries
2025-04-22 20:55:14,004:INFO:Copying training dataset
2025-04-22 20:55:14,009:INFO:Defining folds
2025-04-22 20:55:14,009:INFO:Declaring metric variables
2025-04-22 20:55:14,009:INFO:Importing untrained model
2025-04-22 20:55:14,009:INFO:Declaring custom model
2025-04-22 20:55:14,009:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:14,009:INFO:Starting cross validation
2025-04-22 20:55:14,010:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:15,109:INFO:Calculating mean and std
2025-04-22 20:55:15,110:INFO:Creating metrics dataframe
2025-04-22 20:55:15,111:INFO:Finalizing model
2025-04-22 20:55:16,429:INFO:Uploading results into container
2025-04-22 20:55:16,429:INFO:Uploading model into container now
2025-04-22 20:55:16,429:INFO:_master_model_container: 74
2025-04-22 20:55:16,429:INFO:_display_container: 29
2025-04-22 20:55:16,430:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.921875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:16,430:INFO:create_model() successfully completed......................................
2025-04-22 20:55:16,647:INFO:Threshold: 0.921875. F1: 0.0546
2025-04-22 20:55:16,647:INFO:Initializing create_model()
2025-04-22 20:55:16,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:16,647:INFO:Checking exceptions
2025-04-22 20:55:16,648:INFO:Importing libraries
2025-04-22 20:55:16,648:INFO:Copying training dataset
2025-04-22 20:55:16,654:INFO:Defining folds
2025-04-22 20:55:16,654:INFO:Declaring metric variables
2025-04-22 20:55:16,654:INFO:Importing untrained model
2025-04-22 20:55:16,654:INFO:Declaring custom model
2025-04-22 20:55:16,654:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:16,654:INFO:Starting cross validation
2025-04-22 20:55:16,655:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:17,715:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:55:17,738:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:55:17,759:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:55:17,760:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:55:17,773:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-22 20:55:17,785:INFO:Calculating mean and std
2025-04-22 20:55:17,786:INFO:Creating metrics dataframe
2025-04-22 20:55:17,787:INFO:Finalizing model
2025-04-22 20:55:19,108:INFO:Uploading results into container
2025-04-22 20:55:19,108:INFO:Uploading model into container now
2025-04-22 20:55:19,108:INFO:_master_model_container: 75
2025-04-22 20:55:19,108:INFO:_display_container: 29
2025-04-22 20:55:19,109:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.984375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:19,109:INFO:create_model() successfully completed......................................
2025-04-22 20:55:19,317:INFO:Threshold: 0.984375. F1: 0.0
2025-04-22 20:55:19,317:INFO:Initializing create_model()
2025-04-22 20:55:19,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.15625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:19,318:INFO:Checking exceptions
2025-04-22 20:55:19,319:INFO:Importing libraries
2025-04-22 20:55:19,319:INFO:Copying training dataset
2025-04-22 20:55:19,324:INFO:Defining folds
2025-04-22 20:55:19,324:INFO:Declaring metric variables
2025-04-22 20:55:19,324:INFO:Importing untrained model
2025-04-22 20:55:19,324:INFO:Declaring custom model
2025-04-22 20:55:19,324:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:19,325:INFO:Starting cross validation
2025-04-22 20:55:19,325:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:20,427:INFO:Calculating mean and std
2025-04-22 20:55:20,427:INFO:Creating metrics dataframe
2025-04-22 20:55:20,428:INFO:Finalizing model
2025-04-22 20:55:21,749:INFO:Uploading results into container
2025-04-22 20:55:21,749:INFO:Uploading model into container now
2025-04-22 20:55:21,750:INFO:_master_model_container: 76
2025-04-22 20:55:21,750:INFO:_display_container: 29
2025-04-22 20:55:21,750:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.15625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:21,750:INFO:create_model() successfully completed......................................
2025-04-22 20:55:21,962:INFO:Threshold: 0.15625. F1: 0.3652
2025-04-22 20:55:21,963:INFO:Initializing create_model()
2025-04-22 20:55:21,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.046875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:21,963:INFO:Checking exceptions
2025-04-22 20:55:21,964:INFO:Importing libraries
2025-04-22 20:55:21,964:INFO:Copying training dataset
2025-04-22 20:55:21,969:INFO:Defining folds
2025-04-22 20:55:21,969:INFO:Declaring metric variables
2025-04-22 20:55:21,969:INFO:Importing untrained model
2025-04-22 20:55:21,969:INFO:Declaring custom model
2025-04-22 20:55:21,970:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:21,970:INFO:Starting cross validation
2025-04-22 20:55:21,971:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:23,099:INFO:Calculating mean and std
2025-04-22 20:55:23,099:INFO:Creating metrics dataframe
2025-04-22 20:55:23,100:INFO:Finalizing model
2025-04-22 20:55:24,426:INFO:Uploading results into container
2025-04-22 20:55:24,427:INFO:Uploading model into container now
2025-04-22 20:55:24,427:INFO:_master_model_container: 77
2025-04-22 20:55:24,427:INFO:_display_container: 29
2025-04-22 20:55:24,428:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.046875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:24,428:INFO:create_model() successfully completed......................................
2025-04-22 20:55:24,635:INFO:Threshold: 0.046875. F1: 0.3652
2025-04-22 20:55:24,635:INFO:Initializing create_model()
2025-04-22 20:55:24,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.171875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:24,635:INFO:Checking exceptions
2025-04-22 20:55:24,636:INFO:Importing libraries
2025-04-22 20:55:24,636:INFO:Copying training dataset
2025-04-22 20:55:24,642:INFO:Defining folds
2025-04-22 20:55:24,642:INFO:Declaring metric variables
2025-04-22 20:55:24,642:INFO:Importing untrained model
2025-04-22 20:55:24,642:INFO:Declaring custom model
2025-04-22 20:55:24,642:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:24,642:INFO:Starting cross validation
2025-04-22 20:55:24,643:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:25,767:INFO:Calculating mean and std
2025-04-22 20:55:25,768:INFO:Creating metrics dataframe
2025-04-22 20:55:25,769:INFO:Finalizing model
2025-04-22 20:55:27,101:INFO:Uploading results into container
2025-04-22 20:55:27,101:INFO:Uploading model into container now
2025-04-22 20:55:27,101:INFO:_master_model_container: 78
2025-04-22 20:55:27,101:INFO:_display_container: 29
2025-04-22 20:55:27,102:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.171875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:27,102:INFO:create_model() successfully completed......................................
2025-04-22 20:55:27,308:INFO:Threshold: 0.171875. F1: 0.3652
2025-04-22 20:55:27,309:INFO:Initializing create_model()
2025-04-22 20:55:27,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:27,309:INFO:Checking exceptions
2025-04-22 20:55:27,310:INFO:Importing libraries
2025-04-22 20:55:27,310:INFO:Copying training dataset
2025-04-22 20:55:27,316:INFO:Defining folds
2025-04-22 20:55:27,316:INFO:Declaring metric variables
2025-04-22 20:55:27,316:INFO:Importing untrained model
2025-04-22 20:55:27,316:INFO:Declaring custom model
2025-04-22 20:55:27,317:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:27,317:INFO:Starting cross validation
2025-04-22 20:55:27,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:28,425:INFO:Calculating mean and std
2025-04-22 20:55:28,425:INFO:Creating metrics dataframe
2025-04-22 20:55:28,426:INFO:Finalizing model
2025-04-22 20:55:29,762:INFO:Uploading results into container
2025-04-22 20:55:29,763:INFO:Uploading model into container now
2025-04-22 20:55:29,763:INFO:_master_model_container: 79
2025-04-22 20:55:29,763:INFO:_display_container: 29
2025-04-22 20:55:29,764:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.109375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:29,764:INFO:create_model() successfully completed......................................
2025-04-22 20:55:29,974:INFO:Threshold: 0.109375. F1: 0.3652
2025-04-22 20:55:29,975:INFO:Initializing create_model()
2025-04-22 20:55:29,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:29,975:INFO:Checking exceptions
2025-04-22 20:55:29,976:INFO:Importing libraries
2025-04-22 20:55:29,976:INFO:Copying training dataset
2025-04-22 20:55:29,981:INFO:Defining folds
2025-04-22 20:55:29,981:INFO:Declaring metric variables
2025-04-22 20:55:29,981:INFO:Importing untrained model
2025-04-22 20:55:29,981:INFO:Declaring custom model
2025-04-22 20:55:29,982:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:29,982:INFO:Starting cross validation
2025-04-22 20:55:29,982:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:31,121:INFO:Calculating mean and std
2025-04-22 20:55:31,121:INFO:Creating metrics dataframe
2025-04-22 20:55:31,123:INFO:Finalizing model
2025-04-22 20:55:32,429:INFO:Uploading results into container
2025-04-22 20:55:32,429:INFO:Uploading model into container now
2025-04-22 20:55:32,430:INFO:_master_model_container: 80
2025-04-22 20:55:32,430:INFO:_display_container: 29
2025-04-22 20:55:32,430:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.234375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:32,430:INFO:create_model() successfully completed......................................
2025-04-22 20:55:32,651:INFO:Threshold: 0.234375. F1: 0.366
2025-04-22 20:55:32,651:INFO:Initializing create_model()
2025-04-22 20:55:32,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.28125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:32,651:INFO:Checking exceptions
2025-04-22 20:55:32,652:INFO:Importing libraries
2025-04-22 20:55:32,652:INFO:Copying training dataset
2025-04-22 20:55:32,658:INFO:Defining folds
2025-04-22 20:55:32,658:INFO:Declaring metric variables
2025-04-22 20:55:32,658:INFO:Importing untrained model
2025-04-22 20:55:32,658:INFO:Declaring custom model
2025-04-22 20:55:32,658:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:32,659:INFO:Starting cross validation
2025-04-22 20:55:32,659:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:33,759:INFO:Calculating mean and std
2025-04-22 20:55:33,759:INFO:Creating metrics dataframe
2025-04-22 20:55:33,761:INFO:Finalizing model
2025-04-22 20:55:35,088:INFO:Uploading results into container
2025-04-22 20:55:35,089:INFO:Uploading model into container now
2025-04-22 20:55:35,089:INFO:_master_model_container: 81
2025-04-22 20:55:35,089:INFO:_display_container: 29
2025-04-22 20:55:35,090:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.28125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:35,090:INFO:create_model() successfully completed......................................
2025-04-22 20:55:35,300:INFO:Threshold: 0.28125. F1: 0.3724
2025-04-22 20:55:35,301:INFO:Initializing create_model()
2025-04-22 20:55:35,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.296875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:35,301:INFO:Checking exceptions
2025-04-22 20:55:35,302:INFO:Importing libraries
2025-04-22 20:55:35,302:INFO:Copying training dataset
2025-04-22 20:55:35,307:INFO:Defining folds
2025-04-22 20:55:35,307:INFO:Declaring metric variables
2025-04-22 20:55:35,308:INFO:Importing untrained model
2025-04-22 20:55:35,308:INFO:Declaring custom model
2025-04-22 20:55:35,308:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:35,308:INFO:Starting cross validation
2025-04-22 20:55:35,309:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:36,460:INFO:Calculating mean and std
2025-04-22 20:55:36,461:INFO:Creating metrics dataframe
2025-04-22 20:55:36,462:INFO:Finalizing model
2025-04-22 20:55:37,794:INFO:Uploading results into container
2025-04-22 20:55:37,795:INFO:Uploading model into container now
2025-04-22 20:55:37,795:INFO:_master_model_container: 82
2025-04-22 20:55:37,795:INFO:_display_container: 29
2025-04-22 20:55:37,796:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.296875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:37,796:INFO:create_model() successfully completed......................................
2025-04-22 20:55:38,009:INFO:Threshold: 0.296875. F1: 0.3728
2025-04-22 20:55:38,010:INFO:Initializing create_model()
2025-04-22 20:55:38,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:38,010:INFO:Checking exceptions
2025-04-22 20:55:38,011:INFO:Importing libraries
2025-04-22 20:55:38,011:INFO:Copying training dataset
2025-04-22 20:55:38,016:INFO:Defining folds
2025-04-22 20:55:38,016:INFO:Declaring metric variables
2025-04-22 20:55:38,016:INFO:Importing untrained model
2025-04-22 20:55:38,017:INFO:Declaring custom model
2025-04-22 20:55:38,017:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:38,017:INFO:Starting cross validation
2025-04-22 20:55:38,018:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:39,155:INFO:Calculating mean and std
2025-04-22 20:55:39,156:INFO:Creating metrics dataframe
2025-04-22 20:55:39,157:INFO:Finalizing model
2025-04-22 20:55:40,509:INFO:Uploading results into container
2025-04-22 20:55:40,509:INFO:Uploading model into container now
2025-04-22 20:55:40,509:INFO:_master_model_container: 83
2025-04-22 20:55:40,510:INFO:_display_container: 29
2025-04-22 20:55:40,510:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.359375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:40,510:INFO:create_model() successfully completed......................................
2025-04-22 20:55:40,725:INFO:Threshold: 0.359375. F1: 0.4935
2025-04-22 20:55:40,726:INFO:Initializing create_model()
2025-04-22 20:55:40,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.40625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:40,726:INFO:Checking exceptions
2025-04-22 20:55:40,727:INFO:Importing libraries
2025-04-22 20:55:40,727:INFO:Copying training dataset
2025-04-22 20:55:40,732:INFO:Defining folds
2025-04-22 20:55:40,732:INFO:Declaring metric variables
2025-04-22 20:55:40,732:INFO:Importing untrained model
2025-04-22 20:55:40,732:INFO:Declaring custom model
2025-04-22 20:55:40,732:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:40,732:INFO:Starting cross validation
2025-04-22 20:55:40,733:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:41,912:INFO:Calculating mean and std
2025-04-22 20:55:41,912:INFO:Creating metrics dataframe
2025-04-22 20:55:41,913:INFO:Finalizing model
2025-04-22 20:55:43,272:INFO:Uploading results into container
2025-04-22 20:55:43,272:INFO:Uploading model into container now
2025-04-22 20:55:43,273:INFO:_master_model_container: 84
2025-04-22 20:55:43,273:INFO:_display_container: 29
2025-04-22 20:55:43,273:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.40625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:43,274:INFO:create_model() successfully completed......................................
2025-04-22 20:55:43,485:INFO:Threshold: 0.40625. F1: 0.5153
2025-04-22 20:55:43,485:INFO:Initializing create_model()
2025-04-22 20:55:43,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.421875, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:43,485:INFO:Checking exceptions
2025-04-22 20:55:43,486:INFO:Importing libraries
2025-04-22 20:55:43,486:INFO:Copying training dataset
2025-04-22 20:55:43,491:INFO:Defining folds
2025-04-22 20:55:43,491:INFO:Declaring metric variables
2025-04-22 20:55:43,491:INFO:Importing untrained model
2025-04-22 20:55:43,491:INFO:Declaring custom model
2025-04-22 20:55:43,491:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:43,492:INFO:Starting cross validation
2025-04-22 20:55:43,492:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:44,587:INFO:Calculating mean and std
2025-04-22 20:55:44,587:INFO:Creating metrics dataframe
2025-04-22 20:55:44,588:INFO:Finalizing model
2025-04-22 20:55:45,926:INFO:Uploading results into container
2025-04-22 20:55:45,926:INFO:Uploading model into container now
2025-04-22 20:55:45,927:INFO:_master_model_container: 85
2025-04-22 20:55:45,927:INFO:_display_container: 29
2025-04-22 20:55:45,927:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.421875,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:45,927:INFO:create_model() successfully completed......................................
2025-04-22 20:55:46,136:INFO:Threshold: 0.421875. F1: 0.5158
2025-04-22 20:55:46,138:INFO:Initializing create_model()
2025-04-22 20:55:46,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:46,138:INFO:Checking exceptions
2025-04-22 20:55:46,139:INFO:Importing libraries
2025-04-22 20:55:46,139:INFO:Copying training dataset
2025-04-22 20:55:46,144:INFO:Defining folds
2025-04-22 20:55:46,144:INFO:Declaring metric variables
2025-04-22 20:55:46,144:INFO:Importing untrained model
2025-04-22 20:55:46,144:INFO:Declaring custom model
2025-04-22 20:55:46,145:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:46,145:INFO:Starting cross validation
2025-04-22 20:55:46,146:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:47,282:INFO:Calculating mean and std
2025-04-22 20:55:47,283:INFO:Creating metrics dataframe
2025-04-22 20:55:47,284:INFO:Finalizing model
2025-04-22 20:55:48,641:INFO:Uploading results into container
2025-04-22 20:55:48,641:INFO:Uploading model into container now
2025-04-22 20:55:48,641:INFO:_master_model_container: 86
2025-04-22 20:55:48,641:INFO:_display_container: 29
2025-04-22 20:55:48,642:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.609375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:48,642:INFO:create_model() successfully completed......................................
2025-04-22 20:55:48,864:INFO:Threshold: 0.609375. F1: 0.5313
2025-04-22 20:55:48,864:INFO:Initializing create_model()
2025-04-22 20:55:48,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6093750149011612, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:48,864:INFO:Checking exceptions
2025-04-22 20:55:48,865:INFO:Importing libraries
2025-04-22 20:55:48,865:INFO:Copying training dataset
2025-04-22 20:55:48,871:INFO:Defining folds
2025-04-22 20:55:48,871:INFO:Declaring metric variables
2025-04-22 20:55:48,871:INFO:Importing untrained model
2025-04-22 20:55:48,871:INFO:Declaring custom model
2025-04-22 20:55:48,872:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:48,872:INFO:Starting cross validation
2025-04-22 20:55:48,872:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:49,993:INFO:Calculating mean and std
2025-04-22 20:55:49,993:INFO:Creating metrics dataframe
2025-04-22 20:55:49,995:INFO:Finalizing model
2025-04-22 20:55:51,340:INFO:Uploading results into container
2025-04-22 20:55:51,342:INFO:Uploading model into container now
2025-04-22 20:55:51,342:INFO:_master_model_container: 87
2025-04-22 20:55:51,342:INFO:_display_container: 29
2025-04-22 20:55:51,343:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.6093750149011612,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:51,343:INFO:create_model() successfully completed......................................
2025-04-22 20:55:51,552:INFO:Threshold: 0.6093750149011612. F1: 0.5313
2025-04-22 20:55:51,554:INFO:Initializing create_model()
2025-04-22 20:55:51,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.765625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:51,554:INFO:Checking exceptions
2025-04-22 20:55:51,555:INFO:Importing libraries
2025-04-22 20:55:51,555:INFO:Copying training dataset
2025-04-22 20:55:51,560:INFO:Defining folds
2025-04-22 20:55:51,561:INFO:Declaring metric variables
2025-04-22 20:55:51,561:INFO:Importing untrained model
2025-04-22 20:55:51,561:INFO:Declaring custom model
2025-04-22 20:55:51,561:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:51,561:INFO:Starting cross validation
2025-04-22 20:55:51,562:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:52,675:INFO:Calculating mean and std
2025-04-22 20:55:52,676:INFO:Creating metrics dataframe
2025-04-22 20:55:52,677:INFO:Finalizing model
2025-04-22 20:55:54,019:INFO:Uploading results into container
2025-04-22 20:55:54,019:INFO:Uploading model into container now
2025-04-22 20:55:54,019:INFO:_master_model_container: 88
2025-04-22 20:55:54,019:INFO:_display_container: 29
2025-04-22 20:55:54,020:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.765625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:54,020:INFO:create_model() successfully completed......................................
2025-04-22 20:55:54,235:INFO:Threshold: 0.765625. F1: 0.4441
2025-04-22 20:55:54,235:INFO:Initializing create_model()
2025-04-22 20:55:54,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.828125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:54,235:INFO:Checking exceptions
2025-04-22 20:55:54,236:INFO:Importing libraries
2025-04-22 20:55:54,236:INFO:Copying training dataset
2025-04-22 20:55:54,242:INFO:Defining folds
2025-04-22 20:55:54,242:INFO:Declaring metric variables
2025-04-22 20:55:54,243:INFO:Importing untrained model
2025-04-22 20:55:54,243:INFO:Declaring custom model
2025-04-22 20:55:54,243:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:54,243:INFO:Starting cross validation
2025-04-22 20:55:54,244:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:55,421:INFO:Calculating mean and std
2025-04-22 20:55:55,422:INFO:Creating metrics dataframe
2025-04-22 20:55:55,423:INFO:Finalizing model
2025-04-22 20:55:56,764:INFO:Uploading results into container
2025-04-22 20:55:56,764:INFO:Uploading model into container now
2025-04-22 20:55:56,764:INFO:_master_model_container: 89
2025-04-22 20:55:56,764:INFO:_display_container: 29
2025-04-22 20:55:56,766:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.828125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:56,766:INFO:create_model() successfully completed......................................
2025-04-22 20:55:56,982:INFO:Threshold: 0.828125. F1: 0.377
2025-04-22 20:55:56,982:INFO:Initializing create_model()
2025-04-22 20:55:56,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.890625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:56,982:INFO:Checking exceptions
2025-04-22 20:55:56,983:INFO:Importing libraries
2025-04-22 20:55:56,983:INFO:Copying training dataset
2025-04-22 20:55:56,988:INFO:Defining folds
2025-04-22 20:55:56,989:INFO:Declaring metric variables
2025-04-22 20:55:56,989:INFO:Importing untrained model
2025-04-22 20:55:56,989:INFO:Declaring custom model
2025-04-22 20:55:56,989:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:56,989:INFO:Starting cross validation
2025-04-22 20:55:56,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:55:58,114:INFO:Calculating mean and std
2025-04-22 20:55:58,114:INFO:Creating metrics dataframe
2025-04-22 20:55:58,115:INFO:Finalizing model
2025-04-22 20:55:59,458:INFO:Uploading results into container
2025-04-22 20:55:59,458:INFO:Uploading model into container now
2025-04-22 20:55:59,458:INFO:_master_model_container: 90
2025-04-22 20:55:59,458:INFO:_display_container: 29
2025-04-22 20:55:59,459:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.890625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:55:59,459:INFO:create_model() successfully completed......................................
2025-04-22 20:55:59,671:INFO:Threshold: 0.890625. F1: 0.2353
2025-04-22 20:55:59,672:INFO:Initializing create_model()
2025-04-22 20:55:59,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.953125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:55:59,672:INFO:Checking exceptions
2025-04-22 20:55:59,672:INFO:Importing libraries
2025-04-22 20:55:59,673:INFO:Copying training dataset
2025-04-22 20:55:59,678:INFO:Defining folds
2025-04-22 20:55:59,678:INFO:Declaring metric variables
2025-04-22 20:55:59,678:INFO:Importing untrained model
2025-04-22 20:55:59,678:INFO:Declaring custom model
2025-04-22 20:55:59,679:INFO:Logistic Regression Imported successfully
2025-04-22 20:55:59,679:INFO:Starting cross validation
2025-04-22 20:55:59,679:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:00,841:INFO:Calculating mean and std
2025-04-22 20:56:00,841:INFO:Creating metrics dataframe
2025-04-22 20:56:00,843:INFO:Finalizing model
2025-04-22 20:56:02,187:INFO:Uploading results into container
2025-04-22 20:56:02,188:INFO:Uploading model into container now
2025-04-22 20:56:02,188:INFO:_master_model_container: 91
2025-04-22 20:56:02,188:INFO:_display_container: 29
2025-04-22 20:56:02,189:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.953125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:02,189:INFO:create_model() successfully completed......................................
2025-04-22 20:56:02,402:INFO:Threshold: 0.953125. F1: 0.0091
2025-04-22 20:56:02,402:INFO:Initializing create_model()
2025-04-22 20:56:02,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:02,402:INFO:Checking exceptions
2025-04-22 20:56:02,403:INFO:Importing libraries
2025-04-22 20:56:02,403:INFO:Copying training dataset
2025-04-22 20:56:02,408:INFO:Defining folds
2025-04-22 20:56:02,408:INFO:Declaring metric variables
2025-04-22 20:56:02,408:INFO:Importing untrained model
2025-04-22 20:56:02,408:INFO:Declaring custom model
2025-04-22 20:56:02,409:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:02,409:INFO:Starting cross validation
2025-04-22 20:56:02,409:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:03,525:INFO:Calculating mean and std
2025-04-22 20:56:03,525:INFO:Creating metrics dataframe
2025-04-22 20:56:03,526:INFO:Finalizing model
2025-04-22 20:56:04,871:INFO:Uploading results into container
2025-04-22 20:56:04,872:INFO:Uploading model into container now
2025-04-22 20:56:04,872:INFO:_master_model_container: 92
2025-04-22 20:56:04,872:INFO:_display_container: 29
2025-04-22 20:56:04,873:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.3359375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:04,873:INFO:create_model() successfully completed......................................
2025-04-22 20:56:05,080:INFO:Threshold: 0.3359375. F1: 0.4934
2025-04-22 20:56:05,080:INFO:Initializing create_model()
2025-04-22 20:56:05,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.390625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:05,080:INFO:Checking exceptions
2025-04-22 20:56:05,081:INFO:Importing libraries
2025-04-22 20:56:05,081:INFO:Copying training dataset
2025-04-22 20:56:05,087:INFO:Defining folds
2025-04-22 20:56:05,087:INFO:Declaring metric variables
2025-04-22 20:56:05,087:INFO:Importing untrained model
2025-04-22 20:56:05,087:INFO:Declaring custom model
2025-04-22 20:56:05,087:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:05,087:INFO:Starting cross validation
2025-04-22 20:56:05,088:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:06,233:INFO:Calculating mean and std
2025-04-22 20:56:06,234:INFO:Creating metrics dataframe
2025-04-22 20:56:06,235:INFO:Finalizing model
2025-04-22 20:56:07,577:INFO:Uploading results into container
2025-04-22 20:56:07,577:INFO:Uploading model into container now
2025-04-22 20:56:07,577:INFO:_master_model_container: 93
2025-04-22 20:56:07,577:INFO:_display_container: 29
2025-04-22 20:56:07,578:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.390625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:07,578:INFO:create_model() successfully completed......................................
2025-04-22 20:56:07,787:INFO:Threshold: 0.390625. F1: 0.5147
2025-04-22 20:56:07,788:INFO:Initializing create_model()
2025-04-22 20:56:07,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.3984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:07,788:INFO:Checking exceptions
2025-04-22 20:56:07,789:INFO:Importing libraries
2025-04-22 20:56:07,789:INFO:Copying training dataset
2025-04-22 20:56:07,795:INFO:Defining folds
2025-04-22 20:56:07,795:INFO:Declaring metric variables
2025-04-22 20:56:07,795:INFO:Importing untrained model
2025-04-22 20:56:07,795:INFO:Declaring custom model
2025-04-22 20:56:07,795:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:07,795:INFO:Starting cross validation
2025-04-22 20:56:07,797:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:08,952:INFO:Calculating mean and std
2025-04-22 20:56:08,952:INFO:Creating metrics dataframe
2025-04-22 20:56:08,953:INFO:Finalizing model
2025-04-22 20:56:10,292:INFO:Uploading results into container
2025-04-22 20:56:10,292:INFO:Uploading model into container now
2025-04-22 20:56:10,292:INFO:_master_model_container: 94
2025-04-22 20:56:10,292:INFO:_display_container: 29
2025-04-22 20:56:10,293:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.3984375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:10,293:INFO:create_model() successfully completed......................................
2025-04-22 20:56:10,500:INFO:Threshold: 0.3984375. F1: 0.5152
2025-04-22 20:56:10,501:INFO:Initializing create_model()
2025-04-22 20:56:10,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.453125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:10,501:INFO:Checking exceptions
2025-04-22 20:56:10,502:INFO:Importing libraries
2025-04-22 20:56:10,502:INFO:Copying training dataset
2025-04-22 20:56:10,507:INFO:Defining folds
2025-04-22 20:56:10,507:INFO:Declaring metric variables
2025-04-22 20:56:10,507:INFO:Importing untrained model
2025-04-22 20:56:10,507:INFO:Declaring custom model
2025-04-22 20:56:10,508:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:10,508:INFO:Starting cross validation
2025-04-22 20:56:10,508:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:11,668:INFO:Calculating mean and std
2025-04-22 20:56:11,669:INFO:Creating metrics dataframe
2025-04-22 20:56:11,670:INFO:Finalizing model
2025-04-22 20:56:13,014:INFO:Uploading results into container
2025-04-22 20:56:13,015:INFO:Uploading model into container now
2025-04-22 20:56:13,015:INFO:_master_model_container: 95
2025-04-22 20:56:13,015:INFO:_display_container: 29
2025-04-22 20:56:13,016:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.453125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:13,016:INFO:create_model() successfully completed......................................
2025-04-22 20:56:13,223:INFO:Threshold: 0.453125. F1: 0.5245
2025-04-22 20:56:13,223:INFO:Initializing create_model()
2025-04-22 20:56:13,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.515625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:13,223:INFO:Checking exceptions
2025-04-22 20:56:13,224:INFO:Importing libraries
2025-04-22 20:56:13,224:INFO:Copying training dataset
2025-04-22 20:56:13,230:INFO:Defining folds
2025-04-22 20:56:13,230:INFO:Declaring metric variables
2025-04-22 20:56:13,230:INFO:Importing untrained model
2025-04-22 20:56:13,230:INFO:Declaring custom model
2025-04-22 20:56:13,231:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:13,231:INFO:Starting cross validation
2025-04-22 20:56:13,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:14,351:INFO:Calculating mean and std
2025-04-22 20:56:14,351:INFO:Creating metrics dataframe
2025-04-22 20:56:14,352:INFO:Finalizing model
2025-04-22 20:56:15,703:INFO:Uploading results into container
2025-04-22 20:56:15,704:INFO:Uploading model into container now
2025-04-22 20:56:15,704:INFO:_master_model_container: 96
2025-04-22 20:56:15,704:INFO:_display_container: 29
2025-04-22 20:56:15,705:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.515625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:15,705:INFO:create_model() successfully completed......................................
2025-04-22 20:56:15,913:INFO:Threshold: 0.515625. F1: 0.5313
2025-04-22 20:56:15,913:INFO:Initializing create_model()
2025-04-22 20:56:15,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.578125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:15,914:INFO:Checking exceptions
2025-04-22 20:56:15,915:INFO:Importing libraries
2025-04-22 20:56:15,915:INFO:Copying training dataset
2025-04-22 20:56:15,920:INFO:Defining folds
2025-04-22 20:56:15,920:INFO:Declaring metric variables
2025-04-22 20:56:15,920:INFO:Importing untrained model
2025-04-22 20:56:15,920:INFO:Declaring custom model
2025-04-22 20:56:15,920:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:15,920:INFO:Starting cross validation
2025-04-22 20:56:15,921:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:17,080:INFO:Calculating mean and std
2025-04-22 20:56:17,080:INFO:Creating metrics dataframe
2025-04-22 20:56:17,082:INFO:Finalizing model
2025-04-22 20:56:18,448:INFO:Uploading results into container
2025-04-22 20:56:18,449:INFO:Uploading model into container now
2025-04-22 20:56:18,449:INFO:_master_model_container: 97
2025-04-22 20:56:18,449:INFO:_display_container: 29
2025-04-22 20:56:18,450:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.578125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:18,450:INFO:create_model() successfully completed......................................
2025-04-22 20:56:18,662:INFO:Threshold: 0.578125. F1: 0.5289
2025-04-22 20:56:18,662:INFO:Initializing create_model()
2025-04-22 20:56:18,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.015625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:18,662:INFO:Checking exceptions
2025-04-22 20:56:18,663:INFO:Importing libraries
2025-04-22 20:56:18,664:INFO:Copying training dataset
2025-04-22 20:56:18,669:INFO:Defining folds
2025-04-22 20:56:18,669:INFO:Declaring metric variables
2025-04-22 20:56:18,669:INFO:Importing untrained model
2025-04-22 20:56:18,669:INFO:Declaring custom model
2025-04-22 20:56:18,669:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:18,670:INFO:Starting cross validation
2025-04-22 20:56:18,670:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:19,788:INFO:Calculating mean and std
2025-04-22 20:56:19,788:INFO:Creating metrics dataframe
2025-04-22 20:56:19,790:INFO:Finalizing model
2025-04-22 20:56:21,140:INFO:Uploading results into container
2025-04-22 20:56:21,141:INFO:Uploading model into container now
2025-04-22 20:56:21,141:INFO:_master_model_container: 98
2025-04-22 20:56:21,141:INFO:_display_container: 29
2025-04-22 20:56:21,142:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.015625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:21,142:INFO:create_model() successfully completed......................................
2025-04-22 20:56:21,352:INFO:Threshold: 0.015625. F1: 0.3652
2025-04-22 20:56:21,352:INFO:Initializing create_model()
2025-04-22 20:56:21,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:21,352:INFO:Checking exceptions
2025-04-22 20:56:21,353:INFO:Importing libraries
2025-04-22 20:56:21,353:INFO:Copying training dataset
2025-04-22 20:56:21,358:INFO:Defining folds
2025-04-22 20:56:21,358:INFO:Declaring metric variables
2025-04-22 20:56:21,358:INFO:Importing untrained model
2025-04-22 20:56:21,359:INFO:Declaring custom model
2025-04-22 20:56:21,359:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:21,359:INFO:Starting cross validation
2025-04-22 20:56:21,360:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:22,489:INFO:Calculating mean and std
2025-04-22 20:56:22,490:INFO:Creating metrics dataframe
2025-04-22 20:56:22,491:INFO:Finalizing model
2025-04-22 20:56:23,834:INFO:Uploading results into container
2025-04-22 20:56:23,835:INFO:Uploading model into container now
2025-04-22 20:56:23,835:INFO:_master_model_container: 99
2025-04-22 20:56:23,835:INFO:_display_container: 29
2025-04-22 20:56:23,836:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5234375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:23,836:INFO:create_model() successfully completed......................................
2025-04-22 20:56:24,053:INFO:Threshold: 0.5234375. F1: 0.5265
2025-04-22 20:56:24,053:INFO:Initializing create_model()
2025-04-22 20:56:24,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.4609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:24,053:INFO:Checking exceptions
2025-04-22 20:56:24,054:INFO:Importing libraries
2025-04-22 20:56:24,054:INFO:Copying training dataset
2025-04-22 20:56:24,059:INFO:Defining folds
2025-04-22 20:56:24,059:INFO:Declaring metric variables
2025-04-22 20:56:24,060:INFO:Importing untrained model
2025-04-22 20:56:24,060:INFO:Declaring custom model
2025-04-22 20:56:24,060:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:24,060:INFO:Starting cross validation
2025-04-22 20:56:24,061:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:25,160:INFO:Calculating mean and std
2025-04-22 20:56:25,161:INFO:Creating metrics dataframe
2025-04-22 20:56:25,162:INFO:Finalizing model
2025-04-22 20:56:26,507:INFO:Uploading results into container
2025-04-22 20:56:26,507:INFO:Uploading model into container now
2025-04-22 20:56:26,507:INFO:_master_model_container: 100
2025-04-22 20:56:26,507:INFO:_display_container: 29
2025-04-22 20:56:26,508:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.4609375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:26,508:INFO:create_model() successfully completed......................................
2025-04-22 20:56:26,719:INFO:Threshold: 0.4609375. F1: 0.5279
2025-04-22 20:56:26,719:INFO:Initializing create_model()
2025-04-22 20:56:26,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.5859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:26,719:INFO:Checking exceptions
2025-04-22 20:56:26,720:INFO:Importing libraries
2025-04-22 20:56:26,720:INFO:Copying training dataset
2025-04-22 20:56:26,726:INFO:Defining folds
2025-04-22 20:56:26,726:INFO:Declaring metric variables
2025-04-22 20:56:26,726:INFO:Importing untrained model
2025-04-22 20:56:26,726:INFO:Declaring custom model
2025-04-22 20:56:26,726:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:26,726:INFO:Starting cross validation
2025-04-22 20:56:26,727:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:27,855:INFO:Calculating mean and std
2025-04-22 20:56:27,855:INFO:Creating metrics dataframe
2025-04-22 20:56:27,857:INFO:Finalizing model
2025-04-22 20:56:29,207:INFO:Uploading results into container
2025-04-22 20:56:29,207:INFO:Uploading model into container now
2025-04-22 20:56:29,207:INFO:_master_model_container: 101
2025-04-22 20:56:29,207:INFO:_display_container: 29
2025-04-22 20:56:29,208:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.5859375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:29,208:INFO:create_model() successfully completed......................................
2025-04-22 20:56:29,417:INFO:Threshold: 0.5859375. F1: 0.5295
2025-04-22 20:56:29,418:INFO:Initializing create_model()
2025-04-22 20:56:29,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.640625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:29,418:INFO:Checking exceptions
2025-04-22 20:56:29,419:INFO:Importing libraries
2025-04-22 20:56:29,419:INFO:Copying training dataset
2025-04-22 20:56:29,424:INFO:Defining folds
2025-04-22 20:56:29,424:INFO:Declaring metric variables
2025-04-22 20:56:29,424:INFO:Importing untrained model
2025-04-22 20:56:29,424:INFO:Declaring custom model
2025-04-22 20:56:29,425:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:29,425:INFO:Starting cross validation
2025-04-22 20:56:29,426:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:30,580:INFO:Calculating mean and std
2025-04-22 20:56:30,580:INFO:Creating metrics dataframe
2025-04-22 20:56:30,582:INFO:Finalizing model
2025-04-22 20:56:31,939:INFO:Uploading results into container
2025-04-22 20:56:31,939:INFO:Uploading model into container now
2025-04-22 20:56:31,940:INFO:_master_model_container: 102
2025-04-22 20:56:31,940:INFO:_display_container: 29
2025-04-22 20:56:31,940:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.640625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:31,941:INFO:create_model() successfully completed......................................
2025-04-22 20:56:32,152:INFO:Threshold: 0.640625. F1: 0.523
2025-04-22 20:56:32,152:INFO:Initializing create_model()
2025-04-22 20:56:32,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:32,152:INFO:Checking exceptions
2025-04-22 20:56:32,153:INFO:Importing libraries
2025-04-22 20:56:32,154:INFO:Copying training dataset
2025-04-22 20:56:32,159:INFO:Defining folds
2025-04-22 20:56:32,159:INFO:Declaring metric variables
2025-04-22 20:56:32,159:INFO:Importing untrained model
2025-04-22 20:56:32,159:INFO:Declaring custom model
2025-04-22 20:56:32,159:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:32,159:INFO:Starting cross validation
2025-04-22 20:56:32,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:33,313:INFO:Calculating mean and std
2025-04-22 20:56:33,314:INFO:Creating metrics dataframe
2025-04-22 20:56:33,315:INFO:Finalizing model
2025-04-22 20:56:34,664:INFO:Uploading results into container
2025-04-22 20:56:34,664:INFO:Uploading model into container now
2025-04-22 20:56:34,665:INFO:_master_model_container: 103
2025-04-22 20:56:34,665:INFO:_display_container: 29
2025-04-22 20:56:34,666:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.6484375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:34,666:INFO:create_model() successfully completed......................................
2025-04-22 20:56:34,874:INFO:Threshold: 0.6484375. F1: 0.5222
2025-04-22 20:56:34,874:INFO:Initializing create_model()
2025-04-22 20:56:34,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.703125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:34,874:INFO:Checking exceptions
2025-04-22 20:56:34,875:INFO:Importing libraries
2025-04-22 20:56:34,875:INFO:Copying training dataset
2025-04-22 20:56:34,881:INFO:Defining folds
2025-04-22 20:56:34,881:INFO:Declaring metric variables
2025-04-22 20:56:34,881:INFO:Importing untrained model
2025-04-22 20:56:34,881:INFO:Declaring custom model
2025-04-22 20:56:34,881:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:34,882:INFO:Starting cross validation
2025-04-22 20:56:34,882:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:36,016:INFO:Calculating mean and std
2025-04-22 20:56:36,016:INFO:Creating metrics dataframe
2025-04-22 20:56:36,017:INFO:Finalizing model
2025-04-22 20:56:37,361:INFO:Uploading results into container
2025-04-22 20:56:37,361:INFO:Uploading model into container now
2025-04-22 20:56:37,361:INFO:_master_model_container: 104
2025-04-22 20:56:37,362:INFO:_display_container: 29
2025-04-22 20:56:37,362:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.703125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:37,362:INFO:create_model() successfully completed......................................
2025-04-22 20:56:37,572:INFO:Threshold: 0.703125. F1: 0.4791
2025-04-22 20:56:37,573:INFO:Initializing create_model()
2025-04-22 20:56:37,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:37,573:INFO:Checking exceptions
2025-04-22 20:56:37,574:INFO:Importing libraries
2025-04-22 20:56:37,574:INFO:Copying training dataset
2025-04-22 20:56:37,579:INFO:Defining folds
2025-04-22 20:56:37,579:INFO:Declaring metric variables
2025-04-22 20:56:37,580:INFO:Importing untrained model
2025-04-22 20:56:37,580:INFO:Declaring custom model
2025-04-22 20:56:37,580:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:37,580:INFO:Starting cross validation
2025-04-22 20:56:37,581:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:38,715:INFO:Calculating mean and std
2025-04-22 20:56:38,715:INFO:Creating metrics dataframe
2025-04-22 20:56:38,716:INFO:Finalizing model
2025-04-22 20:56:40,048:INFO:Uploading results into container
2025-04-22 20:56:40,048:INFO:Uploading model into container now
2025-04-22 20:56:40,049:INFO:_master_model_container: 105
2025-04-22 20:56:40,049:INFO:_display_container: 29
2025-04-22 20:56:40,049:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.7109375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:40,049:INFO:create_model() successfully completed......................................
2025-04-22 20:56:40,258:INFO:Threshold: 0.7109375. F1: 0.4763
2025-04-22 20:56:40,259:INFO:Initializing create_model()
2025-04-22 20:56:40,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0234375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:40,259:INFO:Checking exceptions
2025-04-22 20:56:40,260:INFO:Importing libraries
2025-04-22 20:56:40,260:INFO:Copying training dataset
2025-04-22 20:56:40,265:INFO:Defining folds
2025-04-22 20:56:40,265:INFO:Declaring metric variables
2025-04-22 20:56:40,265:INFO:Importing untrained model
2025-04-22 20:56:40,265:INFO:Declaring custom model
2025-04-22 20:56:40,266:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:40,266:INFO:Starting cross validation
2025-04-22 20:56:40,266:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:41,387:INFO:Calculating mean and std
2025-04-22 20:56:41,387:INFO:Creating metrics dataframe
2025-04-22 20:56:41,389:INFO:Finalizing model
2025-04-22 20:56:42,716:INFO:Uploading results into container
2025-04-22 20:56:42,717:INFO:Uploading model into container now
2025-04-22 20:56:42,717:INFO:_master_model_container: 106
2025-04-22 20:56:42,717:INFO:_display_container: 29
2025-04-22 20:56:42,718:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.0234375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:42,718:INFO:create_model() successfully completed......................................
2025-04-22 20:56:42,929:INFO:Threshold: 0.0234375. F1: 0.3652
2025-04-22 20:56:42,929:INFO:Initializing create_model()
2025-04-22 20:56:42,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.0859375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:42,929:INFO:Checking exceptions
2025-04-22 20:56:42,930:INFO:Importing libraries
2025-04-22 20:56:42,930:INFO:Copying training dataset
2025-04-22 20:56:42,936:INFO:Defining folds
2025-04-22 20:56:42,936:INFO:Declaring metric variables
2025-04-22 20:56:42,936:INFO:Importing untrained model
2025-04-22 20:56:42,936:INFO:Declaring custom model
2025-04-22 20:56:42,936:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:42,936:INFO:Starting cross validation
2025-04-22 20:56:42,937:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:44,091:INFO:Calculating mean and std
2025-04-22 20:56:44,091:INFO:Creating metrics dataframe
2025-04-22 20:56:44,092:INFO:Finalizing model
2025-04-22 20:56:45,436:INFO:Uploading results into container
2025-04-22 20:56:45,436:INFO:Uploading model into container now
2025-04-22 20:56:45,437:INFO:_master_model_container: 107
2025-04-22 20:56:45,437:INFO:_display_container: 29
2025-04-22 20:56:45,437:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.0859375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:45,437:INFO:create_model() successfully completed......................................
2025-04-22 20:56:45,648:INFO:Threshold: 0.0859375. F1: 0.3652
2025-04-22 20:56:45,648:INFO:Initializing create_model()
2025-04-22 20:56:45,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.140625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:45,648:INFO:Checking exceptions
2025-04-22 20:56:45,649:INFO:Importing libraries
2025-04-22 20:56:45,650:INFO:Copying training dataset
2025-04-22 20:56:45,654:INFO:Defining folds
2025-04-22 20:56:45,654:INFO:Declaring metric variables
2025-04-22 20:56:45,655:INFO:Importing untrained model
2025-04-22 20:56:45,655:INFO:Declaring custom model
2025-04-22 20:56:45,655:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:45,655:INFO:Starting cross validation
2025-04-22 20:56:45,656:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:46,762:INFO:Calculating mean and std
2025-04-22 20:56:46,763:INFO:Creating metrics dataframe
2025-04-22 20:56:46,764:INFO:Finalizing model
2025-04-22 20:56:48,088:INFO:Uploading results into container
2025-04-22 20:56:48,088:INFO:Uploading model into container now
2025-04-22 20:56:48,089:INFO:_master_model_container: 108
2025-04-22 20:56:48,089:INFO:_display_container: 29
2025-04-22 20:56:48,090:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.140625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:48,090:INFO:create_model() successfully completed......................................
2025-04-22 20:56:48,299:INFO:Threshold: 0.140625. F1: 0.3652
2025-04-22 20:56:48,299:INFO:Initializing create_model()
2025-04-22 20:56:48,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.078125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:48,299:INFO:Checking exceptions
2025-04-22 20:56:48,300:INFO:Importing libraries
2025-04-22 20:56:48,300:INFO:Copying training dataset
2025-04-22 20:56:48,306:INFO:Defining folds
2025-04-22 20:56:48,306:INFO:Declaring metric variables
2025-04-22 20:56:48,306:INFO:Importing untrained model
2025-04-22 20:56:48,306:INFO:Declaring custom model
2025-04-22 20:56:48,306:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:48,306:INFO:Starting cross validation
2025-04-22 20:56:48,307:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:49,485:INFO:Calculating mean and std
2025-04-22 20:56:49,486:INFO:Creating metrics dataframe
2025-04-22 20:56:49,487:INFO:Finalizing model
2025-04-22 20:56:50,817:INFO:Uploading results into container
2025-04-22 20:56:50,818:INFO:Uploading model into container now
2025-04-22 20:56:50,818:INFO:_master_model_container: 109
2025-04-22 20:56:50,818:INFO:_display_container: 29
2025-04-22 20:56:50,820:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.078125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:50,820:INFO:create_model() successfully completed......................................
2025-04-22 20:56:51,028:INFO:Threshold: 0.078125. F1: 0.3652
2025-04-22 20:56:51,028:INFO:Initializing create_model()
2025-04-22 20:56:51,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.1484375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:51,028:INFO:Checking exceptions
2025-04-22 20:56:51,029:INFO:Importing libraries
2025-04-22 20:56:51,030:INFO:Copying training dataset
2025-04-22 20:56:51,035:INFO:Defining folds
2025-04-22 20:56:51,035:INFO:Declaring metric variables
2025-04-22 20:56:51,035:INFO:Importing untrained model
2025-04-22 20:56:51,035:INFO:Declaring custom model
2025-04-22 20:56:51,036:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:51,036:INFO:Starting cross validation
2025-04-22 20:56:51,037:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:52,174:INFO:Calculating mean and std
2025-04-22 20:56:52,174:INFO:Creating metrics dataframe
2025-04-22 20:56:52,176:INFO:Finalizing model
2025-04-22 20:56:53,522:INFO:Uploading results into container
2025-04-22 20:56:53,522:INFO:Uploading model into container now
2025-04-22 20:56:53,523:INFO:_master_model_container: 110
2025-04-22 20:56:53,523:INFO:_display_container: 29
2025-04-22 20:56:53,523:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.1484375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:53,524:INFO:create_model() successfully completed......................................
2025-04-22 20:56:53,734:INFO:Threshold: 0.1484375. F1: 0.3652
2025-04-22 20:56:53,734:INFO:Initializing create_model()
2025-04-22 20:56:53,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.203125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:53,735:INFO:Checking exceptions
2025-04-22 20:56:53,735:INFO:Importing libraries
2025-04-22 20:56:53,736:INFO:Copying training dataset
2025-04-22 20:56:53,741:INFO:Defining folds
2025-04-22 20:56:53,741:INFO:Declaring metric variables
2025-04-22 20:56:53,741:INFO:Importing untrained model
2025-04-22 20:56:53,741:INFO:Declaring custom model
2025-04-22 20:56:53,741:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:53,741:INFO:Starting cross validation
2025-04-22 20:56:53,742:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:54,907:INFO:Calculating mean and std
2025-04-22 20:56:54,907:INFO:Creating metrics dataframe
2025-04-22 20:56:54,909:INFO:Finalizing model
2025-04-22 20:56:56,254:INFO:Uploading results into container
2025-04-22 20:56:56,254:INFO:Uploading model into container now
2025-04-22 20:56:56,255:INFO:_master_model_container: 111
2025-04-22 20:56:56,255:INFO:_display_container: 29
2025-04-22 20:56:56,255:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.203125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:56,255:INFO:create_model() successfully completed......................................
2025-04-22 20:56:56,464:INFO:Threshold: 0.203125. F1: 0.3655
2025-04-22 20:56:56,464:INFO:Initializing create_model()
2025-04-22 20:56:56,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.2109375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:56,464:INFO:Checking exceptions
2025-04-22 20:56:56,466:INFO:Importing libraries
2025-04-22 20:56:56,466:INFO:Copying training dataset
2025-04-22 20:56:56,471:INFO:Defining folds
2025-04-22 20:56:56,471:INFO:Declaring metric variables
2025-04-22 20:56:56,471:INFO:Importing untrained model
2025-04-22 20:56:56,471:INFO:Declaring custom model
2025-04-22 20:56:56,471:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:56,471:INFO:Starting cross validation
2025-04-22 20:56:56,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:56:57,619:INFO:Calculating mean and std
2025-04-22 20:56:57,619:INFO:Creating metrics dataframe
2025-04-22 20:56:57,621:INFO:Finalizing model
2025-04-22 20:56:58,937:INFO:Uploading results into container
2025-04-22 20:56:58,937:INFO:Uploading model into container now
2025-04-22 20:56:58,938:INFO:_master_model_container: 112
2025-04-22 20:56:58,938:INFO:_display_container: 29
2025-04-22 20:56:58,939:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.2109375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:56:58,939:INFO:create_model() successfully completed......................................
2025-04-22 20:56:59,152:INFO:Threshold: 0.2109375. F1: 0.3658
2025-04-22 20:56:59,152:INFO:Initializing create_model()
2025-04-22 20:56:59,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.265625, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:56:59,152:INFO:Checking exceptions
2025-04-22 20:56:59,153:INFO:Importing libraries
2025-04-22 20:56:59,153:INFO:Copying training dataset
2025-04-22 20:56:59,158:INFO:Defining folds
2025-04-22 20:56:59,158:INFO:Declaring metric variables
2025-04-22 20:56:59,159:INFO:Importing untrained model
2025-04-22 20:56:59,159:INFO:Declaring custom model
2025-04-22 20:56:59,159:INFO:Logistic Regression Imported successfully
2025-04-22 20:56:59,159:INFO:Starting cross validation
2025-04-22 20:56:59,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:00,318:INFO:Calculating mean and std
2025-04-22 20:57:00,319:INFO:Creating metrics dataframe
2025-04-22 20:57:00,320:INFO:Finalizing model
2025-04-22 20:57:01,657:INFO:Uploading results into container
2025-04-22 20:57:01,657:INFO:Uploading model into container now
2025-04-22 20:57:01,657:INFO:_master_model_container: 113
2025-04-22 20:57:01,657:INFO:_display_container: 29
2025-04-22 20:57:01,658:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.265625,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:01,658:INFO:create_model() successfully completed......................................
2025-04-22 20:57:01,872:INFO:Threshold: 0.265625. F1: 0.372
2025-04-22 20:57:01,872:INFO:Initializing create_model()
2025-04-22 20:57:01,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.2734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:01,872:INFO:Checking exceptions
2025-04-22 20:57:01,873:INFO:Importing libraries
2025-04-22 20:57:01,873:INFO:Copying training dataset
2025-04-22 20:57:01,878:INFO:Defining folds
2025-04-22 20:57:01,878:INFO:Declaring metric variables
2025-04-22 20:57:01,878:INFO:Importing untrained model
2025-04-22 20:57:01,878:INFO:Declaring custom model
2025-04-22 20:57:01,879:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:01,879:INFO:Starting cross validation
2025-04-22 20:57:01,879:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:03,016:INFO:Calculating mean and std
2025-04-22 20:57:03,016:INFO:Creating metrics dataframe
2025-04-22 20:57:03,017:INFO:Finalizing model
2025-04-22 20:57:04,357:INFO:Uploading results into container
2025-04-22 20:57:04,358:INFO:Uploading model into container now
2025-04-22 20:57:04,358:INFO:_master_model_container: 114
2025-04-22 20:57:04,358:INFO:_display_container: 29
2025-04-22 20:57:04,359:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.2734375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:04,359:INFO:create_model() successfully completed......................................
2025-04-22 20:57:04,571:INFO:Threshold: 0.2734375. F1: 0.3724
2025-04-22 20:57:04,572:INFO:Initializing create_model()
2025-04-22 20:57:04,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.328125, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:04,572:INFO:Checking exceptions
2025-04-22 20:57:04,573:INFO:Importing libraries
2025-04-22 20:57:04,573:INFO:Copying training dataset
2025-04-22 20:57:04,578:INFO:Defining folds
2025-04-22 20:57:04,578:INFO:Declaring metric variables
2025-04-22 20:57:04,579:INFO:Importing untrained model
2025-04-22 20:57:04,579:INFO:Declaring custom model
2025-04-22 20:57:04,579:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:04,579:INFO:Starting cross validation
2025-04-22 20:57:04,580:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:05,714:INFO:Calculating mean and std
2025-04-22 20:57:05,714:INFO:Creating metrics dataframe
2025-04-22 20:57:05,717:INFO:Finalizing model
2025-04-22 20:57:07,041:INFO:Uploading results into container
2025-04-22 20:57:07,042:INFO:Uploading model into container now
2025-04-22 20:57:07,042:INFO:_master_model_container: 115
2025-04-22 20:57:07,042:INFO:_display_container: 29
2025-04-22 20:57:07,043:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.328125,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:07,043:INFO:create_model() successfully completed......................................
2025-04-22 20:57:07,256:INFO:Threshold: 0.328125. F1: 0.4934
2025-04-22 20:57:07,256:INFO:Initializing create_model()
2025-04-22 20:57:07,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7734375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:07,256:INFO:Checking exceptions
2025-04-22 20:57:07,257:INFO:Importing libraries
2025-04-22 20:57:07,257:INFO:Copying training dataset
2025-04-22 20:57:07,262:INFO:Defining folds
2025-04-22 20:57:07,262:INFO:Declaring metric variables
2025-04-22 20:57:07,262:INFO:Importing untrained model
2025-04-22 20:57:07,262:INFO:Declaring custom model
2025-04-22 20:57:07,263:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:07,263:INFO:Starting cross validation
2025-04-22 20:57:07,263:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:08,402:INFO:Calculating mean and std
2025-04-22 20:57:08,402:INFO:Creating metrics dataframe
2025-04-22 20:57:08,403:INFO:Finalizing model
2025-04-22 20:57:09,735:INFO:Uploading results into container
2025-04-22 20:57:09,735:INFO:Uploading model into container now
2025-04-22 20:57:09,737:INFO:_master_model_container: 116
2025-04-22 20:57:09,737:INFO:_display_container: 29
2025-04-22 20:57:09,738:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.7734375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:09,738:INFO:create_model() successfully completed......................................
2025-04-22 20:57:09,950:INFO:Threshold: 0.7734375. F1: 0.4315
2025-04-22 20:57:09,950:INFO:Initializing create_model()
2025-04-22 20:57:09,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8359375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:09,950:INFO:Checking exceptions
2025-04-22 20:57:09,951:INFO:Importing libraries
2025-04-22 20:57:09,951:INFO:Copying training dataset
2025-04-22 20:57:09,956:INFO:Defining folds
2025-04-22 20:57:09,956:INFO:Declaring metric variables
2025-04-22 20:57:09,957:INFO:Importing untrained model
2025-04-22 20:57:09,957:INFO:Declaring custom model
2025-04-22 20:57:09,957:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:09,957:INFO:Starting cross validation
2025-04-22 20:57:09,958:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:11,073:INFO:Calculating mean and std
2025-04-22 20:57:11,074:INFO:Creating metrics dataframe
2025-04-22 20:57:11,075:INFO:Finalizing model
2025-04-22 20:57:12,401:INFO:Uploading results into container
2025-04-22 20:57:12,401:INFO:Uploading model into container now
2025-04-22 20:57:12,403:INFO:_master_model_container: 117
2025-04-22 20:57:12,403:INFO:_display_container: 29
2025-04-22 20:57:12,404:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.8359375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:12,404:INFO:create_model() successfully completed......................................
2025-04-22 20:57:12,615:INFO:Threshold: 0.8359375. F1: 0.3708
2025-04-22 20:57:12,615:INFO:Initializing create_model()
2025-04-22 20:57:12,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.8984375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:12,615:INFO:Checking exceptions
2025-04-22 20:57:12,616:INFO:Importing libraries
2025-04-22 20:57:12,617:INFO:Copying training dataset
2025-04-22 20:57:12,622:INFO:Defining folds
2025-04-22 20:57:12,622:INFO:Declaring metric variables
2025-04-22 20:57:12,622:INFO:Importing untrained model
2025-04-22 20:57:12,622:INFO:Declaring custom model
2025-04-22 20:57:12,622:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:12,622:INFO:Starting cross validation
2025-04-22 20:57:12,623:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:13,757:INFO:Calculating mean and std
2025-04-22 20:57:13,758:INFO:Creating metrics dataframe
2025-04-22 20:57:13,759:INFO:Finalizing model
2025-04-22 20:57:15,088:INFO:Uploading results into container
2025-04-22 20:57:15,088:INFO:Uploading model into container now
2025-04-22 20:57:15,089:INFO:_master_model_container: 118
2025-04-22 20:57:15,089:INFO:_display_container: 29
2025-04-22 20:57:15,089:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.8984375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:15,089:INFO:create_model() successfully completed......................................
2025-04-22 20:57:15,299:INFO:Threshold: 0.8984375. F1: 0.2317
2025-04-22 20:57:15,300:INFO:Initializing create_model()
2025-04-22 20:57:15,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.9609375, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 20:57:15,300:INFO:Checking exceptions
2025-04-22 20:57:15,301:INFO:Importing libraries
2025-04-22 20:57:15,301:INFO:Copying training dataset
2025-04-22 20:57:15,306:INFO:Defining folds
2025-04-22 20:57:15,306:INFO:Declaring metric variables
2025-04-22 20:57:15,306:INFO:Importing untrained model
2025-04-22 20:57:15,306:INFO:Declaring custom model
2025-04-22 20:57:15,307:INFO:Logistic Regression Imported successfully
2025-04-22 20:57:15,307:INFO:Starting cross validation
2025-04-22 20:57:15,307:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 20:57:16,454:INFO:Calculating mean and std
2025-04-22 20:57:16,454:INFO:Creating metrics dataframe
2025-04-22 20:57:16,455:INFO:Finalizing model
2025-04-22 20:57:17,789:INFO:Uploading results into container
2025-04-22 20:57:17,789:INFO:Uploading model into container now
2025-04-22 20:57:17,790:INFO:_master_model_container: 119
2025-04-22 20:57:17,790:INFO:_display_container: 29
2025-04-22 20:57:17,790:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=42,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.9609375,
                                     random_state=42, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2025-04-22 20:57:17,790:INFO:create_model() successfully completed......................................
2025-04-22 20:57:17,999:INFO:Threshold: 0.9609375. F1: 0.0078
2025-04-22 20:57:18,000:INFO:optimization loop finished successfully. Best threshold: 0.5 with F1=0.5328
2025-04-22 20:57:18,005:INFO:plotting optimization threshold using plotly
2025-04-22 20:57:19,307:INFO:returning model with best metric
2025-04-22 20:57:19,307:INFO:also returning data as return_data = True
2025-04-22 20:57:19,307:INFO:optimize_threshold() successfully completed......................................
2025-04-22 21:00:55,196:INFO:Initializing ensemble_model()
2025-04-22 21:00:55,196:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:00:55,197:INFO:Checking exceptions
2025-04-22 21:00:55,213:INFO:Importing libraries
2025-04-22 21:00:55,213:INFO:Copying training dataset
2025-04-22 21:00:55,214:INFO:Checking base model
2025-04-22 21:00:55,214:INFO:Base model : Logistic Regression
2025-04-22 21:00:55,219:INFO:Importing untrained ensembler
2025-04-22 21:00:55,219:INFO:Ensemble method set to Bagging
2025-04-22 21:00:55,220:INFO:SubProcess create_model() called ==================================
2025-04-22 21:00:55,220:INFO:Initializing create_model()
2025-04-22 21:00:55,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=42,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=42, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D226BC5C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:00:55,221:INFO:Checking exceptions
2025-04-22 21:00:55,221:INFO:Importing libraries
2025-04-22 21:00:55,221:INFO:Copying training dataset
2025-04-22 21:00:55,228:INFO:Defining folds
2025-04-22 21:00:55,229:INFO:Declaring metric variables
2025-04-22 21:00:55,232:INFO:Importing untrained model
2025-04-22 21:00:55,232:INFO:Declaring custom model
2025-04-22 21:00:55,236:INFO:Logistic Regression Imported successfully
2025-04-22 21:00:55,240:INFO:Starting cross validation
2025-04-22 21:00:55,241:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:00:56,473:INFO:Calculating mean and std
2025-04-22 21:00:56,474:INFO:Creating metrics dataframe
2025-04-22 21:00:56,479:INFO:Finalizing model
2025-04-22 21:00:57,971:INFO:Uploading results into container
2025-04-22 21:00:57,973:INFO:Uploading model into container now
2025-04-22 21:00:57,973:INFO:_master_model_container: 120
2025-04-22 21:00:57,973:INFO:_display_container: 29
2025-04-22 21:00:57,974:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=42,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=42, verbose=0,
                  warm_start=False)
2025-04-22 21:00:57,974:INFO:create_model() successfully completed......................................
2025-04-22 21:00:58,208:INFO:SubProcess create_model() end ==================================
2025-04-22 21:00:58,208:INFO:choose_better activated
2025-04-22 21:00:58,211:INFO:SubProcess create_model() called ==================================
2025-04-22 21:00:58,211:INFO:Initializing create_model()
2025-04-22 21:00:58,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:00:58,211:INFO:Checking exceptions
2025-04-22 21:00:58,213:INFO:Importing libraries
2025-04-22 21:00:58,213:INFO:Copying training dataset
2025-04-22 21:00:58,218:INFO:Defining folds
2025-04-22 21:00:58,218:INFO:Declaring metric variables
2025-04-22 21:00:58,218:INFO:Importing untrained model
2025-04-22 21:00:58,218:INFO:Declaring custom model
2025-04-22 21:00:58,219:INFO:Logistic Regression Imported successfully
2025-04-22 21:00:58,219:INFO:Starting cross validation
2025-04-22 21:00:58,220:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:00:59,271:INFO:Calculating mean and std
2025-04-22 21:00:59,272:INFO:Creating metrics dataframe
2025-04-22 21:00:59,273:INFO:Finalizing model
2025-04-22 21:01:00,598:INFO:Uploading results into container
2025-04-22 21:01:00,598:INFO:Uploading model into container now
2025-04-22 21:01:00,599:INFO:_master_model_container: 121
2025-04-22 21:01:00,599:INFO:_display_container: 30
2025-04-22 21:01:00,599:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:01:00,599:INFO:create_model() successfully completed......................................
2025-04-22 21:01:00,818:INFO:SubProcess create_model() end ==================================
2025-04-22 21:01:00,819:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 21:01:00,820:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=LogisticRegression(C=1.0, class_weight=None,
                                               dual=False, fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=42,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=42, verbose=0,
                  warm_start=False) result for F1 is 0.5328
2025-04-22 21:01:00,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-04-22 21:01:00,820:INFO:choose_better completed
2025-04-22 21:01:00,820:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2025-04-22 21:01:00,829:INFO:_master_model_container: 121
2025-04-22 21:01:00,830:INFO:_display_container: 29
2025-04-22 21:01:00,830:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:01:00,830:INFO:ensemble_model() successfully completed......................................
2025-04-22 21:02:14,014:INFO:Initializing ensemble_model()
2025-04-22 21:02:14,014:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:02:14,014:INFO:Checking exceptions
2025-04-22 21:02:14,089:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning:

The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.


2025-04-22 21:02:14,281:INFO:Importing libraries
2025-04-22 21:02:14,281:INFO:Copying training dataset
2025-04-22 21:02:14,283:INFO:Checking base model
2025-04-22 21:02:14,283:INFO:Base model : Logistic Regression
2025-04-22 21:02:14,289:INFO:Importing untrained ensembler
2025-04-22 21:02:14,289:INFO:Ensemble method set to Boosting
2025-04-22 21:02:14,289:INFO:SubProcess create_model() called ==================================
2025-04-22 21:02:14,290:INFO:Initializing create_model()
2025-04-22 21:02:14,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=LogisticRegression(C=1.0, class_weight=None,
                                                dual=False, fit_intercept=True,
                                                intercept_scaling=1,
                                                l1_ratio=None, max_iter=1000,
                                                multi_class='auto', n_jobs=None,
                                                penalty='l2', random_state=42,
                                                solver='lbfgs', tol=0.0001,
                                                verbose=0, warm_start=False),
                   learning_rate=1.0, n_estimators=10, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22B44F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:02:14,290:INFO:Checking exceptions
2025-04-22 21:02:14,290:INFO:Importing libraries
2025-04-22 21:02:14,290:INFO:Copying training dataset
2025-04-22 21:02:14,296:INFO:Defining folds
2025-04-22 21:02:14,296:INFO:Declaring metric variables
2025-04-22 21:02:14,299:INFO:Importing untrained model
2025-04-22 21:02:14,299:INFO:Declaring custom model
2025-04-22 21:02:14,303:INFO:Logistic Regression Imported successfully
2025-04-22 21:02:14,310:INFO:Starting cross validation
2025-04-22 21:02:14,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:02:15,321:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 21:02:15,340:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 21:02:15,340:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 21:02:15,362:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 21:02:15,380:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-22 21:02:15,603:INFO:Calculating mean and std
2025-04-22 21:02:15,604:INFO:Creating metrics dataframe
2025-04-22 21:02:15,608:INFO:Finalizing model
2025-04-22 21:02:16,894:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning:

The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.


2025-04-22 21:02:17,073:INFO:Uploading results into container
2025-04-22 21:02:17,074:INFO:Uploading model into container now
2025-04-22 21:02:17,074:INFO:_master_model_container: 122
2025-04-22 21:02:17,074:INFO:_display_container: 30
2025-04-22 21:02:17,075:INFO:AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=LogisticRegression(C=1.0, class_weight=None,
                                                dual=False, fit_intercept=True,
                                                intercept_scaling=1,
                                                l1_ratio=None, max_iter=1000,
                                                multi_class='auto', n_jobs=None,
                                                penalty='l2', random_state=42,
                                                solver='lbfgs', tol=0.0001,
                                                verbose=0, warm_start=False),
                   learning_rate=1.0, n_estimators=10, random_state=42)
2025-04-22 21:02:17,075:INFO:create_model() successfully completed......................................
2025-04-22 21:02:17,306:INFO:SubProcess create_model() end ==================================
2025-04-22 21:02:17,306:INFO:choose_better activated
2025-04-22 21:02:17,309:INFO:SubProcess create_model() called ==================================
2025-04-22 21:02:17,309:INFO:Initializing create_model()
2025-04-22 21:02:17,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:02:17,310:INFO:Checking exceptions
2025-04-22 21:02:17,311:INFO:Importing libraries
2025-04-22 21:02:17,312:INFO:Copying training dataset
2025-04-22 21:02:17,317:INFO:Defining folds
2025-04-22 21:02:17,317:INFO:Declaring metric variables
2025-04-22 21:02:17,317:INFO:Importing untrained model
2025-04-22 21:02:17,318:INFO:Declaring custom model
2025-04-22 21:02:17,318:INFO:Logistic Regression Imported successfully
2025-04-22 21:02:17,318:INFO:Starting cross validation
2025-04-22 21:02:17,319:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:02:18,402:INFO:Calculating mean and std
2025-04-22 21:02:18,402:INFO:Creating metrics dataframe
2025-04-22 21:02:18,405:INFO:Finalizing model
2025-04-22 21:02:19,697:INFO:Uploading results into container
2025-04-22 21:02:19,697:INFO:Uploading model into container now
2025-04-22 21:02:19,698:INFO:_master_model_container: 123
2025-04-22 21:02:19,698:INFO:_display_container: 31
2025-04-22 21:02:19,698:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:02:19,698:INFO:create_model() successfully completed......................................
2025-04-22 21:02:19,914:INFO:SubProcess create_model() end ==================================
2025-04-22 21:02:19,915:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 21:02:19,916:INFO:AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=LogisticRegression(C=1.0, class_weight=None,
                                                dual=False, fit_intercept=True,
                                                intercept_scaling=1,
                                                l1_ratio=None, max_iter=1000,
                                                multi_class='auto', n_jobs=None,
                                                penalty='l2', random_state=42,
                                                solver='lbfgs', tol=0.0001,
                                                verbose=0, warm_start=False),
                   learning_rate=1.0, n_estimators=10, random_state=42) result for F1 is 0.5315
2025-04-22 21:02:19,916:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-04-22 21:02:19,916:INFO:choose_better completed
2025-04-22 21:02:19,916:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2025-04-22 21:02:19,924:INFO:_master_model_container: 123
2025-04-22 21:02:19,924:INFO:_display_container: 30
2025-04-22 21:02:19,924:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:02:19,924:INFO:ensemble_model() successfully completed......................................
2025-04-22 21:15:06,226:INFO:Initializing blend_models()
2025-04-22 21:15:06,226:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=True, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:15:06,227:INFO:Checking exceptions
2025-04-22 21:15:06,248:INFO:Importing libraries
2025-04-22 21:15:06,248:INFO:Copying training dataset
2025-04-22 21:15:06,253:INFO:Getting model names
2025-04-22 21:15:06,259:INFO:SubProcess create_model() called ==================================
2025-04-22 21:15:06,266:INFO:Initializing create_model()
2025-04-22 21:15:06,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21DBF4FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:15:06,266:INFO:Checking exceptions
2025-04-22 21:15:06,266:INFO:Importing libraries
2025-04-22 21:15:06,266:INFO:Copying training dataset
2025-04-22 21:15:06,276:INFO:Defining folds
2025-04-22 21:15:06,276:INFO:Declaring metric variables
2025-04-22 21:15:06,280:INFO:Importing untrained model
2025-04-22 21:15:06,280:INFO:Declaring custom model
2025-04-22 21:15:06,286:INFO:Voting Classifier Imported successfully
2025-04-22 21:15:06,292:INFO:Starting cross validation
2025-04-22 21:15:06,293:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:15:13,067:INFO:Calculating mean and std
2025-04-22 21:15:13,069:INFO:Creating metrics dataframe
2025-04-22 21:15:13,075:INFO:Finalizing model
2025-04-22 21:15:16,937:INFO:Uploading results into container
2025-04-22 21:15:16,938:INFO:Uploading model into container now
2025-04-22 21:15:16,940:INFO:_master_model_container: 124
2025-04-22 21:15:16,940:INFO:_display_container: 31
2025-04-22 21:15:16,946:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-04-22 21:15:16,946:INFO:create_model() successfully completed......................................
2025-04-22 21:15:17,233:INFO:SubProcess create_model() end ==================================
2025-04-22 21:15:17,233:INFO:choose_better activated
2025-04-22 21:15:17,241:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=42,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for F1 is 0.5341
2025-04-22 21:15:17,242:INFO:SubProcess create_model() called ==================================
2025-04-22 21:15:17,242:INFO:Initializing create_model()
2025-04-22 21:15:17,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:15:17,242:INFO:Checking exceptions
2025-04-22 21:15:17,244:INFO:Importing libraries
2025-04-22 21:15:17,244:INFO:Copying training dataset
2025-04-22 21:15:17,250:INFO:Defining folds
2025-04-22 21:15:17,250:INFO:Declaring metric variables
2025-04-22 21:15:17,250:INFO:Importing untrained model
2025-04-22 21:15:17,250:INFO:Declaring custom model
2025-04-22 21:15:17,250:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:15:17,250:INFO:Starting cross validation
2025-04-22 21:15:17,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:15:22,341:INFO:Calculating mean and std
2025-04-22 21:15:22,342:INFO:Creating metrics dataframe
2025-04-22 21:15:22,344:INFO:Finalizing model
2025-04-22 21:15:24,728:INFO:Uploading results into container
2025-04-22 21:15:24,729:INFO:Uploading model into container now
2025-04-22 21:15:24,729:INFO:_master_model_container: 125
2025-04-22 21:15:24,729:INFO:_display_container: 32
2025-04-22 21:15:24,729:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:15:24,729:INFO:create_model() successfully completed......................................
2025-04-22 21:15:24,954:INFO:SubProcess create_model() end ==================================
2025-04-22 21:15:24,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:15:24,955:INFO:SubProcess create_model() called ==================================
2025-04-22 21:15:24,955:INFO:Initializing create_model()
2025-04-22 21:15:24,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:15:24,955:INFO:Checking exceptions
2025-04-22 21:15:24,957:INFO:Importing libraries
2025-04-22 21:15:24,957:INFO:Copying training dataset
2025-04-22 21:15:24,967:INFO:Defining folds
2025-04-22 21:15:24,967:INFO:Declaring metric variables
2025-04-22 21:15:24,967:INFO:Importing untrained model
2025-04-22 21:15:24,968:INFO:Declaring custom model
2025-04-22 21:15:24,968:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:15:24,968:INFO:Starting cross validation
2025-04-22 21:15:24,970:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:15:30,663:INFO:Calculating mean and std
2025-04-22 21:15:30,663:INFO:Creating metrics dataframe
2025-04-22 21:15:30,664:INFO:Finalizing model
2025-04-22 21:15:33,154:INFO:Uploading results into container
2025-04-22 21:15:33,155:INFO:Uploading model into container now
2025-04-22 21:15:33,155:INFO:_master_model_container: 126
2025-04-22 21:15:33,155:INFO:_display_container: 32
2025-04-22 21:15:33,156:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:15:33,156:INFO:create_model() successfully completed......................................
2025-04-22 21:15:33,383:INFO:SubProcess create_model() end ==================================
2025-04-22 21:15:33,384:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:15:33,384:INFO:SubProcess create_model() called ==================================
2025-04-22 21:15:33,384:INFO:Initializing create_model()
2025-04-22 21:15:33,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:15:33,385:INFO:Checking exceptions
2025-04-22 21:15:33,386:INFO:Importing libraries
2025-04-22 21:15:33,386:INFO:Copying training dataset
2025-04-22 21:15:33,393:INFO:Defining folds
2025-04-22 21:15:33,393:INFO:Declaring metric variables
2025-04-22 21:15:33,393:INFO:Importing untrained model
2025-04-22 21:15:33,393:INFO:Declaring custom model
2025-04-22 21:15:33,394:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:15:33,394:INFO:Starting cross validation
2025-04-22 21:15:33,395:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:15:36,963:INFO:Calculating mean and std
2025-04-22 21:15:36,964:INFO:Creating metrics dataframe
2025-04-22 21:15:36,966:INFO:Finalizing model
2025-04-22 21:15:38,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:15:38,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:15:38,403:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:15:38,410:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:15:38,410:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:15:38,410:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:15:38,410:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:15:38,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000515 seconds.
2025-04-22 21:15:38,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:15:38,412:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:15:38,412:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:15:38,412:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:15:38,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:15:38,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:15:38,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:15:38,487:INFO:Uploading results into container
2025-04-22 21:15:38,487:INFO:Uploading model into container now
2025-04-22 21:15:38,488:INFO:_master_model_container: 127
2025-04-22 21:15:38,488:INFO:_display_container: 32
2025-04-22 21:15:38,489:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:15:38,489:INFO:create_model() successfully completed......................................
2025-04-22 21:15:38,744:INFO:SubProcess create_model() end ==================================
2025-04-22 21:15:38,745:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:15:38,745:INFO:SubProcess create_model() called ==================================
2025-04-22 21:15:38,745:INFO:Initializing create_model()
2025-04-22 21:15:38,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:15:38,745:INFO:Checking exceptions
2025-04-22 21:15:38,747:INFO:Importing libraries
2025-04-22 21:15:38,747:INFO:Copying training dataset
2025-04-22 21:15:38,752:INFO:Defining folds
2025-04-22 21:15:38,753:INFO:Declaring metric variables
2025-04-22 21:15:38,753:INFO:Importing untrained model
2025-04-22 21:15:38,753:INFO:Declaring custom model
2025-04-22 21:15:38,753:INFO:Logistic Regression Imported successfully
2025-04-22 21:15:38,753:INFO:Starting cross validation
2025-04-22 21:15:38,754:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:15:41,269:INFO:Calculating mean and std
2025-04-22 21:15:41,269:INFO:Creating metrics dataframe
2025-04-22 21:15:41,271:INFO:Finalizing model
2025-04-22 21:15:42,680:INFO:Uploading results into container
2025-04-22 21:15:42,680:INFO:Uploading model into container now
2025-04-22 21:15:42,681:INFO:_master_model_container: 128
2025-04-22 21:15:42,681:INFO:_display_container: 32
2025-04-22 21:15:42,681:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:15:42,681:INFO:create_model() successfully completed......................................
2025-04-22 21:15:42,923:INFO:SubProcess create_model() end ==================================
2025-04-22 21:15:42,923:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 21:15:42,924:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:15:42,924:INFO:choose_better completed
2025-04-22 21:15:42,924:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-04-22 21:15:42,932:INFO:_master_model_container: 128
2025-04-22 21:15:42,932:INFO:_display_container: 31
2025-04-22 21:15:42,933:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:15:42,933:INFO:blend_models() successfully completed......................................
2025-04-22 21:17:19,232:INFO:Initializing blend_models()
2025-04-22 21:17:19,232:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=True, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:17:19,232:INFO:Checking exceptions
2025-04-22 21:17:19,250:INFO:Importing libraries
2025-04-22 21:17:19,251:INFO:Copying training dataset
2025-04-22 21:17:19,255:INFO:Getting model names
2025-04-22 21:17:19,259:INFO:SubProcess create_model() called ==================================
2025-04-22 21:17:19,262:INFO:Initializing create_model()
2025-04-22 21:17:19,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21DF82CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:17:19,263:INFO:Checking exceptions
2025-04-22 21:17:19,263:INFO:Importing libraries
2025-04-22 21:17:19,263:INFO:Copying training dataset
2025-04-22 21:17:19,270:INFO:Defining folds
2025-04-22 21:17:19,270:INFO:Declaring metric variables
2025-04-22 21:17:19,273:INFO:Importing untrained model
2025-04-22 21:17:19,273:INFO:Declaring custom model
2025-04-22 21:17:19,277:INFO:Voting Classifier Imported successfully
2025-04-22 21:17:19,284:INFO:Starting cross validation
2025-04-22 21:17:19,285:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:17:23,282:INFO:Calculating mean and std
2025-04-22 21:17:23,283:INFO:Creating metrics dataframe
2025-04-22 21:17:23,289:INFO:Finalizing model
2025-04-22 21:17:25,679:INFO:Uploading results into container
2025-04-22 21:17:25,680:INFO:Uploading model into container now
2025-04-22 21:17:25,680:INFO:_master_model_container: 129
2025-04-22 21:17:25,680:INFO:_display_container: 32
2025-04-22 21:17:25,684:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-04-22 21:17:25,684:INFO:create_model() successfully completed......................................
2025-04-22 21:17:25,918:INFO:SubProcess create_model() end ==================================
2025-04-22 21:17:25,918:INFO:choose_better activated
2025-04-22 21:17:25,924:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for F1 is 0.5382
2025-04-22 21:17:25,924:INFO:SubProcess create_model() called ==================================
2025-04-22 21:17:25,925:INFO:Initializing create_model()
2025-04-22 21:17:25,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:17:25,925:INFO:Checking exceptions
2025-04-22 21:17:25,926:INFO:Importing libraries
2025-04-22 21:17:25,926:INFO:Copying training dataset
2025-04-22 21:17:25,933:INFO:Defining folds
2025-04-22 21:17:25,933:INFO:Declaring metric variables
2025-04-22 21:17:25,933:INFO:Importing untrained model
2025-04-22 21:17:25,933:INFO:Declaring custom model
2025-04-22 21:17:25,935:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:17:25,935:INFO:Starting cross validation
2025-04-22 21:17:25,936:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:17:27,786:INFO:Calculating mean and std
2025-04-22 21:17:27,786:INFO:Creating metrics dataframe
2025-04-22 21:17:27,789:INFO:Finalizing model
2025-04-22 21:17:29,738:INFO:Uploading results into container
2025-04-22 21:17:29,738:INFO:Uploading model into container now
2025-04-22 21:17:29,739:INFO:_master_model_container: 130
2025-04-22 21:17:29,739:INFO:_display_container: 33
2025-04-22 21:17:29,739:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:17:29,739:INFO:create_model() successfully completed......................................
2025-04-22 21:17:29,965:INFO:SubProcess create_model() end ==================================
2025-04-22 21:17:29,965:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:17:29,965:INFO:SubProcess create_model() called ==================================
2025-04-22 21:17:29,965:INFO:Initializing create_model()
2025-04-22 21:17:29,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:17:29,966:INFO:Checking exceptions
2025-04-22 21:17:29,967:INFO:Importing libraries
2025-04-22 21:17:29,967:INFO:Copying training dataset
2025-04-22 21:17:29,973:INFO:Defining folds
2025-04-22 21:17:29,973:INFO:Declaring metric variables
2025-04-22 21:17:29,973:INFO:Importing untrained model
2025-04-22 21:17:29,973:INFO:Declaring custom model
2025-04-22 21:17:29,973:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:17:29,974:INFO:Starting cross validation
2025-04-22 21:17:29,974:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:17:32,547:INFO:Calculating mean and std
2025-04-22 21:17:32,548:INFO:Creating metrics dataframe
2025-04-22 21:17:32,549:INFO:Finalizing model
2025-04-22 21:17:35,271:INFO:Uploading results into container
2025-04-22 21:17:35,272:INFO:Uploading model into container now
2025-04-22 21:17:35,272:INFO:_master_model_container: 131
2025-04-22 21:17:35,272:INFO:_display_container: 33
2025-04-22 21:17:35,273:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:17:35,273:INFO:create_model() successfully completed......................................
2025-04-22 21:17:35,565:INFO:SubProcess create_model() end ==================================
2025-04-22 21:17:35,566:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:17:35,566:INFO:SubProcess create_model() called ==================================
2025-04-22 21:17:35,567:INFO:Initializing create_model()
2025-04-22 21:17:35,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:17:35,567:INFO:Checking exceptions
2025-04-22 21:17:35,569:INFO:Importing libraries
2025-04-22 21:17:35,569:INFO:Copying training dataset
2025-04-22 21:17:35,579:INFO:Defining folds
2025-04-22 21:17:35,579:INFO:Declaring metric variables
2025-04-22 21:17:35,580:INFO:Importing untrained model
2025-04-22 21:17:35,580:INFO:Declaring custom model
2025-04-22 21:17:35,581:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:17:35,582:INFO:Starting cross validation
2025-04-22 21:17:35,582:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:17:37,303:INFO:Calculating mean and std
2025-04-22 21:17:37,303:INFO:Creating metrics dataframe
2025-04-22 21:17:37,305:INFO:Finalizing model
2025-04-22 21:17:38,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:17:38,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:17:38,727:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:17:38,735:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:17:38,735:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:17:38,735:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:17:38,735:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:17:38,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.
2025-04-22 21:17:38,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:17:38,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:17:38,737:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:17:38,737:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:17:38,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:17:38,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:17:38,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:17:38,809:INFO:Uploading results into container
2025-04-22 21:17:38,810:INFO:Uploading model into container now
2025-04-22 21:17:38,810:INFO:_master_model_container: 132
2025-04-22 21:17:38,810:INFO:_display_container: 33
2025-04-22 21:17:38,811:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:17:38,811:INFO:create_model() successfully completed......................................
2025-04-22 21:17:39,052:INFO:SubProcess create_model() end ==================================
2025-04-22 21:17:39,053:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:17:39,053:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:17:39,053:INFO:choose_better completed
2025-04-22 21:17:39,054:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-04-22 21:17:39,060:INFO:_master_model_container: 132
2025-04-22 21:17:39,060:INFO:_display_container: 32
2025-04-22 21:17:39,061:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:17:39,061:INFO:blend_models() successfully completed......................................
2025-04-22 21:19:43,180:INFO:Initializing evaluate_model()
2025-04-22 21:19:43,180:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-22 21:19:43,193:INFO:Initializing plot_model()
2025-04-22 21:19:43,193:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-04-22 21:19:43,193:INFO:Checking exceptions
2025-04-22 21:19:43,197:INFO:Preloading libraries
2025-04-22 21:19:43,202:INFO:Copying training dataset
2025-04-22 21:19:43,202:INFO:Plot type: pipeline
2025-04-22 21:19:43,374:INFO:Visual Rendered Successfully
2025-04-22 21:19:43,679:INFO:plot_model() successfully completed......................................
2025-04-22 21:19:49,605:INFO:Initializing plot_model()
2025-04-22 21:19:49,606:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-04-22 21:19:49,606:INFO:Checking exceptions
2025-04-22 21:19:49,608:INFO:Preloading libraries
2025-04-22 21:19:49,612:INFO:Copying training dataset
2025-04-22 21:19:49,612:INFO:Plot type: confusion_matrix
2025-04-22 21:19:49,713:INFO:Fitting Model
2025-04-22 21:19:49,713:INFO:Scoring test/hold-out set
2025-04-22 21:19:49,714:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:19:49,714:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:19:49,714:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:19:49,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:19:49,721:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:19:49,721:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:19:49,830:INFO:Visual Rendered Successfully
2025-04-22 21:19:50,058:INFO:plot_model() successfully completed......................................
2025-04-22 21:22:03,311:INFO:Initializing blend_models()
2025-04-22 21:22:03,311:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=True, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:22:03,311:INFO:Checking exceptions
2025-04-22 21:22:03,327:INFO:Importing libraries
2025-04-22 21:22:03,328:INFO:Copying training dataset
2025-04-22 21:22:03,331:INFO:Getting model names
2025-04-22 21:22:03,334:INFO:SubProcess create_model() called ==================================
2025-04-22 21:22:03,338:INFO:Initializing create_model()
2025-04-22 21:22:03,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22B5EE890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:22:03,338:INFO:Checking exceptions
2025-04-22 21:22:03,338:INFO:Importing libraries
2025-04-22 21:22:03,339:INFO:Copying training dataset
2025-04-22 21:22:03,345:INFO:Defining folds
2025-04-22 21:22:03,345:INFO:Declaring metric variables
2025-04-22 21:22:03,348:INFO:Importing untrained model
2025-04-22 21:22:03,349:INFO:Declaring custom model
2025-04-22 21:22:03,354:INFO:Voting Classifier Imported successfully
2025-04-22 21:22:03,359:INFO:Starting cross validation
2025-04-22 21:22:03,360:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:22:06,435:INFO:Calculating mean and std
2025-04-22 21:22:06,436:INFO:Creating metrics dataframe
2025-04-22 21:22:06,441:INFO:Finalizing model
2025-04-22 21:22:08,748:INFO:Uploading results into container
2025-04-22 21:22:08,750:INFO:Uploading model into container now
2025-04-22 21:22:08,750:INFO:_master_model_container: 133
2025-04-22 21:22:08,750:INFO:_display_container: 33
2025-04-22 21:22:08,753:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-04-22 21:22:08,753:INFO:create_model() successfully completed......................................
2025-04-22 21:22:08,985:INFO:SubProcess create_model() end ==================================
2025-04-22 21:22:08,985:INFO:choose_better activated
2025-04-22 21:22:08,991:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for F1 is 0.5382
2025-04-22 21:22:08,992:INFO:SubProcess create_model() called ==================================
2025-04-22 21:22:08,992:INFO:Initializing create_model()
2025-04-22 21:22:08,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:22:08,992:INFO:Checking exceptions
2025-04-22 21:22:08,994:INFO:Importing libraries
2025-04-22 21:22:08,994:INFO:Copying training dataset
2025-04-22 21:22:09,000:INFO:Defining folds
2025-04-22 21:22:09,000:INFO:Declaring metric variables
2025-04-22 21:22:09,000:INFO:Importing untrained model
2025-04-22 21:22:09,000:INFO:Declaring custom model
2025-04-22 21:22:09,001:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:22:09,001:INFO:Starting cross validation
2025-04-22 21:22:09,001:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:22:10,624:INFO:Calculating mean and std
2025-04-22 21:22:10,624:INFO:Creating metrics dataframe
2025-04-22 21:22:10,626:INFO:Finalizing model
2025-04-22 21:22:12,427:INFO:Uploading results into container
2025-04-22 21:22:12,427:INFO:Uploading model into container now
2025-04-22 21:22:12,427:INFO:_master_model_container: 134
2025-04-22 21:22:12,428:INFO:_display_container: 34
2025-04-22 21:22:12,428:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:22:12,428:INFO:create_model() successfully completed......................................
2025-04-22 21:22:12,649:INFO:SubProcess create_model() end ==================================
2025-04-22 21:22:12,649:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:22:12,649:INFO:SubProcess create_model() called ==================================
2025-04-22 21:22:12,650:INFO:Initializing create_model()
2025-04-22 21:22:12,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:22:12,650:INFO:Checking exceptions
2025-04-22 21:22:12,651:INFO:Importing libraries
2025-04-22 21:22:12,651:INFO:Copying training dataset
2025-04-22 21:22:12,656:INFO:Defining folds
2025-04-22 21:22:12,656:INFO:Declaring metric variables
2025-04-22 21:22:12,656:INFO:Importing untrained model
2025-04-22 21:22:12,656:INFO:Declaring custom model
2025-04-22 21:22:12,657:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:22:12,657:INFO:Starting cross validation
2025-04-22 21:22:12,657:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:22:14,617:INFO:Calculating mean and std
2025-04-22 21:22:14,618:INFO:Creating metrics dataframe
2025-04-22 21:22:14,619:INFO:Finalizing model
2025-04-22 21:22:16,732:INFO:Uploading results into container
2025-04-22 21:22:16,732:INFO:Uploading model into container now
2025-04-22 21:22:16,733:INFO:_master_model_container: 135
2025-04-22 21:22:16,733:INFO:_display_container: 34
2025-04-22 21:22:16,733:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:22:16,733:INFO:create_model() successfully completed......................................
2025-04-22 21:22:16,958:INFO:SubProcess create_model() end ==================================
2025-04-22 21:22:16,959:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:22:16,959:INFO:SubProcess create_model() called ==================================
2025-04-22 21:22:16,959:INFO:Initializing create_model()
2025-04-22 21:22:16,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:22:16,959:INFO:Checking exceptions
2025-04-22 21:22:16,960:INFO:Importing libraries
2025-04-22 21:22:16,960:INFO:Copying training dataset
2025-04-22 21:22:16,967:INFO:Defining folds
2025-04-22 21:22:16,967:INFO:Declaring metric variables
2025-04-22 21:22:16,967:INFO:Importing untrained model
2025-04-22 21:22:16,967:INFO:Declaring custom model
2025-04-22 21:22:16,968:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:22:16,968:INFO:Starting cross validation
2025-04-22 21:22:16,968:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:22:18,287:INFO:Calculating mean and std
2025-04-22 21:22:18,288:INFO:Creating metrics dataframe
2025-04-22 21:22:18,289:INFO:Finalizing model
2025-04-22 21:22:19,572:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:22:19,572:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:22:19,572:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:22:19,578:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:22:19,578:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:22:19,578:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:22:19,578:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:22:19,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2025-04-22 21:22:19,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:22:19,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:22:19,580:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:22:19,580:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:22:19,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:22:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:22:19,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:22:19,642:INFO:Uploading results into container
2025-04-22 21:22:19,642:INFO:Uploading model into container now
2025-04-22 21:22:19,643:INFO:_master_model_container: 136
2025-04-22 21:22:19,643:INFO:_display_container: 34
2025-04-22 21:22:19,644:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:22:19,644:INFO:create_model() successfully completed......................................
2025-04-22 21:22:19,901:INFO:SubProcess create_model() end ==================================
2025-04-22 21:22:19,902:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:22:19,902:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:22:19,902:INFO:choose_better completed
2025-04-22 21:22:19,903:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-04-22 21:22:19,911:INFO:_master_model_container: 136
2025-04-22 21:22:19,911:INFO:_display_container: 33
2025-04-22 21:22:19,911:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:22:19,911:INFO:blend_models() successfully completed......................................
2025-04-22 21:23:16,218:INFO:Initializing blend_models()
2025-04-22 21:23:16,219:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=True, optimize=f1, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:23:16,219:INFO:Checking exceptions
2025-04-22 21:23:16,235:INFO:Importing libraries
2025-04-22 21:23:16,235:INFO:Copying training dataset
2025-04-22 21:23:16,239:INFO:Getting model names
2025-04-22 21:23:16,243:INFO:SubProcess create_model() called ==================================
2025-04-22 21:23:16,246:INFO:Initializing create_model()
2025-04-22 21:23:16,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21DBDE990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:23:16,246:INFO:Checking exceptions
2025-04-22 21:23:16,246:INFO:Importing libraries
2025-04-22 21:23:16,246:INFO:Copying training dataset
2025-04-22 21:23:16,253:INFO:Defining folds
2025-04-22 21:23:16,253:INFO:Declaring metric variables
2025-04-22 21:23:16,256:INFO:Importing untrained model
2025-04-22 21:23:16,256:INFO:Declaring custom model
2025-04-22 21:23:16,259:INFO:Voting Classifier Imported successfully
2025-04-22 21:23:16,265:INFO:Starting cross validation
2025-04-22 21:23:16,266:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:23:18,185:INFO:Calculating mean and std
2025-04-22 21:23:18,187:INFO:Creating metrics dataframe
2025-04-22 21:23:18,193:INFO:Finalizing model
2025-04-22 21:23:20,152:INFO:Uploading results into container
2025-04-22 21:23:20,153:INFO:Uploading model into container now
2025-04-22 21:23:20,153:INFO:_master_model_container: 137
2025-04-22 21:23:20,153:INFO:_display_container: 34
2025-04-22 21:23:20,157:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2025-04-22 21:23:20,157:INFO:create_model() successfully completed......................................
2025-04-22 21:23:20,384:INFO:SubProcess create_model() end ==================================
2025-04-22 21:23:20,384:INFO:choose_better activated
2025-04-22 21:23:20,391:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.4,
                                                         loss='log_loss',
                                                         max_depth=1,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.4,
                                                         min_samples_leaf=4,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=130,
                                                         n_iter_no_change=None...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=86,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=40, objective=None,
                                             random_state=42, reg_alpha=2,
                                             reg_lambda=0.001, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for F1 is 0.5386
2025-04-22 21:23:20,391:INFO:SubProcess create_model() called ==================================
2025-04-22 21:23:20,391:INFO:Initializing create_model()
2025-04-22 21:23:20,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:23:20,391:INFO:Checking exceptions
2025-04-22 21:23:20,392:INFO:Importing libraries
2025-04-22 21:23:20,392:INFO:Copying training dataset
2025-04-22 21:23:20,399:INFO:Defining folds
2025-04-22 21:23:20,399:INFO:Declaring metric variables
2025-04-22 21:23:20,399:INFO:Importing untrained model
2025-04-22 21:23:20,399:INFO:Declaring custom model
2025-04-22 21:23:20,399:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:23:20,400:INFO:Starting cross validation
2025-04-22 21:23:20,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:23:22,027:INFO:Calculating mean and std
2025-04-22 21:23:22,027:INFO:Creating metrics dataframe
2025-04-22 21:23:22,028:INFO:Finalizing model
2025-04-22 21:23:23,850:INFO:Uploading results into container
2025-04-22 21:23:23,850:INFO:Uploading model into container now
2025-04-22 21:23:23,850:INFO:_master_model_container: 138
2025-04-22 21:23:23,850:INFO:_display_container: 35
2025-04-22 21:23:23,851:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:23:23,851:INFO:create_model() successfully completed......................................
2025-04-22 21:23:24,079:INFO:SubProcess create_model() end ==================================
2025-04-22 21:23:24,081:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:23:24,081:INFO:SubProcess create_model() called ==================================
2025-04-22 21:23:24,082:INFO:Initializing create_model()
2025-04-22 21:23:24,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:23:24,082:INFO:Checking exceptions
2025-04-22 21:23:24,083:INFO:Importing libraries
2025-04-22 21:23:24,083:INFO:Copying training dataset
2025-04-22 21:23:24,087:INFO:Defining folds
2025-04-22 21:23:24,088:INFO:Declaring metric variables
2025-04-22 21:23:24,088:INFO:Importing untrained model
2025-04-22 21:23:24,088:INFO:Declaring custom model
2025-04-22 21:23:24,088:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:23:24,088:INFO:Starting cross validation
2025-04-22 21:23:24,090:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:23:25,424:INFO:Calculating mean and std
2025-04-22 21:23:25,425:INFO:Creating metrics dataframe
2025-04-22 21:23:25,426:INFO:Finalizing model
2025-04-22 21:23:26,741:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:23:26,741:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:23:26,741:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:23:26,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:23:26,747:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:23:26,747:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:23:26,747:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:23:26,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.
2025-04-22 21:23:26,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:23:26,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:23:26,753:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:23:26,753:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:23:26,753:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:23:26,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:23:26,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:23:26,812:INFO:Uploading results into container
2025-04-22 21:23:26,812:INFO:Uploading model into container now
2025-04-22 21:23:26,813:INFO:_master_model_container: 139
2025-04-22 21:23:26,813:INFO:_display_container: 35
2025-04-22 21:23:26,813:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:23:26,813:INFO:create_model() successfully completed......................................
2025-04-22 21:23:27,059:INFO:SubProcess create_model() end ==================================
2025-04-22 21:23:27,060:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:23:27,060:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:23:27,060:INFO:choose_better completed
2025-04-22 21:23:27,061:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2025-04-22 21:23:27,067:INFO:_master_model_container: 139
2025-04-22 21:23:27,067:INFO:_display_container: 34
2025-04-22 21:23:27,068:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:23:27,068:INFO:blend_models() successfully completed......................................
2025-04-22 21:25:35,406:INFO:Initializing stack_models()
2025-04-22 21:25:35,406:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:25:35,406:INFO:Checking exceptions
2025-04-22 21:25:35,410:INFO:Defining meta model
2025-04-22 21:25:35,427:INFO:Getting model names
2025-04-22 21:25:35,428:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False))]
2025-04-22 21:25:35,432:INFO:SubProcess create_model() called ==================================
2025-04-22 21:25:35,437:INFO:Initializing create_model()
2025-04-22 21:25:35,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D226DE1710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:25:35,437:INFO:Checking exceptions
2025-04-22 21:25:35,437:INFO:Importing libraries
2025-04-22 21:25:35,437:INFO:Copying training dataset
2025-04-22 21:25:35,447:INFO:Defining folds
2025-04-22 21:25:35,447:INFO:Declaring metric variables
2025-04-22 21:25:35,450:INFO:Importing untrained model
2025-04-22 21:25:35,450:INFO:Declaring custom model
2025-04-22 21:25:35,456:INFO:Stacking Classifier Imported successfully
2025-04-22 21:25:35,463:INFO:Starting cross validation
2025-04-22 21:25:35,463:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:25:45,562:INFO:Calculating mean and std
2025-04-22 21:25:45,564:INFO:Creating metrics dataframe
2025-04-22 21:25:45,570:INFO:Finalizing model
2025-04-22 21:25:50,285:INFO:Uploading results into container
2025-04-22 21:25:50,286:INFO:Uploading model into container now
2025-04-22 21:25:50,286:INFO:_master_model_container: 140
2025-04-22 21:25:50,286:INFO:_display_container: 35
2025-04-22 21:25:50,290:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-04-22 21:25:50,292:INFO:create_model() successfully completed......................................
2025-04-22 21:25:50,527:INFO:SubProcess create_model() end ==================================
2025-04-22 21:25:50,527:INFO:choose_better activated
2025-04-22 21:25:50,534:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0) result for F1 is 0.5343
2025-04-22 21:25:50,535:INFO:SubProcess create_model() called ==================================
2025-04-22 21:25:50,535:INFO:Initializing create_model()
2025-04-22 21:25:50,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:25:50,535:INFO:Checking exceptions
2025-04-22 21:25:50,537:INFO:Importing libraries
2025-04-22 21:25:50,537:INFO:Copying training dataset
2025-04-22 21:25:50,542:INFO:Defining folds
2025-04-22 21:25:50,542:INFO:Declaring metric variables
2025-04-22 21:25:50,542:INFO:Importing untrained model
2025-04-22 21:25:50,542:INFO:Declaring custom model
2025-04-22 21:25:50,542:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:25:50,542:INFO:Starting cross validation
2025-04-22 21:25:50,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:25:52,269:INFO:Calculating mean and std
2025-04-22 21:25:52,269:INFO:Creating metrics dataframe
2025-04-22 21:25:52,271:INFO:Finalizing model
2025-04-22 21:25:54,111:INFO:Uploading results into container
2025-04-22 21:25:54,111:INFO:Uploading model into container now
2025-04-22 21:25:54,111:INFO:_master_model_container: 141
2025-04-22 21:25:54,111:INFO:_display_container: 36
2025-04-22 21:25:54,112:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:25:54,112:INFO:create_model() successfully completed......................................
2025-04-22 21:25:54,336:INFO:SubProcess create_model() end ==================================
2025-04-22 21:25:54,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:25:54,336:INFO:SubProcess create_model() called ==================================
2025-04-22 21:25:54,337:INFO:Initializing create_model()
2025-04-22 21:25:54,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:25:54,337:INFO:Checking exceptions
2025-04-22 21:25:54,338:INFO:Importing libraries
2025-04-22 21:25:54,338:INFO:Copying training dataset
2025-04-22 21:25:54,343:INFO:Defining folds
2025-04-22 21:25:54,343:INFO:Declaring metric variables
2025-04-22 21:25:54,343:INFO:Importing untrained model
2025-04-22 21:25:54,343:INFO:Declaring custom model
2025-04-22 21:25:54,343:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:25:54,343:INFO:Starting cross validation
2025-04-22 21:25:54,344:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:25:56,347:INFO:Calculating mean and std
2025-04-22 21:25:56,347:INFO:Creating metrics dataframe
2025-04-22 21:25:56,349:INFO:Finalizing model
2025-04-22 21:25:58,496:INFO:Uploading results into container
2025-04-22 21:25:58,496:INFO:Uploading model into container now
2025-04-22 21:25:58,497:INFO:_master_model_container: 142
2025-04-22 21:25:58,497:INFO:_display_container: 36
2025-04-22 21:25:58,497:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:25:58,497:INFO:create_model() successfully completed......................................
2025-04-22 21:25:58,724:INFO:SubProcess create_model() end ==================================
2025-04-22 21:25:58,724:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:25:58,724:INFO:SubProcess create_model() called ==================================
2025-04-22 21:25:58,725:INFO:Initializing create_model()
2025-04-22 21:25:58,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:25:58,725:INFO:Checking exceptions
2025-04-22 21:25:58,726:INFO:Importing libraries
2025-04-22 21:25:58,726:INFO:Copying training dataset
2025-04-22 21:25:58,732:INFO:Defining folds
2025-04-22 21:25:58,732:INFO:Declaring metric variables
2025-04-22 21:25:58,732:INFO:Importing untrained model
2025-04-22 21:25:58,732:INFO:Declaring custom model
2025-04-22 21:25:58,733:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:25:58,733:INFO:Starting cross validation
2025-04-22 21:25:58,733:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:26:00,114:INFO:Calculating mean and std
2025-04-22 21:26:00,114:INFO:Creating metrics dataframe
2025-04-22 21:26:00,116:INFO:Finalizing model
2025-04-22 21:26:01,444:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:26:01,444:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:26:01,445:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:26:01,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:26:01,451:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:26:01,451:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:26:01,451:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:26:01,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.
2025-04-22 21:26:01,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:26:01,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:26:01,453:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:26:01,453:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:26:01,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:26:01,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,504:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:26:01,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:26:01,511:INFO:Uploading results into container
2025-04-22 21:26:01,511:INFO:Uploading model into container now
2025-04-22 21:26:01,512:INFO:_master_model_container: 143
2025-04-22 21:26:01,512:INFO:_display_container: 36
2025-04-22 21:26:01,512:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:26:01,512:INFO:create_model() successfully completed......................................
2025-04-22 21:26:01,751:INFO:SubProcess create_model() end ==================================
2025-04-22 21:26:01,752:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:26:01,752:INFO:SubProcess create_model() called ==================================
2025-04-22 21:26:01,752:INFO:Initializing create_model()
2025-04-22 21:26:01,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:26:01,752:INFO:Checking exceptions
2025-04-22 21:26:01,753:INFO:Importing libraries
2025-04-22 21:26:01,753:INFO:Copying training dataset
2025-04-22 21:26:01,759:INFO:Defining folds
2025-04-22 21:26:01,759:INFO:Declaring metric variables
2025-04-22 21:26:01,759:INFO:Importing untrained model
2025-04-22 21:26:01,759:INFO:Declaring custom model
2025-04-22 21:26:01,759:INFO:Logistic Regression Imported successfully
2025-04-22 21:26:01,759:INFO:Starting cross validation
2025-04-22 21:26:01,760:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:26:02,865:INFO:Calculating mean and std
2025-04-22 21:26:02,866:INFO:Creating metrics dataframe
2025-04-22 21:26:02,867:INFO:Finalizing model
2025-04-22 21:26:04,150:INFO:Uploading results into container
2025-04-22 21:26:04,151:INFO:Uploading model into container now
2025-04-22 21:26:04,151:INFO:_master_model_container: 144
2025-04-22 21:26:04,151:INFO:_display_container: 36
2025-04-22 21:26:04,152:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:26:04,152:INFO:create_model() successfully completed......................................
2025-04-22 21:26:04,379:INFO:SubProcess create_model() end ==================================
2025-04-22 21:26:04,380:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 21:26:04,380:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:26:04,380:INFO:choose_better completed
2025-04-22 21:26:04,380:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2025-04-22 21:26:04,387:INFO:_master_model_container: 144
2025-04-22 21:26:04,388:INFO:_display_container: 35
2025-04-22 21:26:04,388:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:26:04,388:INFO:stack_models() successfully completed......................................
2025-04-22 21:27:52,901:INFO:Initializing stack_models()
2025-04-22 21:27:52,901:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:27:52,903:INFO:Checking exceptions
2025-04-22 21:27:52,906:INFO:Defining meta model
2025-04-22 21:27:52,920:INFO:Getting model names
2025-04-22 21:27:52,921:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False))]
2025-04-22 21:27:52,925:INFO:SubProcess create_model() called ==================================
2025-04-22 21:27:52,929:INFO:Initializing create_model()
2025-04-22 21:27:52,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22C5DBF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:27:52,930:INFO:Checking exceptions
2025-04-22 21:27:52,930:INFO:Importing libraries
2025-04-22 21:27:52,930:INFO:Copying training dataset
2025-04-22 21:27:52,935:INFO:Defining folds
2025-04-22 21:27:52,936:INFO:Declaring metric variables
2025-04-22 21:27:52,939:INFO:Importing untrained model
2025-04-22 21:27:52,939:INFO:Declaring custom model
2025-04-22 21:27:52,943:INFO:Stacking Classifier Imported successfully
2025-04-22 21:27:52,949:INFO:Starting cross validation
2025-04-22 21:27:52,949:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:28:02,646:INFO:Calculating mean and std
2025-04-22 21:28:02,648:INFO:Creating metrics dataframe
2025-04-22 21:28:02,653:INFO:Finalizing model
2025-04-22 21:28:07,135:INFO:Uploading results into container
2025-04-22 21:28:07,135:INFO:Uploading model into container now
2025-04-22 21:28:07,136:INFO:_master_model_container: 145
2025-04-22 21:28:07,136:INFO:_display_container: 36
2025-04-22 21:28:07,141:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2025-04-22 21:28:07,141:INFO:create_model() successfully completed......................................
2025-04-22 21:28:07,373:INFO:SubProcess create_model() end ==================================
2025-04-22 21:28:07,373:INFO:choose_better activated
2025-04-22 21:28:07,381:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0) result for F1 is 0.5347
2025-04-22 21:28:07,381:INFO:SubProcess create_model() called ==================================
2025-04-22 21:28:07,381:INFO:Initializing create_model()
2025-04-22 21:28:07,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:28:07,381:INFO:Checking exceptions
2025-04-22 21:28:07,383:INFO:Importing libraries
2025-04-22 21:28:07,383:INFO:Copying training dataset
2025-04-22 21:28:07,388:INFO:Defining folds
2025-04-22 21:28:07,388:INFO:Declaring metric variables
2025-04-22 21:28:07,388:INFO:Importing untrained model
2025-04-22 21:28:07,389:INFO:Declaring custom model
2025-04-22 21:28:07,389:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:28:07,389:INFO:Starting cross validation
2025-04-22 21:28:07,390:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:28:09,108:INFO:Calculating mean and std
2025-04-22 21:28:09,108:INFO:Creating metrics dataframe
2025-04-22 21:28:09,109:INFO:Finalizing model
2025-04-22 21:28:10,927:INFO:Uploading results into container
2025-04-22 21:28:10,927:INFO:Uploading model into container now
2025-04-22 21:28:10,927:INFO:_master_model_container: 146
2025-04-22 21:28:10,927:INFO:_display_container: 37
2025-04-22 21:28:10,928:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:28:10,928:INFO:create_model() successfully completed......................................
2025-04-22 21:28:11,152:INFO:SubProcess create_model() end ==================================
2025-04-22 21:28:11,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:28:11,152:INFO:SubProcess create_model() called ==================================
2025-04-22 21:28:11,153:INFO:Initializing create_model()
2025-04-22 21:28:11,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:28:11,153:INFO:Checking exceptions
2025-04-22 21:28:11,154:INFO:Importing libraries
2025-04-22 21:28:11,154:INFO:Copying training dataset
2025-04-22 21:28:11,160:INFO:Defining folds
2025-04-22 21:28:11,160:INFO:Declaring metric variables
2025-04-22 21:28:11,160:INFO:Importing untrained model
2025-04-22 21:28:11,160:INFO:Declaring custom model
2025-04-22 21:28:11,160:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:28:11,160:INFO:Starting cross validation
2025-04-22 21:28:11,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:28:13,188:INFO:Calculating mean and std
2025-04-22 21:28:13,188:INFO:Creating metrics dataframe
2025-04-22 21:28:13,190:INFO:Finalizing model
2025-04-22 21:28:15,317:INFO:Uploading results into container
2025-04-22 21:28:15,317:INFO:Uploading model into container now
2025-04-22 21:28:15,317:INFO:_master_model_container: 147
2025-04-22 21:28:15,317:INFO:_display_container: 37
2025-04-22 21:28:15,317:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:28:15,317:INFO:create_model() successfully completed......................................
2025-04-22 21:28:15,541:INFO:SubProcess create_model() end ==================================
2025-04-22 21:28:15,542:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:28:15,542:INFO:SubProcess create_model() called ==================================
2025-04-22 21:28:15,542:INFO:Initializing create_model()
2025-04-22 21:28:15,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:28:15,542:INFO:Checking exceptions
2025-04-22 21:28:15,543:INFO:Importing libraries
2025-04-22 21:28:15,543:INFO:Copying training dataset
2025-04-22 21:28:15,549:INFO:Defining folds
2025-04-22 21:28:15,549:INFO:Declaring metric variables
2025-04-22 21:28:15,549:INFO:Importing untrained model
2025-04-22 21:28:15,549:INFO:Declaring custom model
2025-04-22 21:28:15,550:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:28:15,550:INFO:Starting cross validation
2025-04-22 21:28:15,551:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:28:16,911:INFO:Calculating mean and std
2025-04-22 21:28:16,911:INFO:Creating metrics dataframe
2025-04-22 21:28:16,913:INFO:Finalizing model
2025-04-22 21:28:18,226:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:28:18,226:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:28:18,226:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:28:18,233:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:28:18,233:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:28:18,233:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:28:18,233:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:28:18,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.
2025-04-22 21:28:18,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:28:18,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:28:18,235:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:28:18,235:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:28:18,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:28:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:28:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:28:18,294:INFO:Uploading results into container
2025-04-22 21:28:18,294:INFO:Uploading model into container now
2025-04-22 21:28:18,294:INFO:_master_model_container: 148
2025-04-22 21:28:18,294:INFO:_display_container: 37
2025-04-22 21:28:18,295:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:28:18,295:INFO:create_model() successfully completed......................................
2025-04-22 21:28:18,530:INFO:SubProcess create_model() end ==================================
2025-04-22 21:28:18,531:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:28:18,531:INFO:SubProcess create_model() called ==================================
2025-04-22 21:28:18,531:INFO:Initializing create_model()
2025-04-22 21:28:18,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:28:18,532:INFO:Checking exceptions
2025-04-22 21:28:18,533:INFO:Importing libraries
2025-04-22 21:28:18,533:INFO:Copying training dataset
2025-04-22 21:28:18,538:INFO:Defining folds
2025-04-22 21:28:18,538:INFO:Declaring metric variables
2025-04-22 21:28:18,538:INFO:Importing untrained model
2025-04-22 21:28:18,538:INFO:Declaring custom model
2025-04-22 21:28:18,539:INFO:Logistic Regression Imported successfully
2025-04-22 21:28:18,539:INFO:Starting cross validation
2025-04-22 21:28:18,540:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:28:19,591:INFO:Calculating mean and std
2025-04-22 21:28:19,591:INFO:Creating metrics dataframe
2025-04-22 21:28:19,592:INFO:Finalizing model
2025-04-22 21:28:20,899:INFO:Uploading results into container
2025-04-22 21:28:20,899:INFO:Uploading model into container now
2025-04-22 21:28:20,901:INFO:_master_model_container: 149
2025-04-22 21:28:20,901:INFO:_display_container: 37
2025-04-22 21:28:20,901:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-22 21:28:20,901:INFO:create_model() successfully completed......................................
2025-04-22 21:28:21,130:INFO:SubProcess create_model() end ==================================
2025-04-22 21:28:21,130:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for F1 is 0.5328
2025-04-22 21:28:21,130:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:28:21,130:INFO:choose_better completed
2025-04-22 21:28:21,131:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2025-04-22 21:28:21,138:INFO:_master_model_container: 149
2025-04-22 21:28:21,138:INFO:_display_container: 36
2025-04-22 21:28:21,139:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:28:21,139:INFO:stack_models() successfully completed......................................
2025-04-22 21:29:07,543:INFO:Initializing stack_models()
2025-04-22 21:29:07,543:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:29:07,544:INFO:Checking exceptions
2025-04-22 21:29:07,548:INFO:Defining meta model
2025-04-22 21:29:07,563:INFO:Getting model names
2025-04-22 21:29:07,564:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2025-04-22 21:29:07,568:INFO:SubProcess create_model() called ==================================
2025-04-22 21:29:07,572:INFO:Initializing create_model()
2025-04-22 21:29:07,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D21CBD21D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:29:07,572:INFO:Checking exceptions
2025-04-22 21:29:07,572:INFO:Importing libraries
2025-04-22 21:29:07,572:INFO:Copying training dataset
2025-04-22 21:29:07,580:INFO:Defining folds
2025-04-22 21:29:07,580:INFO:Declaring metric variables
2025-04-22 21:29:07,583:INFO:Importing untrained model
2025-04-22 21:29:07,583:INFO:Declaring custom model
2025-04-22 21:29:07,587:INFO:Stacking Classifier Imported successfully
2025-04-22 21:29:07,592:INFO:Starting cross validation
2025-04-22 21:29:07,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:29:18,699:INFO:Calculating mean and std
2025-04-22 21:29:18,700:INFO:Creating metrics dataframe
2025-04-22 21:29:18,706:INFO:Finalizing model
2025-04-22 21:29:23,234:INFO:Uploading results into container
2025-04-22 21:29:23,235:INFO:Uploading model into container now
2025-04-22 21:29:23,235:INFO:_master_model_container: 150
2025-04-22 21:29:23,235:INFO:_display_container: 37
2025-04-22 21:29:23,239:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2025-04-22 21:29:23,239:INFO:create_model() successfully completed......................................
2025-04-22 21:29:23,483:INFO:SubProcess create_model() end ==================================
2025-04-22 21:29:23,483:INFO:choose_better activated
2025-04-22 21:29:23,490:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0) result for F1 is 0.5342
2025-04-22 21:29:23,490:INFO:SubProcess create_model() called ==================================
2025-04-22 21:29:23,491:INFO:Initializing create_model()
2025-04-22 21:29:23,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:29:23,491:INFO:Checking exceptions
2025-04-22 21:29:23,493:INFO:Importing libraries
2025-04-22 21:29:23,493:INFO:Copying training dataset
2025-04-22 21:29:23,498:INFO:Defining folds
2025-04-22 21:29:23,498:INFO:Declaring metric variables
2025-04-22 21:29:23,498:INFO:Importing untrained model
2025-04-22 21:29:23,498:INFO:Declaring custom model
2025-04-22 21:29:23,499:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:29:23,499:INFO:Starting cross validation
2025-04-22 21:29:23,500:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:29:25,200:INFO:Calculating mean and std
2025-04-22 21:29:25,201:INFO:Creating metrics dataframe
2025-04-22 21:29:25,202:INFO:Finalizing model
2025-04-22 21:29:26,999:INFO:Uploading results into container
2025-04-22 21:29:27,000:INFO:Uploading model into container now
2025-04-22 21:29:27,000:INFO:_master_model_container: 151
2025-04-22 21:29:27,000:INFO:_display_container: 38
2025-04-22 21:29:27,000:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:29:27,001:INFO:create_model() successfully completed......................................
2025-04-22 21:29:27,223:INFO:SubProcess create_model() end ==================================
2025-04-22 21:29:27,223:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:29:27,223:INFO:SubProcess create_model() called ==================================
2025-04-22 21:29:27,224:INFO:Initializing create_model()
2025-04-22 21:29:27,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:29:27,224:INFO:Checking exceptions
2025-04-22 21:29:27,225:INFO:Importing libraries
2025-04-22 21:29:27,225:INFO:Copying training dataset
2025-04-22 21:29:27,232:INFO:Defining folds
2025-04-22 21:29:27,232:INFO:Declaring metric variables
2025-04-22 21:29:27,232:INFO:Importing untrained model
2025-04-22 21:29:27,232:INFO:Declaring custom model
2025-04-22 21:29:27,232:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:29:27,232:INFO:Starting cross validation
2025-04-22 21:29:27,233:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:29:29,315:INFO:Calculating mean and std
2025-04-22 21:29:29,316:INFO:Creating metrics dataframe
2025-04-22 21:29:29,317:INFO:Finalizing model
2025-04-22 21:29:31,438:INFO:Uploading results into container
2025-04-22 21:29:31,438:INFO:Uploading model into container now
2025-04-22 21:29:31,440:INFO:_master_model_container: 152
2025-04-22 21:29:31,440:INFO:_display_container: 38
2025-04-22 21:29:31,440:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:29:31,440:INFO:create_model() successfully completed......................................
2025-04-22 21:29:31,667:INFO:SubProcess create_model() end ==================================
2025-04-22 21:29:31,667:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:29:31,667:INFO:SubProcess create_model() called ==================================
2025-04-22 21:29:31,668:INFO:Initializing create_model()
2025-04-22 21:29:31,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:29:31,668:INFO:Checking exceptions
2025-04-22 21:29:31,669:INFO:Importing libraries
2025-04-22 21:29:31,669:INFO:Copying training dataset
2025-04-22 21:29:31,674:INFO:Defining folds
2025-04-22 21:29:31,674:INFO:Declaring metric variables
2025-04-22 21:29:31,675:INFO:Importing untrained model
2025-04-22 21:29:31,675:INFO:Declaring custom model
2025-04-22 21:29:31,676:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:29:31,676:INFO:Starting cross validation
2025-04-22 21:29:31,677:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:29:33,535:INFO:Calculating mean and std
2025-04-22 21:29:33,536:INFO:Creating metrics dataframe
2025-04-22 21:29:33,538:INFO:Finalizing model
2025-04-22 21:29:34,852:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:29:34,852:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:29:34,852:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:29:34,858:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:29:34,858:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:29:34,858:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:29:34,858:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:29:34,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.
2025-04-22 21:29:34,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:29:34,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:29:34,860:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:29:34,860:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:29:34,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:29:34,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:29:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:29:34,944:INFO:Uploading results into container
2025-04-22 21:29:34,944:INFO:Uploading model into container now
2025-04-22 21:29:34,945:INFO:_master_model_container: 153
2025-04-22 21:29:34,945:INFO:_display_container: 38
2025-04-22 21:29:34,945:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:29:34,946:INFO:create_model() successfully completed......................................
2025-04-22 21:29:35,216:INFO:SubProcess create_model() end ==================================
2025-04-22 21:29:35,216:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:29:35,217:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:29:35,217:INFO:choose_better completed
2025-04-22 21:29:35,217:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2025-04-22 21:29:35,224:INFO:_master_model_container: 153
2025-04-22 21:29:35,224:INFO:_display_container: 37
2025-04-22 21:29:35,225:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:29:35,225:INFO:stack_models() successfully completed......................................
2025-04-22 21:29:52,705:INFO:Initializing stack_models()
2025-04-22 21:29:52,705:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:29:52,705:INFO:Checking exceptions
2025-04-22 21:29:52,711:INFO:Defining meta model
2025-04-22 21:29:52,727:INFO:Getting model names
2025-04-22 21:29:52,728:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2025-04-22 21:29:52,732:INFO:SubProcess create_model() called ==================================
2025-04-22 21:29:52,736:INFO:Initializing create_model()
2025-04-22 21:29:52,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22B41F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:29:52,736:INFO:Checking exceptions
2025-04-22 21:29:52,736:INFO:Importing libraries
2025-04-22 21:29:52,737:INFO:Copying training dataset
2025-04-22 21:29:52,746:INFO:Defining folds
2025-04-22 21:29:52,746:INFO:Declaring metric variables
2025-04-22 21:29:52,750:INFO:Importing untrained model
2025-04-22 21:29:52,750:INFO:Declaring custom model
2025-04-22 21:29:52,755:INFO:Stacking Classifier Imported successfully
2025-04-22 21:29:52,762:INFO:Starting cross validation
2025-04-22 21:29:52,763:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:30:03,075:INFO:Calculating mean and std
2025-04-22 21:30:03,077:INFO:Creating metrics dataframe
2025-04-22 21:30:03,083:INFO:Finalizing model
2025-04-22 21:30:07,803:INFO:Uploading results into container
2025-04-22 21:30:07,803:INFO:Uploading model into container now
2025-04-22 21:30:07,804:INFO:_master_model_container: 154
2025-04-22 21:30:07,804:INFO:_display_container: 38
2025-04-22 21:30:07,809:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2025-04-22 21:30:07,809:INFO:create_model() successfully completed......................................
2025-04-22 21:30:08,044:INFO:SubProcess create_model() end ==================================
2025-04-22 21:30:08,045:INFO:choose_better activated
2025-04-22 21:30:08,051:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0) result for F1 is 0.5311
2025-04-22 21:30:08,051:INFO:SubProcess create_model() called ==================================
2025-04-22 21:30:08,052:INFO:Initializing create_model()
2025-04-22 21:30:08,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:30:08,052:INFO:Checking exceptions
2025-04-22 21:30:08,054:INFO:Importing libraries
2025-04-22 21:30:08,054:INFO:Copying training dataset
2025-04-22 21:30:08,060:INFO:Defining folds
2025-04-22 21:30:08,060:INFO:Declaring metric variables
2025-04-22 21:30:08,060:INFO:Importing untrained model
2025-04-22 21:30:08,060:INFO:Declaring custom model
2025-04-22 21:30:08,061:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:30:08,061:INFO:Starting cross validation
2025-04-22 21:30:08,061:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:30:10,214:INFO:Calculating mean and std
2025-04-22 21:30:10,215:INFO:Creating metrics dataframe
2025-04-22 21:30:10,216:INFO:Finalizing model
2025-04-22 21:30:12,266:INFO:Uploading results into container
2025-04-22 21:30:12,267:INFO:Uploading model into container now
2025-04-22 21:30:12,267:INFO:_master_model_container: 155
2025-04-22 21:30:12,267:INFO:_display_container: 39
2025-04-22 21:30:12,267:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:30:12,267:INFO:create_model() successfully completed......................................
2025-04-22 21:30:12,500:INFO:SubProcess create_model() end ==================================
2025-04-22 21:30:12,500:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:30:12,500:INFO:SubProcess create_model() called ==================================
2025-04-22 21:30:12,501:INFO:Initializing create_model()
2025-04-22 21:30:12,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:30:12,501:INFO:Checking exceptions
2025-04-22 21:30:12,502:INFO:Importing libraries
2025-04-22 21:30:12,502:INFO:Copying training dataset
2025-04-22 21:30:12,508:INFO:Defining folds
2025-04-22 21:30:12,508:INFO:Declaring metric variables
2025-04-22 21:30:12,508:INFO:Importing untrained model
2025-04-22 21:30:12,508:INFO:Declaring custom model
2025-04-22 21:30:12,509:INFO:Ada Boost Classifier Imported successfully
2025-04-22 21:30:12,509:INFO:Starting cross validation
2025-04-22 21:30:12,510:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:30:15,318:INFO:Calculating mean and std
2025-04-22 21:30:15,319:INFO:Creating metrics dataframe
2025-04-22 21:30:15,320:INFO:Finalizing model
2025-04-22 21:30:17,991:INFO:Uploading results into container
2025-04-22 21:30:17,992:INFO:Uploading model into container now
2025-04-22 21:30:17,992:INFO:_master_model_container: 156
2025-04-22 21:30:17,992:INFO:_display_container: 39
2025-04-22 21:30:17,992:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42)
2025-04-22 21:30:17,992:INFO:create_model() successfully completed......................................
2025-04-22 21:30:18,216:INFO:SubProcess create_model() end ==================================
2025-04-22 21:30:18,217:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.1,
                   n_estimators=180, random_state=42) result for F1 is 0.5374
2025-04-22 21:30:18,217:INFO:SubProcess create_model() called ==================================
2025-04-22 21:30:18,217:INFO:Initializing create_model()
2025-04-22 21:30:18,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:30:18,217:INFO:Checking exceptions
2025-04-22 21:30:18,218:INFO:Importing libraries
2025-04-22 21:30:18,219:INFO:Copying training dataset
2025-04-22 21:30:18,224:INFO:Defining folds
2025-04-22 21:30:18,224:INFO:Declaring metric variables
2025-04-22 21:30:18,224:INFO:Importing untrained model
2025-04-22 21:30:18,224:INFO:Declaring custom model
2025-04-22 21:30:18,225:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:30:18,225:INFO:Starting cross validation
2025-04-22 21:30:18,226:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:30:19,991:INFO:Calculating mean and std
2025-04-22 21:30:19,992:INFO:Creating metrics dataframe
2025-04-22 21:30:19,994:INFO:Finalizing model
2025-04-22 21:30:21,295:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:30:21,295:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:30:21,295:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:30:21,301:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:30:21,301:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:30:21,301:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:30:21,301:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:30:21,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
2025-04-22 21:30:21,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:30:21,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:30:21,303:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:30:21,303:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:30:21,303:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:30:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,356:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:30:21,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:30:21,363:INFO:Uploading results into container
2025-04-22 21:30:21,364:INFO:Uploading model into container now
2025-04-22 21:30:21,364:INFO:_master_model_container: 157
2025-04-22 21:30:21,364:INFO:_display_container: 39
2025-04-22 21:30:21,365:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:30:21,365:INFO:create_model() successfully completed......................................
2025-04-22 21:30:21,606:INFO:SubProcess create_model() end ==================================
2025-04-22 21:30:21,607:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:30:21,608:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:30:21,608:INFO:choose_better completed
2025-04-22 21:30:21,608:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2025-04-22 21:30:21,615:INFO:_master_model_container: 157
2025-04-22 21:30:21,615:INFO:_display_container: 38
2025-04-22 21:30:21,615:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:30:21,615:INFO:stack_models() successfully completed......................................
2025-04-22 21:31:37,009:INFO:Initializing stack_models()
2025-04-22 21:31:37,010:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:31:37,010:INFO:Checking exceptions
2025-04-22 21:31:37,013:INFO:Defining meta model
2025-04-22 21:31:37,029:INFO:Getting model names
2025-04-22 21:31:37,029:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2025-04-22 21:31:37,034:INFO:SubProcess create_model() called ==================================
2025-04-22 21:31:37,038:INFO:Initializing create_model()
2025-04-22 21:31:37,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22B41F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:31:37,038:INFO:Checking exceptions
2025-04-22 21:31:37,038:INFO:Importing libraries
2025-04-22 21:31:37,038:INFO:Copying training dataset
2025-04-22 21:31:37,046:INFO:Defining folds
2025-04-22 21:31:37,046:INFO:Declaring metric variables
2025-04-22 21:31:37,048:INFO:Importing untrained model
2025-04-22 21:31:37,048:INFO:Declaring custom model
2025-04-22 21:31:37,053:INFO:Stacking Classifier Imported successfully
2025-04-22 21:31:37,060:INFO:Starting cross validation
2025-04-22 21:31:37,060:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:31:42,222:INFO:Calculating mean and std
2025-04-22 21:31:42,224:INFO:Creating metrics dataframe
2025-04-22 21:31:42,229:INFO:Finalizing model
2025-04-22 21:31:45,483:INFO:Uploading results into container
2025-04-22 21:31:45,484:INFO:Uploading model into container now
2025-04-22 21:31:45,484:INFO:_master_model_container: 158
2025-04-22 21:31:45,484:INFO:_display_container: 39
2025-04-22 21:31:45,487:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2025-04-22 21:31:45,487:INFO:create_model() successfully completed......................................
2025-04-22 21:31:45,719:INFO:SubProcess create_model() end ==================================
2025-04-22 21:31:45,720:INFO:choose_better activated
2025-04-22 21:31:45,726:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0) result for F1 is 0.5311
2025-04-22 21:31:45,726:INFO:SubProcess create_model() called ==================================
2025-04-22 21:31:45,726:INFO:Initializing create_model()
2025-04-22 21:31:45,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:31:45,727:INFO:Checking exceptions
2025-04-22 21:31:45,728:INFO:Importing libraries
2025-04-22 21:31:45,728:INFO:Copying training dataset
2025-04-22 21:31:45,733:INFO:Defining folds
2025-04-22 21:31:45,733:INFO:Declaring metric variables
2025-04-22 21:31:45,733:INFO:Importing untrained model
2025-04-22 21:31:45,733:INFO:Declaring custom model
2025-04-22 21:31:45,734:INFO:Gradient Boosting Classifier Imported successfully
2025-04-22 21:31:45,734:INFO:Starting cross validation
2025-04-22 21:31:45,734:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:31:47,481:INFO:Calculating mean and std
2025-04-22 21:31:47,481:INFO:Creating metrics dataframe
2025-04-22 21:31:47,483:INFO:Finalizing model
2025-04-22 21:31:49,281:INFO:Uploading results into container
2025-04-22 21:31:49,282:INFO:Uploading model into container now
2025-04-22 21:31:49,282:INFO:_master_model_container: 159
2025-04-22 21:31:49,282:INFO:_display_container: 40
2025-04-22 21:31:49,283:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-22 21:31:49,283:INFO:create_model() successfully completed......................................
2025-04-22 21:31:49,508:INFO:SubProcess create_model() end ==================================
2025-04-22 21:31:49,509:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.5384
2025-04-22 21:31:49,509:INFO:SubProcess create_model() called ==================================
2025-04-22 21:31:49,509:INFO:Initializing create_model()
2025-04-22 21:31:49,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:31:49,509:INFO:Checking exceptions
2025-04-22 21:31:49,511:INFO:Importing libraries
2025-04-22 21:31:49,511:INFO:Copying training dataset
2025-04-22 21:31:49,516:INFO:Defining folds
2025-04-22 21:31:49,516:INFO:Declaring metric variables
2025-04-22 21:31:49,516:INFO:Importing untrained model
2025-04-22 21:31:49,516:INFO:Declaring custom model
2025-04-22 21:31:49,517:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:31:49,517:INFO:Starting cross validation
2025-04-22 21:31:49,518:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:31:50,914:INFO:Calculating mean and std
2025-04-22 21:31:50,914:INFO:Creating metrics dataframe
2025-04-22 21:31:50,916:INFO:Finalizing model
2025-04-22 21:31:52,231:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:31:52,231:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:31:52,231:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:31:52,237:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:31:52,237:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:31:52,237:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:31:52,237:INFO:[LightGBM] [Info] Number of positive: 15853, number of negative: 15853
2025-04-22 21:31:52,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.
2025-04-22 21:31:52,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-22 21:31:52,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-22 21:31:52,239:INFO:[LightGBM] [Info] Total Bins 111
2025-04-22 21:31:52,239:INFO:[LightGBM] [Info] Number of data points in the train set: 31706, number of used features: 4
2025-04-22 21:31:52,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-04-22 21:31:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-04-22 21:31:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-22 21:31:52,298:INFO:Uploading results into container
2025-04-22 21:31:52,298:INFO:Uploading model into container now
2025-04-22 21:31:52,299:INFO:_master_model_container: 160
2025-04-22 21:31:52,299:INFO:_display_container: 40
2025-04-22 21:31:52,299:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:31:52,299:INFO:create_model() successfully completed......................................
2025-04-22 21:31:52,540:INFO:SubProcess create_model() end ==================================
2025-04-22 21:31:52,541:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.5391
2025-04-22 21:31:52,541:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-22 21:31:52,541:INFO:choose_better completed
2025-04-22 21:31:52,542:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2025-04-22 21:31:52,548:INFO:_master_model_container: 160
2025-04-22 21:31:52,549:INFO:_display_container: 39
2025-04-22 21:31:52,549:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-22 21:31:52,549:INFO:stack_models() successfully completed......................................
2025-04-22 21:35:25,477:INFO:Initializing stack_models()
2025-04-22 21:35:25,477:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=True, optimize=f1, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-22 21:35:25,477:INFO:Checking exceptions
2025-04-22 21:35:25,482:INFO:Defining meta model
2025-04-22 21:35:25,498:INFO:Getting model names
2025-04-22 21:35:25,498:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=1,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.4, min_samples_leaf=4,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=42, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2025-04-22 21:35:25,502:INFO:SubProcess create_model() called ==================================
2025-04-22 21:35:25,505:INFO:Initializing create_model()
2025-04-22 21:35:25,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.4,
                                                           loss='log_loss',
                                                           max_depth=1,
                                                           max_features=1.0,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.4,
                                                           min_samples_leaf=4,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=130,
                                                           n_iter_no_chan...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=42,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D22B41F1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:35:25,505:INFO:Checking exceptions
2025-04-22 21:35:25,505:INFO:Importing libraries
2025-04-22 21:35:25,505:INFO:Copying training dataset
2025-04-22 21:35:25,514:INFO:Defining folds
2025-04-22 21:35:25,514:INFO:Declaring metric variables
2025-04-22 21:35:25,517:INFO:Importing untrained model
2025-04-22 21:35:25,517:INFO:Declaring custom model
2025-04-22 21:35:25,521:INFO:Stacking Classifier Imported successfully
2025-04-22 21:35:25,528:INFO:Starting cross validation
2025-04-22 21:35:25,529:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:35:30,906:INFO:Calculating mean and std
2025-04-22 21:35:30,908:INFO:Creating metrics dataframe
2025-04-22 21:35:30,914:INFO:Finalizing model
2025-04-22 21:35:43,083:INFO:Initializing create_model()
2025-04-22 21:35:43,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:35:43,083:INFO:Checking exceptions
2025-04-22 21:36:25,289:INFO:gpu_param set to False
2025-04-22 21:36:25,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:36:25,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:36:25,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:36:25,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:38:17,186:INFO:Initializing create_model()
2025-04-22 21:38:17,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:38:17,186:INFO:Checking exceptions
2025-04-22 21:39:12,808:INFO:Initializing create_model()
2025-04-22 21:39:12,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:39:12,808:INFO:Checking exceptions
2025-04-22 21:39:14,399:INFO:Initializing create_model()
2025-04-22 21:39:14,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:39:14,400:INFO:Checking exceptions
2025-04-22 21:41:11,900:INFO:Initializing plot_model()
2025-04-22 21:41:11,900:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:11,900:INFO:Checking exceptions
2025-04-22 21:41:11,905:INFO:Preloading libraries
2025-04-22 21:41:11,910:INFO:Copying training dataset
2025-04-22 21:41:11,910:INFO:Plot type: auc
2025-04-22 21:41:12,018:INFO:Fitting Model
2025-04-22 21:41:12,019:INFO:Scoring test/hold-out set
2025-04-22 21:41:12,020:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:12,020:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:12,020:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:12,025:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:12,025:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:12,025:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:12,204:INFO:Visual Rendered Successfully
2025-04-22 21:41:12,446:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:12,447:INFO:Initializing plot_model()
2025-04-22 21:41:12,447:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:12,447:INFO:Checking exceptions
2025-04-22 21:41:12,453:INFO:Preloading libraries
2025-04-22 21:41:12,456:INFO:Copying training dataset
2025-04-22 21:41:12,456:INFO:Plot type: confusion_matrix
2025-04-22 21:41:12,566:INFO:Fitting Model
2025-04-22 21:41:12,566:INFO:Scoring test/hold-out set
2025-04-22 21:41:12,567:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:12,567:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:12,567:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:12,573:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:12,574:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:12,574:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:12,693:INFO:Visual Rendered Successfully
2025-04-22 21:41:12,926:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:12,927:INFO:Initializing plot_model()
2025-04-22 21:41:12,927:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:12,927:INFO:Checking exceptions
2025-04-22 21:41:12,931:INFO:Preloading libraries
2025-04-22 21:41:12,934:INFO:Copying training dataset
2025-04-22 21:41:12,934:INFO:Plot type: pr
2025-04-22 21:41:13,045:INFO:Fitting Model
2025-04-22 21:41:13,046:INFO:Scoring test/hold-out set
2025-04-22 21:41:13,047:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:13,047:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:13,047:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:13,054:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:13,054:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:13,054:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:13,205:INFO:Visual Rendered Successfully
2025-04-22 21:41:13,447:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:13,448:INFO:Initializing plot_model()
2025-04-22 21:41:13,448:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:13,448:INFO:Checking exceptions
2025-04-22 21:41:13,452:INFO:Preloading libraries
2025-04-22 21:41:13,455:INFO:Copying training dataset
2025-04-22 21:41:13,455:INFO:Plot type: class_report
2025-04-22 21:41:13,561:INFO:Fitting Model
2025-04-22 21:41:13,562:INFO:Scoring test/hold-out set
2025-04-22 21:41:13,562:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:13,562:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:13,562:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:13,569:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:13,569:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:13,569:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:13,750:INFO:Visual Rendered Successfully
2025-04-22 21:41:13,984:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:13,985:INFO:Initializing plot_model()
2025-04-22 21:41:13,985:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:13,985:INFO:Checking exceptions
2025-04-22 21:41:13,991:INFO:Preloading libraries
2025-04-22 21:41:13,995:INFO:Copying training dataset
2025-04-22 21:41:13,995:INFO:Plot type: lift
2025-04-22 21:41:13,995:INFO:Generating predictions / predict_proba on X_test
2025-04-22 21:41:14,044:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:14,044:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:14,044:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:14,198:INFO:Visual Rendered Successfully
2025-04-22 21:41:14,433:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:14,434:INFO:Initializing plot_model()
2025-04-22 21:41:14,434:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:14,434:INFO:Checking exceptions
2025-04-22 21:41:14,437:INFO:Preloading libraries
2025-04-22 21:41:14,442:INFO:Copying training dataset
2025-04-22 21:41:14,442:INFO:Plot type: gain
2025-04-22 21:41:14,442:INFO:Generating predictions / predict_proba on X_test
2025-04-22 21:41:14,487:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:14,487:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:14,487:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:14,639:INFO:Visual Rendered Successfully
2025-04-22 21:41:14,870:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:14,872:INFO:Initializing plot_model()
2025-04-22 21:41:14,872:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:14,872:INFO:Checking exceptions
2025-04-22 21:41:14,876:INFO:Preloading libraries
2025-04-22 21:41:14,879:INFO:Copying training dataset
2025-04-22 21:41:14,879:INFO:Plot type: feature
2025-04-22 21:41:14,879:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 21:41:15,019:INFO:Visual Rendered Successfully
2025-04-22 21:41:15,277:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:39,850:INFO:Initializing plot_model()
2025-04-22 21:41:39,850:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:39,850:INFO:Checking exceptions
2025-04-22 21:41:39,856:INFO:Preloading libraries
2025-04-22 21:41:39,859:INFO:Copying training dataset
2025-04-22 21:41:39,859:INFO:Plot type: auc
2025-04-22 21:41:39,976:INFO:Fitting Model
2025-04-22 21:41:39,978:INFO:Scoring test/hold-out set
2025-04-22 21:41:39,979:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:39,979:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:39,979:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:39,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:39,985:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:39,986:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:40,169:INFO:Visual Rendered Successfully
2025-04-22 21:41:40,415:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:40,416:INFO:Initializing plot_model()
2025-04-22 21:41:40,416:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs={'percent': True}, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:40,416:INFO:Checking exceptions
2025-04-22 21:41:40,421:INFO:Preloading libraries
2025-04-22 21:41:40,424:INFO:Copying training dataset
2025-04-22 21:41:40,424:INFO:Plot type: confusion_matrix
2025-04-22 21:41:40,532:INFO:Fitting Model
2025-04-22 21:41:40,532:INFO:Scoring test/hold-out set
2025-04-22 21:41:40,533:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:40,533:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:40,533:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:40,539:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:40,540:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:40,540:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:40,655:INFO:Visual Rendered Successfully
2025-04-22 21:41:40,900:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:40,901:INFO:Initializing plot_model()
2025-04-22 21:41:40,901:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:40,901:INFO:Checking exceptions
2025-04-22 21:41:40,906:INFO:Preloading libraries
2025-04-22 21:41:40,915:INFO:Copying training dataset
2025-04-22 21:41:40,915:INFO:Plot type: confusion_matrix
2025-04-22 21:41:41,026:INFO:Fitting Model
2025-04-22 21:41:41,027:INFO:Scoring test/hold-out set
2025-04-22 21:41:41,028:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:41,028:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:41,028:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:41,033:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:41,033:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:41,033:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:41,151:INFO:Visual Rendered Successfully
2025-04-22 21:41:41,393:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:41,394:INFO:Initializing plot_model()
2025-04-22 21:41:41,394:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:41,394:INFO:Checking exceptions
2025-04-22 21:41:41,399:INFO:Preloading libraries
2025-04-22 21:41:41,403:INFO:Copying training dataset
2025-04-22 21:41:41,403:INFO:Plot type: pr
2025-04-22 21:41:41,511:INFO:Fitting Model
2025-04-22 21:41:41,512:INFO:Scoring test/hold-out set
2025-04-22 21:41:41,513:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:41,513:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:41,513:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:41,518:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:41,518:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:41,518:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:41,669:INFO:Visual Rendered Successfully
2025-04-22 21:41:41,908:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:41,909:INFO:Initializing plot_model()
2025-04-22 21:41:41,909:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:41,909:INFO:Checking exceptions
2025-04-22 21:41:41,913:INFO:Preloading libraries
2025-04-22 21:41:41,917:INFO:Copying training dataset
2025-04-22 21:41:41,917:INFO:Plot type: class_report
2025-04-22 21:41:42,025:INFO:Fitting Model
2025-04-22 21:41:42,025:INFO:Scoring test/hold-out set
2025-04-22 21:41:42,026:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:42,026:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:42,026:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:42,032:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:42,032:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:42,032:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:42,217:INFO:Visual Rendered Successfully
2025-04-22 21:41:42,451:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:42,453:INFO:Initializing plot_model()
2025-04-22 21:41:42,454:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=lift, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:42,454:INFO:Checking exceptions
2025-04-22 21:41:42,458:INFO:Preloading libraries
2025-04-22 21:41:42,461:INFO:Copying training dataset
2025-04-22 21:41:42,461:INFO:Plot type: lift
2025-04-22 21:41:42,462:INFO:Generating predictions / predict_proba on X_test
2025-04-22 21:41:42,512:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:42,512:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:42,512:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:42,663:INFO:Visual Rendered Successfully
2025-04-22 21:41:42,908:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:42,909:INFO:Initializing plot_model()
2025-04-22 21:41:42,909:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=gain, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:42,909:INFO:Checking exceptions
2025-04-22 21:41:42,913:INFO:Preloading libraries
2025-04-22 21:41:42,916:INFO:Copying training dataset
2025-04-22 21:41:42,916:INFO:Plot type: gain
2025-04-22 21:41:42,916:INFO:Generating predictions / predict_proba on X_test
2025-04-22 21:41:42,964:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-22 21:41:42,964:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-22 21:41:42,964:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-22 21:41:43,111:INFO:Visual Rendered Successfully
2025-04-22 21:41:43,344:INFO:plot_model() successfully completed......................................
2025-04-22 21:41:43,344:INFO:Initializing plot_model()
2025-04-22 21:41:43,344:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D21E45A910>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-04-22 21:41:43,345:INFO:Checking exceptions
2025-04-22 21:41:43,348:INFO:Preloading libraries
2025-04-22 21:41:43,352:INFO:Copying training dataset
2025-04-22 21:41:43,352:INFO:Plot type: feature
2025-04-22 21:41:43,353:WARNING:No coef_ found. Trying feature_importances_
2025-04-22 21:41:43,488:INFO:Visual Rendered Successfully
2025-04-22 21:41:43,722:INFO:plot_model() successfully completed......................................
2025-04-25 11:53:50,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 11:53:50,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 11:53:50,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 11:53:50,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 11:53:54,739:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:54,740:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:54,823:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:54,824:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:55,012:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:55,014:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:55,099:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:55,100:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:55,183:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:55,184:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:55,270:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:55,271:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 11:53:56,644:WARNING:<ipython-input-19-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-25 11:53:57,114:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:57,115:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:57,479:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:57,481:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:57,696:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:57,698:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:57,884:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:57,885:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:58,065:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:58,066:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:58,241:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 11:53:58,242:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 11:53:59,723:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-25 11:54:00,175:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-25 11:54:00,176:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-25 11:54:10,580:INFO:PyCaret ClassificationExperiment
2025-04-25 11:54:10,580:INFO:Logging name: baseline
2025-04-25 11:54:10,580:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-25 11:54:10,580:INFO:version 3.3.2
2025-04-25 11:54:10,580:INFO:Initializing setup()
2025-04-25 11:54:10,580:INFO:self.USI: 7e3c
2025-04-25 11:54:10,580:INFO:self._variable_keys: {'exp_name_log', '_available_plots', '_ml_usecase', 'gpu_param', 'memory', 'log_plots_param', 'logging_param', 'fix_imbalance', 'fold_shuffle_param', 'X_test', 'n_jobs_param', 'html_param', 'exp_id', 'y_test', 'X', 'X_train', 'seed', 'data', 'y', 'fold_generator', 'idx', 'target_param', 'USI', 'fold_groups_param', 'y_train', 'pipeline', 'gpu_n_jobs_param', 'is_multiclass'}
2025-04-25 11:54:10,580:INFO:Checking environment
2025-04-25 11:54:10,580:INFO:python_version: 3.11.4
2025-04-25 11:54:10,580:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-25 11:54:10,580:INFO:machine: AMD64
2025-04-25 11:54:10,580:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-25 11:54:10,597:INFO:Memory: svmem(total=16498810880, available=3323703296, percent=79.9, used=13175107584, free=3323703296)
2025-04-25 11:54:10,597:INFO:Physical Core: 8
2025-04-25 11:54:10,597:INFO:Logical Core: 16
2025-04-25 11:54:10,597:INFO:Checking libraries
2025-04-25 11:54:10,597:INFO:System:
2025-04-25 11:54:10,597:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-25 11:54:10,597:INFO:executable: c:\Python311\python.exe
2025-04-25 11:54:10,597:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-25 11:54:10,597:INFO:PyCaret required dependencies:
2025-04-25 11:54:10,600:INFO:                 pip: 23.1.2
2025-04-25 11:54:10,600:INFO:          setuptools: 65.5.0
2025-04-25 11:54:10,600:INFO:             pycaret: 3.3.2
2025-04-25 11:54:10,600:INFO:             IPython: 8.20.0
2025-04-25 11:54:10,600:INFO:          ipywidgets: 8.1.6
2025-04-25 11:54:10,600:INFO:                tqdm: 4.66.2
2025-04-25 11:54:10,600:INFO:               numpy: 1.26.2
2025-04-25 11:54:10,600:INFO:              pandas: 2.1.4
2025-04-25 11:54:10,600:INFO:              jinja2: 3.1.2
2025-04-25 11:54:10,600:INFO:               scipy: 1.11.4
2025-04-25 11:54:10,600:INFO:              joblib: 1.3.2
2025-04-25 11:54:10,600:INFO:             sklearn: 1.4.2
2025-04-25 11:54:10,600:INFO:                pyod: 2.0.4
2025-04-25 11:54:10,600:INFO:            imblearn: 0.12.0
2025-04-25 11:54:10,600:INFO:   category_encoders: 2.7.0
2025-04-25 11:54:10,600:INFO:            lightgbm: 4.6.0
2025-04-25 11:54:10,600:INFO:               numba: 0.61.2
2025-04-25 11:54:10,600:INFO:            requests: 2.31.0
2025-04-25 11:54:10,600:INFO:          matplotlib: 3.7.5
2025-04-25 11:54:10,600:INFO:          scikitplot: 0.3.7
2025-04-25 11:54:10,600:INFO:         yellowbrick: 1.5
2025-04-25 11:54:10,600:INFO:              plotly: 5.24.1
2025-04-25 11:54:10,600:INFO:    plotly-resampler: Not installed
2025-04-25 11:54:10,600:INFO:             kaleido: 0.2.1
2025-04-25 11:54:10,600:INFO:           schemdraw: 0.15
2025-04-25 11:54:10,600:INFO:         statsmodels: 0.14.4
2025-04-25 11:54:10,600:INFO:              sktime: 0.26.0
2025-04-25 11:54:10,600:INFO:               tbats: 1.1.3
2025-04-25 11:54:10,600:INFO:            pmdarima: 2.0.4
2025-04-25 11:54:10,600:INFO:              psutil: 5.9.8
2025-04-25 11:54:10,600:INFO:          markupsafe: 2.1.3
2025-04-25 11:54:10,600:INFO:             pickle5: Not installed
2025-04-25 11:54:10,600:INFO:         cloudpickle: 3.1.1
2025-04-25 11:54:10,600:INFO:         deprecation: 2.1.0
2025-04-25 11:54:10,600:INFO:              xxhash: 3.5.0
2025-04-25 11:54:10,600:INFO:           wurlitzer: Not installed
2025-04-25 11:54:10,600:INFO:PyCaret optional dependencies:
2025-04-25 11:54:10,740:INFO:                shap: Not installed
2025-04-25 11:54:10,740:INFO:           interpret: Not installed
2025-04-25 11:54:10,740:INFO:                umap: Not installed
2025-04-25 11:54:10,740:INFO:     ydata_profiling: Not installed
2025-04-25 11:54:10,740:INFO:  explainerdashboard: Not installed
2025-04-25 11:54:10,740:INFO:             autoviz: Not installed
2025-04-25 11:54:10,740:INFO:           fairlearn: Not installed
2025-04-25 11:54:10,740:INFO:          deepchecks: Not installed
2025-04-25 11:54:10,741:INFO:             xgboost: 3.0.0
2025-04-25 11:54:10,741:INFO:            catboost: 1.2.8
2025-04-25 11:54:10,741:INFO:              kmodes: Not installed
2025-04-25 11:54:10,741:INFO:             mlxtend: 0.23.4
2025-04-25 11:54:10,741:INFO:       statsforecast: Not installed
2025-04-25 11:54:10,741:INFO:        tune_sklearn: Not installed
2025-04-25 11:54:10,741:INFO:                 ray: Not installed
2025-04-25 11:54:10,741:INFO:            hyperopt: Not installed
2025-04-25 11:54:10,741:INFO:              optuna: Not installed
2025-04-25 11:54:10,741:INFO:               skopt: Not installed
2025-04-25 11:54:10,741:INFO:              mlflow: Not installed
2025-04-25 11:54:10,741:INFO:              gradio: Not installed
2025-04-25 11:54:10,741:INFO:             fastapi: Not installed
2025-04-25 11:54:10,741:INFO:             uvicorn: Not installed
2025-04-25 11:54:10,741:INFO:              m2cgen: Not installed
2025-04-25 11:54:10,741:INFO:           evidently: Not installed
2025-04-25 11:54:10,741:INFO:               fugue: Not installed
2025-04-25 11:54:10,741:INFO:           streamlit: Not installed
2025-04-25 11:54:10,741:INFO:             prophet: Not installed
2025-04-25 11:54:10,741:INFO:None
2025-04-25 11:54:10,741:INFO:Set up data.
2025-04-25 11:54:10,754:INFO:Set up folding strategy.
2025-04-25 11:54:10,754:INFO:Set up train/test split.
2025-04-25 11:54:10,772:INFO:Set up index.
2025-04-25 11:54:10,773:INFO:Assigning column types.
2025-04-25 11:54:10,785:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-25 11:54:10,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-25 11:54:10,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 11:54:10,858:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:10,860:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-25 11:54:12,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 11:54:12,508:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:12,510:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,511:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-25 11:54:12,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 11:54:12,572:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:12,574:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 11:54:12,637:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:12,639:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,640:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-25 11:54:12,702:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:12,704:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,765:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:12,767:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:12,769:INFO:Preparing preprocessing pipeline...
2025-04-25 11:54:12,771:INFO:Set up simple imputation.
2025-04-25 11:54:12,779:INFO:Set up encoding of ordinal features.
2025-04-25 11:54:12,786:INFO:Set up encoding of categorical features.
2025-04-25 11:54:12,916:INFO:Finished creating preprocessing pipeline.
2025-04-25 11:54:12,943:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-25 11:54:12,943:INFO:Creating final display dataframe.
2025-04-25 11:54:13,214:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        7e3c
2025-04-25 11:54:13,281:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:13,283:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:13,344:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 11:54:13,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 11:54:13,347:INFO:setup() successfully completed in 2.82s...............
2025-04-25 11:54:13,360:INFO:Initializing compare_models()
2025-04-25 11:54:13,360:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-25 11:54:13,361:INFO:Checking exceptions
2025-04-25 11:54:13,372:INFO:Preparing display monitor
2025-04-25 11:54:13,391:INFO:Initializing Logistic Regression
2025-04-25 11:54:13,392:INFO:Total runtime is 0.0 minutes
2025-04-25 11:54:13,395:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:13,395:INFO:Initializing create_model()
2025-04-25 11:54:13,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:13,395:INFO:Checking exceptions
2025-04-25 11:54:13,395:INFO:Importing libraries
2025-04-25 11:54:13,396:INFO:Copying training dataset
2025-04-25 11:54:13,412:INFO:Defining folds
2025-04-25 11:54:13,412:INFO:Declaring metric variables
2025-04-25 11:54:13,415:INFO:Importing untrained model
2025-04-25 11:54:13,417:INFO:Logistic Regression Imported successfully
2025-04-25 11:54:13,423:INFO:Starting cross validation
2025-04-25 11:54:13,425:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:18,232:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 11:54:18,232:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 11:54:18,235:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 11:54:18,285:INFO:Calculating mean and std
2025-04-25 11:54:18,286:INFO:Creating metrics dataframe
2025-04-25 11:54:18,288:INFO:Uploading results into container
2025-04-25 11:54:18,289:INFO:Uploading model into container now
2025-04-25 11:54:18,289:INFO:_master_model_container: 1
2025-04-25 11:54:18,289:INFO:_display_container: 2
2025-04-25 11:54:18,290:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-25 11:54:18,290:INFO:create_model() successfully completed......................................
2025-04-25 11:54:18,505:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:18,505:INFO:Creating metrics dataframe
2025-04-25 11:54:18,511:INFO:Initializing K Neighbors Classifier
2025-04-25 11:54:18,511:INFO:Total runtime is 0.08533966143925985 minutes
2025-04-25 11:54:18,514:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:18,514:INFO:Initializing create_model()
2025-04-25 11:54:18,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:18,515:INFO:Checking exceptions
2025-04-25 11:54:18,515:INFO:Importing libraries
2025-04-25 11:54:18,515:INFO:Copying training dataset
2025-04-25 11:54:18,533:INFO:Defining folds
2025-04-25 11:54:18,533:INFO:Declaring metric variables
2025-04-25 11:54:18,536:INFO:Importing untrained model
2025-04-25 11:54:18,539:INFO:K Neighbors Classifier Imported successfully
2025-04-25 11:54:18,545:INFO:Starting cross validation
2025-04-25 11:54:18,546:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:21,928:INFO:Calculating mean and std
2025-04-25 11:54:21,930:INFO:Creating metrics dataframe
2025-04-25 11:54:21,933:INFO:Uploading results into container
2025-04-25 11:54:21,934:INFO:Uploading model into container now
2025-04-25 11:54:21,934:INFO:_master_model_container: 2
2025-04-25 11:54:21,934:INFO:_display_container: 2
2025-04-25 11:54:21,935:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-25 11:54:21,935:INFO:create_model() successfully completed......................................
2025-04-25 11:54:22,110:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:22,110:INFO:Creating metrics dataframe
2025-04-25 11:54:22,115:INFO:Initializing Naive Bayes
2025-04-25 11:54:22,115:INFO:Total runtime is 0.14540528059005736 minutes
2025-04-25 11:54:22,118:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:22,118:INFO:Initializing create_model()
2025-04-25 11:54:22,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:22,118:INFO:Checking exceptions
2025-04-25 11:54:22,118:INFO:Importing libraries
2025-04-25 11:54:22,118:INFO:Copying training dataset
2025-04-25 11:54:22,135:INFO:Defining folds
2025-04-25 11:54:22,135:INFO:Declaring metric variables
2025-04-25 11:54:22,139:INFO:Importing untrained model
2025-04-25 11:54:22,142:INFO:Naive Bayes Imported successfully
2025-04-25 11:54:22,148:INFO:Starting cross validation
2025-04-25 11:54:22,149:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:24,723:INFO:Calculating mean and std
2025-04-25 11:54:24,725:INFO:Creating metrics dataframe
2025-04-25 11:54:24,728:INFO:Uploading results into container
2025-04-25 11:54:24,729:INFO:Uploading model into container now
2025-04-25 11:54:24,730:INFO:_master_model_container: 3
2025-04-25 11:54:24,730:INFO:_display_container: 2
2025-04-25 11:54:24,730:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 11:54:24,731:INFO:create_model() successfully completed......................................
2025-04-25 11:54:24,897:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:24,897:INFO:Creating metrics dataframe
2025-04-25 11:54:24,903:INFO:Initializing Decision Tree Classifier
2025-04-25 11:54:24,903:INFO:Total runtime is 0.19187275171279905 minutes
2025-04-25 11:54:24,905:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:24,905:INFO:Initializing create_model()
2025-04-25 11:54:24,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:24,905:INFO:Checking exceptions
2025-04-25 11:54:24,905:INFO:Importing libraries
2025-04-25 11:54:24,905:INFO:Copying training dataset
2025-04-25 11:54:24,922:INFO:Defining folds
2025-04-25 11:54:24,922:INFO:Declaring metric variables
2025-04-25 11:54:24,925:INFO:Importing untrained model
2025-04-25 11:54:24,928:INFO:Decision Tree Classifier Imported successfully
2025-04-25 11:54:24,934:INFO:Starting cross validation
2025-04-25 11:54:24,936:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:27,626:INFO:Calculating mean and std
2025-04-25 11:54:27,627:INFO:Creating metrics dataframe
2025-04-25 11:54:27,629:INFO:Uploading results into container
2025-04-25 11:54:27,630:INFO:Uploading model into container now
2025-04-25 11:54:27,630:INFO:_master_model_container: 4
2025-04-25 11:54:27,630:INFO:_display_container: 2
2025-04-25 11:54:27,631:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-25 11:54:27,631:INFO:create_model() successfully completed......................................
2025-04-25 11:54:27,783:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:27,783:INFO:Creating metrics dataframe
2025-04-25 11:54:27,789:INFO:Initializing SVM - Linear Kernel
2025-04-25 11:54:27,789:INFO:Total runtime is 0.2399792949358622 minutes
2025-04-25 11:54:27,792:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:27,792:INFO:Initializing create_model()
2025-04-25 11:54:27,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:27,792:INFO:Checking exceptions
2025-04-25 11:54:27,792:INFO:Importing libraries
2025-04-25 11:54:27,792:INFO:Copying training dataset
2025-04-25 11:54:27,811:INFO:Defining folds
2025-04-25 11:54:27,811:INFO:Declaring metric variables
2025-04-25 11:54:27,814:INFO:Importing untrained model
2025-04-25 11:54:27,817:INFO:SVM - Linear Kernel Imported successfully
2025-04-25 11:54:27,824:INFO:Starting cross validation
2025-04-25 11:54:27,825:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:28,676:INFO:Calculating mean and std
2025-04-25 11:54:28,677:INFO:Creating metrics dataframe
2025-04-25 11:54:28,679:INFO:Uploading results into container
2025-04-25 11:54:28,680:INFO:Uploading model into container now
2025-04-25 11:54:28,680:INFO:_master_model_container: 5
2025-04-25 11:54:28,680:INFO:_display_container: 2
2025-04-25 11:54:28,681:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-25 11:54:28,681:INFO:create_model() successfully completed......................................
2025-04-25 11:54:28,843:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:28,843:INFO:Creating metrics dataframe
2025-04-25 11:54:28,852:INFO:Initializing Ridge Classifier
2025-04-25 11:54:28,853:INFO:Total runtime is 0.2577004233996073 minutes
2025-04-25 11:54:28,856:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:28,857:INFO:Initializing create_model()
2025-04-25 11:54:28,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:28,857:INFO:Checking exceptions
2025-04-25 11:54:28,857:INFO:Importing libraries
2025-04-25 11:54:28,857:INFO:Copying training dataset
2025-04-25 11:54:28,883:INFO:Defining folds
2025-04-25 11:54:28,883:INFO:Declaring metric variables
2025-04-25 11:54:28,888:INFO:Importing untrained model
2025-04-25 11:54:28,894:INFO:Ridge Classifier Imported successfully
2025-04-25 11:54:28,909:INFO:Starting cross validation
2025-04-25 11:54:28,911:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:29,243:INFO:Calculating mean and std
2025-04-25 11:54:29,244:INFO:Creating metrics dataframe
2025-04-25 11:54:29,246:INFO:Uploading results into container
2025-04-25 11:54:29,247:INFO:Uploading model into container now
2025-04-25 11:54:29,248:INFO:_master_model_container: 6
2025-04-25 11:54:29,248:INFO:_display_container: 2
2025-04-25 11:54:29,248:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-25 11:54:29,248:INFO:create_model() successfully completed......................................
2025-04-25 11:54:29,422:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:29,423:INFO:Creating metrics dataframe
2025-04-25 11:54:29,432:INFO:Initializing Random Forest Classifier
2025-04-25 11:54:29,432:INFO:Total runtime is 0.2673595706621805 minutes
2025-04-25 11:54:29,436:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:29,437:INFO:Initializing create_model()
2025-04-25 11:54:29,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:29,437:INFO:Checking exceptions
2025-04-25 11:54:29,437:INFO:Importing libraries
2025-04-25 11:54:29,437:INFO:Copying training dataset
2025-04-25 11:54:29,461:INFO:Defining folds
2025-04-25 11:54:29,461:INFO:Declaring metric variables
2025-04-25 11:54:29,466:INFO:Importing untrained model
2025-04-25 11:54:29,471:INFO:Random Forest Classifier Imported successfully
2025-04-25 11:54:29,480:INFO:Starting cross validation
2025-04-25 11:54:29,481:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:32,466:INFO:Calculating mean and std
2025-04-25 11:54:32,468:INFO:Creating metrics dataframe
2025-04-25 11:54:32,470:INFO:Uploading results into container
2025-04-25 11:54:32,470:INFO:Uploading model into container now
2025-04-25 11:54:32,471:INFO:_master_model_container: 7
2025-04-25 11:54:32,471:INFO:_display_container: 2
2025-04-25 11:54:32,471:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-25 11:54:32,471:INFO:create_model() successfully completed......................................
2025-04-25 11:54:32,661:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:32,661:INFO:Creating metrics dataframe
2025-04-25 11:54:32,668:INFO:Initializing Quadratic Discriminant Analysis
2025-04-25 11:54:32,668:INFO:Total runtime is 0.3212968746821085 minutes
2025-04-25 11:54:32,672:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:32,672:INFO:Initializing create_model()
2025-04-25 11:54:32,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:32,672:INFO:Checking exceptions
2025-04-25 11:54:32,672:INFO:Importing libraries
2025-04-25 11:54:32,672:INFO:Copying training dataset
2025-04-25 11:54:32,693:INFO:Defining folds
2025-04-25 11:54:32,693:INFO:Declaring metric variables
2025-04-25 11:54:32,696:INFO:Importing untrained model
2025-04-25 11:54:32,700:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-25 11:54:32,708:INFO:Starting cross validation
2025-04-25 11:54:32,710:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:32,977:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 11:54:32,977:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 11:54:32,977:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 11:54:33,074:INFO:Calculating mean and std
2025-04-25 11:54:33,076:INFO:Creating metrics dataframe
2025-04-25 11:54:33,078:INFO:Uploading results into container
2025-04-25 11:54:33,079:INFO:Uploading model into container now
2025-04-25 11:54:33,079:INFO:_master_model_container: 8
2025-04-25 11:54:33,079:INFO:_display_container: 2
2025-04-25 11:54:33,080:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-25 11:54:33,080:INFO:create_model() successfully completed......................................
2025-04-25 11:54:33,244:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:33,244:INFO:Creating metrics dataframe
2025-04-25 11:54:33,253:INFO:Initializing Ada Boost Classifier
2025-04-25 11:54:33,253:INFO:Total runtime is 0.33103915850321447 minutes
2025-04-25 11:54:33,256:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:33,256:INFO:Initializing create_model()
2025-04-25 11:54:33,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:33,256:INFO:Checking exceptions
2025-04-25 11:54:33,256:INFO:Importing libraries
2025-04-25 11:54:33,256:INFO:Copying training dataset
2025-04-25 11:54:33,273:INFO:Defining folds
2025-04-25 11:54:33,273:INFO:Declaring metric variables
2025-04-25 11:54:33,278:INFO:Importing untrained model
2025-04-25 11:54:33,282:INFO:Ada Boost Classifier Imported successfully
2025-04-25 11:54:33,290:INFO:Starting cross validation
2025-04-25 11:54:33,291:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:33,470:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 11:54:33,470:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 11:54:33,470:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 11:54:33,472:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 11:54:33,478:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 11:54:35,179:INFO:Calculating mean and std
2025-04-25 11:54:35,181:INFO:Creating metrics dataframe
2025-04-25 11:54:35,182:INFO:Uploading results into container
2025-04-25 11:54:35,183:INFO:Uploading model into container now
2025-04-25 11:54:35,184:INFO:_master_model_container: 9
2025-04-25 11:54:35,184:INFO:_display_container: 2
2025-04-25 11:54:35,184:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-25 11:54:35,185:INFO:create_model() successfully completed......................................
2025-04-25 11:54:35,338:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:35,338:INFO:Creating metrics dataframe
2025-04-25 11:54:35,347:INFO:Initializing Gradient Boosting Classifier
2025-04-25 11:54:35,347:INFO:Total runtime is 0.3659402052561442 minutes
2025-04-25 11:54:35,350:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:35,351:INFO:Initializing create_model()
2025-04-25 11:54:35,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:35,351:INFO:Checking exceptions
2025-04-25 11:54:35,351:INFO:Importing libraries
2025-04-25 11:54:35,351:INFO:Copying training dataset
2025-04-25 11:54:35,372:INFO:Defining folds
2025-04-25 11:54:35,372:INFO:Declaring metric variables
2025-04-25 11:54:35,377:INFO:Importing untrained model
2025-04-25 11:54:35,380:INFO:Gradient Boosting Classifier Imported successfully
2025-04-25 11:54:35,387:INFO:Starting cross validation
2025-04-25 11:54:35,388:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:42,074:INFO:Calculating mean and std
2025-04-25 11:54:42,076:INFO:Creating metrics dataframe
2025-04-25 11:54:42,079:INFO:Uploading results into container
2025-04-25 11:54:42,080:INFO:Uploading model into container now
2025-04-25 11:54:42,080:INFO:_master_model_container: 10
2025-04-25 11:54:42,080:INFO:_display_container: 2
2025-04-25 11:54:42,081:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-25 11:54:42,081:INFO:create_model() successfully completed......................................
2025-04-25 11:54:42,224:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:42,224:INFO:Creating metrics dataframe
2025-04-25 11:54:42,232:INFO:Initializing Linear Discriminant Analysis
2025-04-25 11:54:42,232:INFO:Total runtime is 0.48069121042887364 minutes
2025-04-25 11:54:42,235:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:42,236:INFO:Initializing create_model()
2025-04-25 11:54:42,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:42,236:INFO:Checking exceptions
2025-04-25 11:54:42,236:INFO:Importing libraries
2025-04-25 11:54:42,236:INFO:Copying training dataset
2025-04-25 11:54:42,254:INFO:Defining folds
2025-04-25 11:54:42,254:INFO:Declaring metric variables
2025-04-25 11:54:42,257:INFO:Importing untrained model
2025-04-25 11:54:42,261:INFO:Linear Discriminant Analysis Imported successfully
2025-04-25 11:54:42,267:INFO:Starting cross validation
2025-04-25 11:54:42,269:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:42,527:INFO:Calculating mean and std
2025-04-25 11:54:42,529:INFO:Creating metrics dataframe
2025-04-25 11:54:42,530:INFO:Uploading results into container
2025-04-25 11:54:42,530:INFO:Uploading model into container now
2025-04-25 11:54:42,531:INFO:_master_model_container: 11
2025-04-25 11:54:42,531:INFO:_display_container: 2
2025-04-25 11:54:42,531:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-25 11:54:42,531:INFO:create_model() successfully completed......................................
2025-04-25 11:54:42,675:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:42,675:INFO:Creating metrics dataframe
2025-04-25 11:54:42,684:INFO:Initializing Extra Trees Classifier
2025-04-25 11:54:42,684:INFO:Total runtime is 0.48822982311248775 minutes
2025-04-25 11:54:42,687:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:42,688:INFO:Initializing create_model()
2025-04-25 11:54:42,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:42,688:INFO:Checking exceptions
2025-04-25 11:54:42,688:INFO:Importing libraries
2025-04-25 11:54:42,688:INFO:Copying training dataset
2025-04-25 11:54:42,706:INFO:Defining folds
2025-04-25 11:54:42,706:INFO:Declaring metric variables
2025-04-25 11:54:42,710:INFO:Importing untrained model
2025-04-25 11:54:42,714:INFO:Extra Trees Classifier Imported successfully
2025-04-25 11:54:42,720:INFO:Starting cross validation
2025-04-25 11:54:42,722:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:44,227:INFO:Calculating mean and std
2025-04-25 11:54:44,229:INFO:Creating metrics dataframe
2025-04-25 11:54:44,231:INFO:Uploading results into container
2025-04-25 11:54:44,231:INFO:Uploading model into container now
2025-04-25 11:54:44,232:INFO:_master_model_container: 12
2025-04-25 11:54:44,232:INFO:_display_container: 2
2025-04-25 11:54:44,232:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-25 11:54:44,232:INFO:create_model() successfully completed......................................
2025-04-25 11:54:44,388:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:44,388:INFO:Creating metrics dataframe
2025-04-25 11:54:44,399:INFO:Initializing Extreme Gradient Boosting
2025-04-25 11:54:44,399:INFO:Total runtime is 0.5168024937311808 minutes
2025-04-25 11:54:44,402:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:44,402:INFO:Initializing create_model()
2025-04-25 11:54:44,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:44,403:INFO:Checking exceptions
2025-04-25 11:54:44,403:INFO:Importing libraries
2025-04-25 11:54:44,403:INFO:Copying training dataset
2025-04-25 11:54:44,419:INFO:Defining folds
2025-04-25 11:54:44,419:INFO:Declaring metric variables
2025-04-25 11:54:44,423:INFO:Importing untrained model
2025-04-25 11:54:44,428:INFO:Extreme Gradient Boosting Imported successfully
2025-04-25 11:54:44,435:INFO:Starting cross validation
2025-04-25 11:54:44,436:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:45,473:INFO:Calculating mean and std
2025-04-25 11:54:45,474:INFO:Creating metrics dataframe
2025-04-25 11:54:45,476:INFO:Uploading results into container
2025-04-25 11:54:45,477:INFO:Uploading model into container now
2025-04-25 11:54:45,477:INFO:_master_model_container: 13
2025-04-25 11:54:45,478:INFO:_display_container: 2
2025-04-25 11:54:45,478:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-04-25 11:54:45,478:INFO:create_model() successfully completed......................................
2025-04-25 11:54:45,635:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:45,636:INFO:Creating metrics dataframe
2025-04-25 11:54:45,645:INFO:Initializing Light Gradient Boosting Machine
2025-04-25 11:54:45,645:INFO:Total runtime is 0.537575892607371 minutes
2025-04-25 11:54:45,648:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:45,649:INFO:Initializing create_model()
2025-04-25 11:54:45,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:45,649:INFO:Checking exceptions
2025-04-25 11:54:45,649:INFO:Importing libraries
2025-04-25 11:54:45,649:INFO:Copying training dataset
2025-04-25 11:54:45,678:INFO:Defining folds
2025-04-25 11:54:45,678:INFO:Declaring metric variables
2025-04-25 11:54:45,682:INFO:Importing untrained model
2025-04-25 11:54:45,687:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-25 11:54:45,694:INFO:Starting cross validation
2025-04-25 11:54:45,696:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:46,589:INFO:Calculating mean and std
2025-04-25 11:54:46,590:INFO:Creating metrics dataframe
2025-04-25 11:54:46,592:INFO:Uploading results into container
2025-04-25 11:54:46,593:INFO:Uploading model into container now
2025-04-25 11:54:46,593:INFO:_master_model_container: 14
2025-04-25 11:54:46,593:INFO:_display_container: 2
2025-04-25 11:54:46,595:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-25 11:54:46,595:INFO:create_model() successfully completed......................................
2025-04-25 11:54:46,783:INFO:SubProcess create_model() end ==================================
2025-04-25 11:54:46,783:INFO:Creating metrics dataframe
2025-04-25 11:54:46,791:INFO:Initializing CatBoost Classifier
2025-04-25 11:54:46,791:INFO:Total runtime is 0.556674591700236 minutes
2025-04-25 11:54:46,795:INFO:SubProcess create_model() called ==================================
2025-04-25 11:54:46,795:INFO:Initializing create_model()
2025-04-25 11:54:46,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:46,795:INFO:Checking exceptions
2025-04-25 11:54:46,795:INFO:Importing libraries
2025-04-25 11:54:46,795:INFO:Copying training dataset
2025-04-25 11:54:46,814:INFO:Defining folds
2025-04-25 11:54:46,814:INFO:Declaring metric variables
2025-04-25 11:54:46,820:INFO:Importing untrained model
2025-04-25 11:54:46,824:INFO:CatBoost Classifier Imported successfully
2025-04-25 11:54:46,841:INFO:Starting cross validation
2025-04-25 11:54:46,844:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:54:54,272:WARNING:c:\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
4 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Python311\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Python311\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "c:\Python311\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5023, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5072, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-04-25 11:54:54,272:INFO:Calculating mean and std
2025-04-25 11:54:54,273:INFO:Creating metrics dataframe
2025-04-25 11:54:54,275:INFO:Uploading results into container
2025-04-25 11:54:54,276:INFO:Uploading model into container now
2025-04-25 11:54:54,276:INFO:_master_model_container: 15
2025-04-25 11:54:54,276:INFO:_display_container: 2
2025-04-25 11:54:54,276:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D3E912B10>
2025-04-25 11:54:54,276:INFO:create_model() successfully completed......................................
2025-04-25 11:54:54,424:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000022D3E912B10> raised an exception or returned all 0.0, trying without fit_kwargs:
2025-04-25 11:54:54,426:WARNING:Traceback (most recent call last):
  File "c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-04-25 11:54:54,426:INFO:Initializing create_model()
2025-04-25 11:54:54,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:54:54,426:INFO:Checking exceptions
2025-04-25 11:54:54,428:INFO:Importing libraries
2025-04-25 11:54:54,428:INFO:Copying training dataset
2025-04-25 11:54:54,446:INFO:Defining folds
2025-04-25 11:54:54,446:INFO:Declaring metric variables
2025-04-25 11:54:54,449:INFO:Importing untrained model
2025-04-25 11:54:54,453:INFO:CatBoost Classifier Imported successfully
2025-04-25 11:54:54,458:INFO:Starting cross validation
2025-04-25 11:54:54,460:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:55:23,633:INFO:Calculating mean and std
2025-04-25 11:55:23,634:INFO:Creating metrics dataframe
2025-04-25 11:55:23,636:INFO:Uploading results into container
2025-04-25 11:55:23,637:INFO:Uploading model into container now
2025-04-25 11:55:23,637:INFO:_master_model_container: 16
2025-04-25 11:55:23,638:INFO:_display_container: 2
2025-04-25 11:55:23,638:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D3D673B50>
2025-04-25 11:55:23,638:INFO:create_model() successfully completed......................................
2025-04-25 11:55:23,837:INFO:SubProcess create_model() end ==================================
2025-04-25 11:55:23,837:INFO:Creating metrics dataframe
2025-04-25 11:55:23,847:INFO:Initializing Dummy Classifier
2025-04-25 11:55:23,847:INFO:Total runtime is 1.174273995558421 minutes
2025-04-25 11:55:23,850:INFO:SubProcess create_model() called ==================================
2025-04-25 11:55:23,850:INFO:Initializing create_model()
2025-04-25 11:55:23,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D3A7AF1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:55:23,850:INFO:Checking exceptions
2025-04-25 11:55:23,851:INFO:Importing libraries
2025-04-25 11:55:23,851:INFO:Copying training dataset
2025-04-25 11:55:23,870:INFO:Defining folds
2025-04-25 11:55:23,871:INFO:Declaring metric variables
2025-04-25 11:55:23,875:INFO:Importing untrained model
2025-04-25 11:55:23,878:INFO:Dummy Classifier Imported successfully
2025-04-25 11:55:23,884:INFO:Starting cross validation
2025-04-25 11:55:23,887:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 11:55:24,130:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 11:55:24,141:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 11:55:24,157:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 11:55:24,176:INFO:Calculating mean and std
2025-04-25 11:55:24,182:INFO:Creating metrics dataframe
2025-04-25 11:55:24,184:INFO:Uploading results into container
2025-04-25 11:55:24,185:INFO:Uploading model into container now
2025-04-25 11:55:24,185:INFO:_master_model_container: 17
2025-04-25 11:55:24,186:INFO:_display_container: 2
2025-04-25 11:55:24,186:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-25 11:55:24,186:INFO:create_model() successfully completed......................................
2025-04-25 11:55:24,383:INFO:SubProcess create_model() end ==================================
2025-04-25 11:55:24,383:INFO:Creating metrics dataframe
2025-04-25 11:55:24,396:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-25 11:55:24,403:INFO:Initializing create_model()
2025-04-25 11:55:24,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D3D5734D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 11:55:24,404:INFO:Checking exceptions
2025-04-25 11:55:24,405:INFO:Importing libraries
2025-04-25 11:55:24,405:INFO:Copying training dataset
2025-04-25 11:55:24,428:INFO:Defining folds
2025-04-25 11:55:24,428:INFO:Declaring metric variables
2025-04-25 11:55:24,428:INFO:Importing untrained model
2025-04-25 11:55:24,428:INFO:Declaring custom model
2025-04-25 11:55:24,430:INFO:Naive Bayes Imported successfully
2025-04-25 11:55:24,431:INFO:Cross validation set to False
2025-04-25 11:55:24,431:INFO:Fitting Model
2025-04-25 11:55:24,561:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 11:55:24,561:INFO:create_model() successfully completed......................................
2025-04-25 11:55:24,765:INFO:_master_model_container: 17
2025-04-25 11:55:24,766:INFO:_display_container: 2
2025-04-25 11:55:24,766:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 11:55:24,766:INFO:compare_models() successfully completed......................................
2025-04-25 12:04:22,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 12:04:22,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 12:04:22,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 12:04:22,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-25 12:04:25,458:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,459:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:25,537:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,538:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:25,724:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,725:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:25,806:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,807:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:25,889:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,890:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:25,973:WARNING:<ipython-input-15-1a6bf577c5b8>:23: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:25,974:WARNING:<ipython-input-15-1a6bf577c5b8>:27: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize = 14)

2025-04-25 12:04:27,310:WARNING:<ipython-input-19-402454ba1a67>:20: UserWarning: Legend does not support handles for str instances.
A proxy artist may be used instead.
See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries
  plt.legend("Female",

2025-04-25 12:04:27,757:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:27,758:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:28,081:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:28,082:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:28,264:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:28,265:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:28,448:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:28,449:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:28,628:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:28,630:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:28,818:WARNING:<ipython-input-20-9e529f7f1745>:13: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)

2025-04-25 12:04:28,819:WARNING:<ipython-input-20-9e529f7f1745>:17: UserWarning: FixedFormatter should only be used together with FixedLocator
  ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)

2025-04-25 12:04:30,227:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.
  warnings.warn("p-value may not be accurate for N > 5000.")

2025-04-25 12:04:30,663:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.
  warnings.warn("Input data for shapiro has range zero. The results "

2025-04-25 12:04:30,664:WARNING:c:\Python311\Lib\site-packages\scipy\stats\_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.
  res = hypotest_fun_out(*samples, **kwds)

2025-04-25 12:04:40,855:INFO:PyCaret ClassificationExperiment
2025-04-25 12:04:40,855:INFO:Logging name: baseline
2025-04-25 12:04:40,855:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-25 12:04:40,855:INFO:version 3.3.2
2025-04-25 12:04:40,855:INFO:Initializing setup()
2025-04-25 12:04:40,855:INFO:self.USI: 2338
2025-04-25 12:04:40,855:INFO:self._variable_keys: {'n_jobs_param', 'idx', 'pipeline', 'fold_shuffle_param', 'data', 'USI', 'y_test', 'fold_groups_param', '_ml_usecase', 'target_param', 'html_param', 'exp_name_log', 'is_multiclass', 'y', 'seed', 'fix_imbalance', 'X', 'y_train', 'X_test', 'fold_generator', 'logging_param', 'gpu_n_jobs_param', 'log_plots_param', 'X_train', 'exp_id', 'memory', '_available_plots', 'gpu_param'}
2025-04-25 12:04:40,855:INFO:Checking environment
2025-04-25 12:04:40,855:INFO:python_version: 3.11.4
2025-04-25 12:04:40,855:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-25 12:04:40,855:INFO:machine: AMD64
2025-04-25 12:04:40,855:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-25 12:04:40,864:INFO:Memory: svmem(total=16498810880, available=4688433152, percent=71.6, used=11810377728, free=4688433152)
2025-04-25 12:04:40,864:INFO:Physical Core: 8
2025-04-25 12:04:40,864:INFO:Logical Core: 16
2025-04-25 12:04:40,864:INFO:Checking libraries
2025-04-25 12:04:40,864:INFO:System:
2025-04-25 12:04:40,864:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-25 12:04:40,864:INFO:executable: c:\Python311\python.exe
2025-04-25 12:04:40,864:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-25 12:04:40,864:INFO:PyCaret required dependencies:
2025-04-25 12:04:40,866:INFO:                 pip: 23.1.2
2025-04-25 12:04:40,866:INFO:          setuptools: 65.5.0
2025-04-25 12:04:40,866:INFO:             pycaret: 3.3.2
2025-04-25 12:04:40,866:INFO:             IPython: 8.20.0
2025-04-25 12:04:40,866:INFO:          ipywidgets: 8.1.6
2025-04-25 12:04:40,866:INFO:                tqdm: 4.66.2
2025-04-25 12:04:40,866:INFO:               numpy: 1.26.2
2025-04-25 12:04:40,866:INFO:              pandas: 2.1.4
2025-04-25 12:04:40,866:INFO:              jinja2: 3.1.2
2025-04-25 12:04:40,867:INFO:               scipy: 1.11.4
2025-04-25 12:04:40,867:INFO:              joblib: 1.3.2
2025-04-25 12:04:40,867:INFO:             sklearn: 1.4.2
2025-04-25 12:04:40,867:INFO:                pyod: 2.0.4
2025-04-25 12:04:40,867:INFO:            imblearn: 0.12.0
2025-04-25 12:04:40,867:INFO:   category_encoders: 2.7.0
2025-04-25 12:04:40,867:INFO:            lightgbm: 4.6.0
2025-04-25 12:04:40,867:INFO:               numba: 0.61.2
2025-04-25 12:04:40,867:INFO:            requests: 2.31.0
2025-04-25 12:04:40,867:INFO:          matplotlib: 3.7.5
2025-04-25 12:04:40,867:INFO:          scikitplot: 0.3.7
2025-04-25 12:04:40,867:INFO:         yellowbrick: 1.5
2025-04-25 12:04:40,867:INFO:              plotly: 5.24.1
2025-04-25 12:04:40,867:INFO:    plotly-resampler: Not installed
2025-04-25 12:04:40,867:INFO:             kaleido: 0.2.1
2025-04-25 12:04:40,867:INFO:           schemdraw: 0.15
2025-04-25 12:04:40,867:INFO:         statsmodels: 0.14.4
2025-04-25 12:04:40,867:INFO:              sktime: 0.26.0
2025-04-25 12:04:40,867:INFO:               tbats: 1.1.3
2025-04-25 12:04:40,867:INFO:            pmdarima: 2.0.4
2025-04-25 12:04:40,867:INFO:              psutil: 5.9.8
2025-04-25 12:04:40,867:INFO:          markupsafe: 2.1.3
2025-04-25 12:04:40,867:INFO:             pickle5: Not installed
2025-04-25 12:04:40,867:INFO:         cloudpickle: 3.1.1
2025-04-25 12:04:40,867:INFO:         deprecation: 2.1.0
2025-04-25 12:04:40,867:INFO:              xxhash: 3.5.0
2025-04-25 12:04:40,867:INFO:           wurlitzer: Not installed
2025-04-25 12:04:40,867:INFO:PyCaret optional dependencies:
2025-04-25 12:04:40,905:INFO:                shap: Not installed
2025-04-25 12:04:40,905:INFO:           interpret: Not installed
2025-04-25 12:04:40,905:INFO:                umap: Not installed
2025-04-25 12:04:40,905:INFO:     ydata_profiling: Not installed
2025-04-25 12:04:40,905:INFO:  explainerdashboard: Not installed
2025-04-25 12:04:40,905:INFO:             autoviz: Not installed
2025-04-25 12:04:40,905:INFO:           fairlearn: Not installed
2025-04-25 12:04:40,905:INFO:          deepchecks: Not installed
2025-04-25 12:04:40,905:INFO:             xgboost: 3.0.0
2025-04-25 12:04:40,905:INFO:            catboost: 1.2.8
2025-04-25 12:04:40,905:INFO:              kmodes: Not installed
2025-04-25 12:04:40,905:INFO:             mlxtend: 0.23.4
2025-04-25 12:04:40,905:INFO:       statsforecast: Not installed
2025-04-25 12:04:40,905:INFO:        tune_sklearn: Not installed
2025-04-25 12:04:40,905:INFO:                 ray: Not installed
2025-04-25 12:04:40,905:INFO:            hyperopt: Not installed
2025-04-25 12:04:40,905:INFO:              optuna: Not installed
2025-04-25 12:04:40,905:INFO:               skopt: Not installed
2025-04-25 12:04:40,905:INFO:              mlflow: Not installed
2025-04-25 12:04:40,905:INFO:              gradio: Not installed
2025-04-25 12:04:40,905:INFO:             fastapi: Not installed
2025-04-25 12:04:40,906:INFO:             uvicorn: Not installed
2025-04-25 12:04:40,906:INFO:              m2cgen: Not installed
2025-04-25 12:04:40,906:INFO:           evidently: Not installed
2025-04-25 12:04:40,906:INFO:               fugue: Not installed
2025-04-25 12:04:40,906:INFO:           streamlit: Not installed
2025-04-25 12:04:40,906:INFO:             prophet: Not installed
2025-04-25 12:04:40,906:INFO:None
2025-04-25 12:04:40,906:INFO:Set up data.
2025-04-25 12:04:40,918:INFO:Set up folding strategy.
2025-04-25 12:04:40,918:INFO:Set up train/test split.
2025-04-25 12:04:40,943:INFO:Set up index.
2025-04-25 12:04:40,944:INFO:Assigning column types.
2025-04-25 12:04:40,955:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-25 12:04:40,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-25 12:04:40,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 12:04:41,026:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,028:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-25 12:04:41,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 12:04:41,113:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,115:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,116:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-25 12:04:41,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 12:04:41,178:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,180:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-25 12:04:41,241:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,244:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,244:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-25 12:04:41,307:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,309:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,369:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,372:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,373:INFO:Preparing preprocessing pipeline...
2025-04-25 12:04:41,376:INFO:Set up simple imputation.
2025-04-25 12:04:41,384:INFO:Set up encoding of ordinal features.
2025-04-25 12:04:41,391:INFO:Set up encoding of categorical features.
2025-04-25 12:04:41,507:INFO:Finished creating preprocessing pipeline.
2025-04-25 12:04:41,537:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\BEIBAR~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'AGE',
                                             'Sept_Pay_status',
                                             'August_Pay_status',
                                             'July_Pay_status',
                                             'June_Pay_status',
                                             'May_Pay_status',
                                             'April_Pay_status',
                                             'Sept_Bill_Amount',
                                             'August_Bill_Amount',
                                             'July_Bill_Amount',
                                             'June_Bill_Am...
                                                                        {'col': 'MARRIAGE',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['EDUCATION'],
                                    transformer=OneHotEncoder(cols=['EDUCATION'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-04-25 12:04:41,538:INFO:Creating final display dataframe.
2025-04-25 12:04:41,809:INFO:Setup _display_container:                     Description                       Value
0                    Session id                          42
1                        Target  default_payment_next_month
2                   Target type                      Binary
3           Original data shape                 (29163, 24)
4        Transformed data shape                 (29163, 26)
5   Transformed train set shape                 (20414, 26)
6    Transformed test set shape                  (8749, 26)
7              Numeric features                          20
8          Categorical features                           3
9                    Preprocess                        True
10              Imputation type                      simple
11           Numeric imputation                        mean
12       Categorical imputation                        mode
13     Maximum one-hot encoding                          25
14              Encoding method                        None
15               Fold Generator             StratifiedKFold
16                  Fold Number                           5
17                     CPU Jobs                          -1
18                      Use GPU                       False
19               Log Experiment                       False
20              Experiment Name                    baseline
21                          USI                        2338
2025-04-25 12:04:41,875:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,877:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,938:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-25 12:04:41,941:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-25 12:04:41,943:INFO:setup() successfully completed in 1.11s...............
2025-04-25 12:04:41,953:INFO:Initializing compare_models()
2025-04-25 12:04:41,953:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-04-25 12:04:41,953:INFO:Checking exceptions
2025-04-25 12:04:41,965:INFO:Preparing display monitor
2025-04-25 12:04:41,983:INFO:Initializing Logistic Regression
2025-04-25 12:04:41,984:INFO:Total runtime is 1.6621748606363933e-05 minutes
2025-04-25 12:04:41,986:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:41,986:INFO:Initializing create_model()
2025-04-25 12:04:41,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:41,986:INFO:Checking exceptions
2025-04-25 12:04:41,986:INFO:Importing libraries
2025-04-25 12:04:41,986:INFO:Copying training dataset
2025-04-25 12:04:42,003:INFO:Defining folds
2025-04-25 12:04:42,003:INFO:Declaring metric variables
2025-04-25 12:04:42,007:INFO:Importing untrained model
2025-04-25 12:04:42,009:INFO:Logistic Regression Imported successfully
2025-04-25 12:04:42,014:INFO:Starting cross validation
2025-04-25 12:04:42,015:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:46,625:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 12:04:46,633:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 12:04:46,672:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 12:04:46,676:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 12:04:46,768:WARNING:c:\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-25 12:04:46,810:INFO:Calculating mean and std
2025-04-25 12:04:46,813:INFO:Creating metrics dataframe
2025-04-25 12:04:46,814:INFO:Uploading results into container
2025-04-25 12:04:46,815:INFO:Uploading model into container now
2025-04-25 12:04:46,815:INFO:_master_model_container: 1
2025-04-25 12:04:46,816:INFO:_display_container: 2
2025-04-25 12:04:46,816:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-25 12:04:46,816:INFO:create_model() successfully completed......................................
2025-04-25 12:04:47,010:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:47,010:INFO:Creating metrics dataframe
2025-04-25 12:04:47,015:INFO:Initializing K Neighbors Classifier
2025-04-25 12:04:47,015:INFO:Total runtime is 0.08387910127639771 minutes
2025-04-25 12:04:47,018:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:47,018:INFO:Initializing create_model()
2025-04-25 12:04:47,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:47,018:INFO:Checking exceptions
2025-04-25 12:04:47,018:INFO:Importing libraries
2025-04-25 12:04:47,018:INFO:Copying training dataset
2025-04-25 12:04:47,037:INFO:Defining folds
2025-04-25 12:04:47,037:INFO:Declaring metric variables
2025-04-25 12:04:47,040:INFO:Importing untrained model
2025-04-25 12:04:47,043:INFO:K Neighbors Classifier Imported successfully
2025-04-25 12:04:47,047:INFO:Starting cross validation
2025-04-25 12:04:47,049:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:50,455:INFO:Calculating mean and std
2025-04-25 12:04:50,458:INFO:Creating metrics dataframe
2025-04-25 12:04:50,460:INFO:Uploading results into container
2025-04-25 12:04:50,461:INFO:Uploading model into container now
2025-04-25 12:04:50,461:INFO:_master_model_container: 2
2025-04-25 12:04:50,461:INFO:_display_container: 2
2025-04-25 12:04:50,462:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-25 12:04:50,462:INFO:create_model() successfully completed......................................
2025-04-25 12:04:50,630:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:50,630:INFO:Creating metrics dataframe
2025-04-25 12:04:50,635:INFO:Initializing Naive Bayes
2025-04-25 12:04:50,635:INFO:Total runtime is 0.14420089721679688 minutes
2025-04-25 12:04:50,638:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:50,638:INFO:Initializing create_model()
2025-04-25 12:04:50,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:50,638:INFO:Checking exceptions
2025-04-25 12:04:50,638:INFO:Importing libraries
2025-04-25 12:04:50,638:INFO:Copying training dataset
2025-04-25 12:04:50,655:INFO:Defining folds
2025-04-25 12:04:50,655:INFO:Declaring metric variables
2025-04-25 12:04:50,657:INFO:Importing untrained model
2025-04-25 12:04:50,660:INFO:Naive Bayes Imported successfully
2025-04-25 12:04:50,666:INFO:Starting cross validation
2025-04-25 12:04:50,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:53,199:INFO:Calculating mean and std
2025-04-25 12:04:53,201:INFO:Creating metrics dataframe
2025-04-25 12:04:53,203:INFO:Uploading results into container
2025-04-25 12:04:53,203:INFO:Uploading model into container now
2025-04-25 12:04:53,204:INFO:_master_model_container: 3
2025-04-25 12:04:53,204:INFO:_display_container: 2
2025-04-25 12:04:53,204:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 12:04:53,204:INFO:create_model() successfully completed......................................
2025-04-25 12:04:53,373:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:53,373:INFO:Creating metrics dataframe
2025-04-25 12:04:53,378:INFO:Initializing Decision Tree Classifier
2025-04-25 12:04:53,378:INFO:Total runtime is 0.18993107080459595 minutes
2025-04-25 12:04:53,380:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:53,381:INFO:Initializing create_model()
2025-04-25 12:04:53,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:53,381:INFO:Checking exceptions
2025-04-25 12:04:53,381:INFO:Importing libraries
2025-04-25 12:04:53,381:INFO:Copying training dataset
2025-04-25 12:04:53,398:INFO:Defining folds
2025-04-25 12:04:53,398:INFO:Declaring metric variables
2025-04-25 12:04:53,401:INFO:Importing untrained model
2025-04-25 12:04:53,404:INFO:Decision Tree Classifier Imported successfully
2025-04-25 12:04:53,409:INFO:Starting cross validation
2025-04-25 12:04:53,410:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:55,956:INFO:Calculating mean and std
2025-04-25 12:04:55,957:INFO:Creating metrics dataframe
2025-04-25 12:04:55,959:INFO:Uploading results into container
2025-04-25 12:04:55,960:INFO:Uploading model into container now
2025-04-25 12:04:55,960:INFO:_master_model_container: 4
2025-04-25 12:04:55,960:INFO:_display_container: 2
2025-04-25 12:04:55,961:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-04-25 12:04:55,961:INFO:create_model() successfully completed......................................
2025-04-25 12:04:56,098:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:56,098:INFO:Creating metrics dataframe
2025-04-25 12:04:56,104:INFO:Initializing SVM - Linear Kernel
2025-04-25 12:04:56,104:INFO:Total runtime is 0.23535449107487996 minutes
2025-04-25 12:04:56,107:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:56,107:INFO:Initializing create_model()
2025-04-25 12:04:56,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:56,107:INFO:Checking exceptions
2025-04-25 12:04:56,107:INFO:Importing libraries
2025-04-25 12:04:56,107:INFO:Copying training dataset
2025-04-25 12:04:56,124:INFO:Defining folds
2025-04-25 12:04:56,124:INFO:Declaring metric variables
2025-04-25 12:04:56,127:INFO:Importing untrained model
2025-04-25 12:04:56,129:INFO:SVM - Linear Kernel Imported successfully
2025-04-25 12:04:56,134:INFO:Starting cross validation
2025-04-25 12:04:56,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:56,640:INFO:Calculating mean and std
2025-04-25 12:04:56,641:INFO:Creating metrics dataframe
2025-04-25 12:04:56,642:INFO:Uploading results into container
2025-04-25 12:04:56,643:INFO:Uploading model into container now
2025-04-25 12:04:56,643:INFO:_master_model_container: 5
2025-04-25 12:04:56,643:INFO:_display_container: 2
2025-04-25 12:04:56,643:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-25 12:04:56,643:INFO:create_model() successfully completed......................................
2025-04-25 12:04:56,779:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:56,780:INFO:Creating metrics dataframe
2025-04-25 12:04:56,785:INFO:Initializing Ridge Classifier
2025-04-25 12:04:56,785:INFO:Total runtime is 0.2467104474703471 minutes
2025-04-25 12:04:56,787:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:56,788:INFO:Initializing create_model()
2025-04-25 12:04:56,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:56,788:INFO:Checking exceptions
2025-04-25 12:04:56,788:INFO:Importing libraries
2025-04-25 12:04:56,788:INFO:Copying training dataset
2025-04-25 12:04:56,804:INFO:Defining folds
2025-04-25 12:04:56,804:INFO:Declaring metric variables
2025-04-25 12:04:56,807:INFO:Importing untrained model
2025-04-25 12:04:56,810:INFO:Ridge Classifier Imported successfully
2025-04-25 12:04:56,815:INFO:Starting cross validation
2025-04-25 12:04:56,816:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:57,004:INFO:Calculating mean and std
2025-04-25 12:04:57,005:INFO:Creating metrics dataframe
2025-04-25 12:04:57,007:INFO:Uploading results into container
2025-04-25 12:04:57,007:INFO:Uploading model into container now
2025-04-25 12:04:57,007:INFO:_master_model_container: 6
2025-04-25 12:04:57,008:INFO:_display_container: 2
2025-04-25 12:04:57,008:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-25 12:04:57,008:INFO:create_model() successfully completed......................................
2025-04-25 12:04:57,143:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:57,143:INFO:Creating metrics dataframe
2025-04-25 12:04:57,149:INFO:Initializing Random Forest Classifier
2025-04-25 12:04:57,149:INFO:Total runtime is 0.25276799996693927 minutes
2025-04-25 12:04:57,152:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:57,152:INFO:Initializing create_model()
2025-04-25 12:04:57,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:57,152:INFO:Checking exceptions
2025-04-25 12:04:57,152:INFO:Importing libraries
2025-04-25 12:04:57,152:INFO:Copying training dataset
2025-04-25 12:04:57,167:INFO:Defining folds
2025-04-25 12:04:57,167:INFO:Declaring metric variables
2025-04-25 12:04:57,170:INFO:Importing untrained model
2025-04-25 12:04:57,173:INFO:Random Forest Classifier Imported successfully
2025-04-25 12:04:57,180:INFO:Starting cross validation
2025-04-25 12:04:57,181:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:59,543:INFO:Calculating mean and std
2025-04-25 12:04:59,543:INFO:Creating metrics dataframe
2025-04-25 12:04:59,545:INFO:Uploading results into container
2025-04-25 12:04:59,545:INFO:Uploading model into container now
2025-04-25 12:04:59,546:INFO:_master_model_container: 7
2025-04-25 12:04:59,546:INFO:_display_container: 2
2025-04-25 12:04:59,546:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-04-25 12:04:59,546:INFO:create_model() successfully completed......................................
2025-04-25 12:04:59,682:INFO:SubProcess create_model() end ==================================
2025-04-25 12:04:59,682:INFO:Creating metrics dataframe
2025-04-25 12:04:59,688:INFO:Initializing Quadratic Discriminant Analysis
2025-04-25 12:04:59,688:INFO:Total runtime is 0.29508339166641234 minutes
2025-04-25 12:04:59,692:INFO:SubProcess create_model() called ==================================
2025-04-25 12:04:59,692:INFO:Initializing create_model()
2025-04-25 12:04:59,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:04:59,692:INFO:Checking exceptions
2025-04-25 12:04:59,692:INFO:Importing libraries
2025-04-25 12:04:59,692:INFO:Copying training dataset
2025-04-25 12:04:59,708:INFO:Defining folds
2025-04-25 12:04:59,708:INFO:Declaring metric variables
2025-04-25 12:04:59,710:INFO:Importing untrained model
2025-04-25 12:04:59,713:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-25 12:04:59,718:INFO:Starting cross validation
2025-04-25 12:04:59,720:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:04:59,860:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 12:04:59,861:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 12:04:59,877:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 12:04:59,878:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 12:04:59,878:WARNING:c:\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-25 12:04:59,928:INFO:Calculating mean and std
2025-04-25 12:04:59,928:INFO:Creating metrics dataframe
2025-04-25 12:04:59,930:INFO:Uploading results into container
2025-04-25 12:04:59,930:INFO:Uploading model into container now
2025-04-25 12:04:59,930:INFO:_master_model_container: 8
2025-04-25 12:04:59,931:INFO:_display_container: 2
2025-04-25 12:04:59,931:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-25 12:04:59,931:INFO:create_model() successfully completed......................................
2025-04-25 12:05:00,070:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:00,070:INFO:Creating metrics dataframe
2025-04-25 12:05:00,076:INFO:Initializing Ada Boost Classifier
2025-04-25 12:05:00,076:INFO:Total runtime is 0.30155752499898275 minutes
2025-04-25 12:05:00,079:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:00,079:INFO:Initializing create_model()
2025-04-25 12:05:00,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:00,079:INFO:Checking exceptions
2025-04-25 12:05:00,079:INFO:Importing libraries
2025-04-25 12:05:00,079:INFO:Copying training dataset
2025-04-25 12:05:00,095:INFO:Defining folds
2025-04-25 12:05:00,095:INFO:Declaring metric variables
2025-04-25 12:05:00,098:INFO:Importing untrained model
2025-04-25 12:05:00,101:INFO:Ada Boost Classifier Imported successfully
2025-04-25 12:05:00,105:INFO:Starting cross validation
2025-04-25 12:05:00,107:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:00,222:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 12:05:00,227:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 12:05:00,236:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 12:05:00,241:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 12:05:00,241:WARNING:c:\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-25 12:05:01,644:INFO:Calculating mean and std
2025-04-25 12:05:01,645:INFO:Creating metrics dataframe
2025-04-25 12:05:01,646:INFO:Uploading results into container
2025-04-25 12:05:01,647:INFO:Uploading model into container now
2025-04-25 12:05:01,647:INFO:_master_model_container: 9
2025-04-25 12:05:01,649:INFO:_display_container: 2
2025-04-25 12:05:01,649:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-04-25 12:05:01,649:INFO:create_model() successfully completed......................................
2025-04-25 12:05:01,794:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:01,794:INFO:Creating metrics dataframe
2025-04-25 12:05:01,801:INFO:Initializing Gradient Boosting Classifier
2025-04-25 12:05:01,801:INFO:Total runtime is 0.33031426270802816 minutes
2025-04-25 12:05:01,803:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:01,803:INFO:Initializing create_model()
2025-04-25 12:05:01,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:01,805:INFO:Checking exceptions
2025-04-25 12:05:01,805:INFO:Importing libraries
2025-04-25 12:05:01,805:INFO:Copying training dataset
2025-04-25 12:05:01,821:INFO:Defining folds
2025-04-25 12:05:01,821:INFO:Declaring metric variables
2025-04-25 12:05:01,823:INFO:Importing untrained model
2025-04-25 12:05:01,827:INFO:Gradient Boosting Classifier Imported successfully
2025-04-25 12:05:01,831:INFO:Starting cross validation
2025-04-25 12:05:01,832:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:07,614:INFO:Calculating mean and std
2025-04-25 12:05:07,615:INFO:Creating metrics dataframe
2025-04-25 12:05:07,617:INFO:Uploading results into container
2025-04-25 12:05:07,618:INFO:Uploading model into container now
2025-04-25 12:05:07,618:INFO:_master_model_container: 10
2025-04-25 12:05:07,618:INFO:_display_container: 2
2025-04-25 12:05:07,619:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-25 12:05:07,619:INFO:create_model() successfully completed......................................
2025-04-25 12:05:07,753:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:07,754:INFO:Creating metrics dataframe
2025-04-25 12:05:07,760:INFO:Initializing Linear Discriminant Analysis
2025-04-25 12:05:07,760:INFO:Total runtime is 0.4296282490094503 minutes
2025-04-25 12:05:07,763:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:07,763:INFO:Initializing create_model()
2025-04-25 12:05:07,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:07,763:INFO:Checking exceptions
2025-04-25 12:05:07,763:INFO:Importing libraries
2025-04-25 12:05:07,763:INFO:Copying training dataset
2025-04-25 12:05:07,779:INFO:Defining folds
2025-04-25 12:05:07,779:INFO:Declaring metric variables
2025-04-25 12:05:07,782:INFO:Importing untrained model
2025-04-25 12:05:07,784:INFO:Linear Discriminant Analysis Imported successfully
2025-04-25 12:05:07,789:INFO:Starting cross validation
2025-04-25 12:05:07,790:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:08,009:INFO:Calculating mean and std
2025-04-25 12:05:08,010:INFO:Creating metrics dataframe
2025-04-25 12:05:08,011:INFO:Uploading results into container
2025-04-25 12:05:08,012:INFO:Uploading model into container now
2025-04-25 12:05:08,012:INFO:_master_model_container: 11
2025-04-25 12:05:08,012:INFO:_display_container: 2
2025-04-25 12:05:08,012:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-25 12:05:08,012:INFO:create_model() successfully completed......................................
2025-04-25 12:05:08,148:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:08,149:INFO:Creating metrics dataframe
2025-04-25 12:05:08,155:INFO:Initializing Extra Trees Classifier
2025-04-25 12:05:08,155:INFO:Total runtime is 0.4362067898114522 minutes
2025-04-25 12:05:08,158:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:08,158:INFO:Initializing create_model()
2025-04-25 12:05:08,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:08,158:INFO:Checking exceptions
2025-04-25 12:05:08,158:INFO:Importing libraries
2025-04-25 12:05:08,158:INFO:Copying training dataset
2025-04-25 12:05:08,173:INFO:Defining folds
2025-04-25 12:05:08,173:INFO:Declaring metric variables
2025-04-25 12:05:08,178:INFO:Importing untrained model
2025-04-25 12:05:08,180:INFO:Extra Trees Classifier Imported successfully
2025-04-25 12:05:08,184:INFO:Starting cross validation
2025-04-25 12:05:08,185:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:09,450:INFO:Calculating mean and std
2025-04-25 12:05:09,451:INFO:Creating metrics dataframe
2025-04-25 12:05:09,452:INFO:Uploading results into container
2025-04-25 12:05:09,452:INFO:Uploading model into container now
2025-04-25 12:05:09,454:INFO:_master_model_container: 12
2025-04-25 12:05:09,454:INFO:_display_container: 2
2025-04-25 12:05:09,454:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-04-25 12:05:09,454:INFO:create_model() successfully completed......................................
2025-04-25 12:05:09,600:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:09,600:INFO:Creating metrics dataframe
2025-04-25 12:05:09,609:INFO:Initializing Extreme Gradient Boosting
2025-04-25 12:05:09,609:INFO:Total runtime is 0.46043636004130045 minutes
2025-04-25 12:05:09,611:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:09,611:INFO:Initializing create_model()
2025-04-25 12:05:09,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:09,611:INFO:Checking exceptions
2025-04-25 12:05:09,613:INFO:Importing libraries
2025-04-25 12:05:09,613:INFO:Copying training dataset
2025-04-25 12:05:09,629:INFO:Defining folds
2025-04-25 12:05:09,629:INFO:Declaring metric variables
2025-04-25 12:05:09,632:INFO:Importing untrained model
2025-04-25 12:05:09,635:INFO:Extreme Gradient Boosting Imported successfully
2025-04-25 12:05:09,642:INFO:Starting cross validation
2025-04-25 12:05:09,644:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:10,566:INFO:Calculating mean and std
2025-04-25 12:05:10,566:INFO:Creating metrics dataframe
2025-04-25 12:05:10,568:INFO:Uploading results into container
2025-04-25 12:05:10,568:INFO:Uploading model into container now
2025-04-25 12:05:10,568:INFO:_master_model_container: 13
2025-04-25 12:05:10,569:INFO:_display_container: 2
2025-04-25 12:05:10,569:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-04-25 12:05:10,569:INFO:create_model() successfully completed......................................
2025-04-25 12:05:10,738:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:10,738:INFO:Creating metrics dataframe
2025-04-25 12:05:10,752:INFO:Initializing Light Gradient Boosting Machine
2025-04-25 12:05:10,752:INFO:Total runtime is 0.4794936180114746 minutes
2025-04-25 12:05:10,757:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:10,758:INFO:Initializing create_model()
2025-04-25 12:05:10,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:10,758:INFO:Checking exceptions
2025-04-25 12:05:10,758:INFO:Importing libraries
2025-04-25 12:05:10,758:INFO:Copying training dataset
2025-04-25 12:05:10,783:INFO:Defining folds
2025-04-25 12:05:10,783:INFO:Declaring metric variables
2025-04-25 12:05:10,787:INFO:Importing untrained model
2025-04-25 12:05:10,790:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-25 12:05:10,797:INFO:Starting cross validation
2025-04-25 12:05:10,799:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:11,693:INFO:Calculating mean and std
2025-04-25 12:05:11,694:INFO:Creating metrics dataframe
2025-04-25 12:05:11,696:INFO:Uploading results into container
2025-04-25 12:05:11,697:INFO:Uploading model into container now
2025-04-25 12:05:11,697:INFO:_master_model_container: 14
2025-04-25 12:05:11,697:INFO:_display_container: 2
2025-04-25 12:05:11,698:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-25 12:05:11,698:INFO:create_model() successfully completed......................................
2025-04-25 12:05:11,860:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:11,860:INFO:Creating metrics dataframe
2025-04-25 12:05:11,867:INFO:Initializing CatBoost Classifier
2025-04-25 12:05:11,868:INFO:Total runtime is 0.4980919082959493 minutes
2025-04-25 12:05:11,870:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:11,870:INFO:Initializing create_model()
2025-04-25 12:05:11,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:11,871:INFO:Checking exceptions
2025-04-25 12:05:11,871:INFO:Importing libraries
2025-04-25 12:05:11,871:INFO:Copying training dataset
2025-04-25 12:05:11,888:INFO:Defining folds
2025-04-25 12:05:11,888:INFO:Declaring metric variables
2025-04-25 12:05:11,892:INFO:Importing untrained model
2025-04-25 12:05:11,895:INFO:CatBoost Classifier Imported successfully
2025-04-25 12:05:11,900:INFO:Starting cross validation
2025-04-25 12:05:11,901:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:36,316:INFO:Calculating mean and std
2025-04-25 12:05:36,317:INFO:Creating metrics dataframe
2025-04-25 12:05:36,319:INFO:Uploading results into container
2025-04-25 12:05:36,321:INFO:Uploading model into container now
2025-04-25 12:05:36,322:INFO:_master_model_container: 15
2025-04-25 12:05:36,322:INFO:_display_container: 2
2025-04-25 12:05:36,322:INFO:<catboost.core.CatBoostClassifier object at 0x0000025F04CAE790>
2025-04-25 12:05:36,322:INFO:create_model() successfully completed......................................
2025-04-25 12:05:36,504:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:36,504:INFO:Creating metrics dataframe
2025-04-25 12:05:36,513:INFO:Initializing Dummy Classifier
2025-04-25 12:05:36,513:INFO:Total runtime is 0.9088457584381103 minutes
2025-04-25 12:05:36,516:INFO:SubProcess create_model() called ==================================
2025-04-25 12:05:36,517:INFO:Initializing create_model()
2025-04-25 12:05:36,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025F02DA71D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:36,517:INFO:Checking exceptions
2025-04-25 12:05:36,517:INFO:Importing libraries
2025-04-25 12:05:36,517:INFO:Copying training dataset
2025-04-25 12:05:36,535:INFO:Defining folds
2025-04-25 12:05:36,535:INFO:Declaring metric variables
2025-04-25 12:05:36,538:INFO:Importing untrained model
2025-04-25 12:05:36,542:INFO:Dummy Classifier Imported successfully
2025-04-25 12:05:36,548:INFO:Starting cross validation
2025-04-25 12:05:36,550:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-04-25 12:05:36,729:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 12:05:36,738:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 12:05:36,747:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 12:05:36,748:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 12:05:36,750:WARNING:c:\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-25 12:05:36,763:INFO:Calculating mean and std
2025-04-25 12:05:36,764:INFO:Creating metrics dataframe
2025-04-25 12:05:36,766:INFO:Uploading results into container
2025-04-25 12:05:36,766:INFO:Uploading model into container now
2025-04-25 12:05:36,766:INFO:_master_model_container: 16
2025-04-25 12:05:36,767:INFO:_display_container: 2
2025-04-25 12:05:36,767:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-25 12:05:36,767:INFO:create_model() successfully completed......................................
2025-04-25 12:05:36,922:INFO:SubProcess create_model() end ==================================
2025-04-25 12:05:36,922:INFO:Creating metrics dataframe
2025-04-25 12:05:36,933:WARNING:c:\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-25 12:05:36,941:INFO:Initializing create_model()
2025-04-25 12:05:36,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025F02E2E250>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-25 12:05:36,941:INFO:Checking exceptions
2025-04-25 12:05:36,943:INFO:Importing libraries
2025-04-25 12:05:36,943:INFO:Copying training dataset
2025-04-25 12:05:36,961:INFO:Defining folds
2025-04-25 12:05:36,961:INFO:Declaring metric variables
2025-04-25 12:05:36,961:INFO:Importing untrained model
2025-04-25 12:05:36,961:INFO:Declaring custom model
2025-04-25 12:05:36,961:INFO:Naive Bayes Imported successfully
2025-04-25 12:05:36,962:INFO:Cross validation set to False
2025-04-25 12:05:36,962:INFO:Fitting Model
2025-04-25 12:05:37,059:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 12:05:37,059:INFO:create_model() successfully completed......................................
2025-04-25 12:05:37,220:INFO:_master_model_container: 16
2025-04-25 12:05:37,220:INFO:_display_container: 2
2025-04-25 12:05:37,221:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-25 12:05:37,221:INFO:compare_models() successfully completed......................................
